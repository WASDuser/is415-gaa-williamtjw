[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resources/ICEs/ex5/ice5.html",
    "href": "resources/ICEs/ex5/ice5.html",
    "title": "ICE 5: Geographically Weighted Summary Statistics: GWmodel methods",
    "section": "",
    "text": "Notes:\n\nFixed Weight Matrices\n\nSuitable for Uniform Data: Works well if data points are uniformly distributed. The spatial extent of each observation’s neighborhood is consistent.\n\n\n\nNo Bias in Neighborhood Size: Every point considers a similar geographical area, making comparison across regions easier in some cases.\nSkew: Dense clusters - too many neighbours; conversely if its sparsely populated, it may result in too few neighbours\n\nAdaptive Weight Matrices\n\nAdapts to spatial data variability\nComputational Complexity\n\nQUEEN contiguity usually is the default analysis to capture all spatial relations but ROOK is preferred to reduce noise if those relations are strictly edge-edge like zoning regulations\nwhen computing the centriod, take note on selecting the study area, e.g. if you want to study Jurong Island, make sure to exclude the other islands so that the placement of the centriod better represents Jurong Island\n\n\n\nICE: Geographically Weighted Summary Statistics\n\nLoad packages\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\n\nData Preparation\n\nhunan_sf &lt;- st_read(dsn = 'data/geospatial/', layer = 'Hunan')\n\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\nhunan_sf &lt;- left_join(hunan_sf,hunan2012) %&gt;% select(1:3,7,15,16,31,32)\nhunan_sf\n\n\nNote: R is case-sensitive; convert everything to UPPER/LOWERCASE\n\nSave derived data into .rds file to simplify subsequent analysis and save memorys\n\nwrite_rds(hunan_sf,'data/rds/hunan_sf.rds')\n\n\n\nMapping GDPPC\nConvert to SpatialPolygon*Dataframe\n\nhunan_sp &lt;- hunan_sf %&gt;% as_Spatial() # old fashioned way of storing in list\n\n\n\nGeographicaly Weighted Summary Statistics\n\nAdaptive bandwidth\n\nAIC\n\nbw_AIC &lt;- bw.gwr(\n  GDPPC ~ 1, # as a function of GDPPC\n  data = hunan_sp,\n  approach = 'AIC', # find the model that best balances goodness of fit and complexity\n  adaptive = TRUE,\n  kernel = 'bisquare', # gives more weight to closer observations and reduces the weight of distant ones smoothly until bandwidth cutoff\n  longlat = T\n)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\n\nCV\n\nbw_CV &lt;- bw.gwr(\n  GDPPC ~ 1,\n  data = hunan_sp,\n  approach = 'CV', # iteratively removing one observation, fitting the model on the remaining data, and then predicting the removed observation; bandwidth that minimizes the prediction error is chosen\n  adaptive = TRUE,\n  kernel = 'bisquare',\n  longlat = T\n)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\n\nCompare\n\nbw_AIC\n\n[1] 22\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nFixed Bandwidth\n\nAIC\n\nbw_AIC_fixed &lt;- bw.gwr(\n  GDPPC ~ 1,\n  data = hunan_sp,\n  approach = 'AIC',\n  adaptive = FALSE,\n  kernel = 'bisquare',\n  longlat = T\n)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\n\nCV\n\nbw_CV_fixed &lt;- bw.gwr(\n  GDPPC ~ 1,\n  data = hunan_sp,\n  approach = 'CV',\n  adaptive = FALSE,\n  kernel = 'bisquare',\n  longlat = T\n)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\n\nCompare\n\nbw_AIC_fixed\n\n[1] 160.5517\n\nbw_CV_fixed\n\n[1] 76.29126\n\n\n\nNote:\nAkaike Information Criterion (AIC): balance between goodness of fit and model complexity; smoother, lower complexity\nCross-Validation (CV): predictive performance (minimizes the prediction error )\n\n\n\n\nCompute GW Summary Stats.\n\ngwstat &lt;- gwss(\n  data = hunan_sp,\n  vars = 'GDPPC',\n  bw = bw_AIC,\n  adaptive = TRUE, # must correspond with bw (bw must be adaptive if TRUE)\n  kernel = 'bisquare',\n  longlat = T\n)\n\n# take note of the gwstat['SDF'] data --&gt; View(gwstat[[\"SDF\"]]@data)\n\nPrepare output data\nExtract SDF table and convert into data.frame\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nAppend the newly derived data frame onto hunan_sf data.frame using cbind()\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\nNote: Don’t do any sorting before appending with cbind() . It combines columns from different data frames, matrices, or vectors by matching their corresponding rows blindly. If you sort one of the data frames before appending with cbind(), it may misalign the data.\n\n\n\n\nVisualise GW Summary Stats.\n\ntm_shape(hunan_gstat) +\n  # tm_fill() and tm_border() better control than tm_polygon()\n  tm_fill( # to create chloropleth map, rather than empty polygon map\n    \"GDPPC_LM\",\n    n=5, # num of class\n    style = 'quantile'\n    ) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"Distribution of GW mean\",\n    main.title.position = 'center',\n    main.title.size = 2.0,\n    legend.text.size = 1.2,\n    legend.height = 1.50,\n    legend.width = 1.50,\n    frame = TRUE\n  )"
  },
  {
    "objectID": "resources/ICEs/ex2/ice2.html",
    "href": "resources/ICEs/ex2/ice2.html",
    "title": "ICE 2:",
    "section": "",
    "text": "Getting Started\n\npacman::p_load(tidyverse,sf,ggstatsplot,tmap)\n\n\n\nImporting Data\n\n2014 Sub-zone Data (shp & kml)\n\nmpsz14_shp &lt;- st_read(dsn = 'data/geospatial/', layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n# layer means sf will search for the engine(?)\n# layer wont need extension because it knows to seek for a shapefile\n#'&lt;-' or '=' works on windows+macOS\n\n\nNote: R is a OOP enabled language, sf being the object class\n\n\nView(mpsz14_shp)\n\n\nmpsz14_kml = st_read('data/geospatial/MasterPlan2014SubzoneBoundaryWebKML.kml')\n# supposed to trigger a error message saying its unsupported / corrupted\n\nMasterPlan2014SubzoneBoundaryWebKML.kml from data.gov.sg is apparently corrupted.\nThis is a quick fix:\n\nst_write(mpsz14_shp, 'data/geospatial/MP14_SUBZONE_WEB_PL.kml', delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/geospatial/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\n\n2019 Subzone Boundary (No sea) (kml, shp, geojson)\n\nmpsz19_kml = st_read('data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml')\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_shp &lt;- st_read(dsn = 'data/MPSZ-2019/', layer = 'MPSZ-2019')\n\nReading layer `MPSZ-2019' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_geojson &lt;- st_read('data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaGEOJSON.geojson')\n\nReading layer `MasterPlan2019SubzoneBoundaryNoSeaGEOJSON' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nNote: geojson format is very messy because the data is buried under html tags so lines of code is needed to extract; while in the kml / shp formats the data is readily accessible\n\n\nNote: under ‘geometry’ if the values tend to be large, its because its in PCS (measure in meters)\n\nIn-class discussion\n\n\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Floor Area of Residence 2023\n\nNote: use the .csv file\n\n\npopdata2023 = read_csv('data/respopagesexfa2023.csv')\n\nRows: 75696 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nPre-School Location (both kml & geojson )\n\npreschool_kml = st_read('data/PreSchoolsLocation.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npreschool_geojson &lt;- st_read('data/PreSchoolsLocation.geojson')\n\nReading layer `PreSchoolsLocation' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex2/data/PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\nTransforming Coordinate System\n\nmpsz19_shp_3414 = mpsz14_shp %&gt;% # pipe operator; saves memory\n  st_transform(crs = 3414)\n\n\npreschool_kml_3414 = preschool_kml %&gt;% \n  st_transform(crs = 3414)\n\nChecking CRS\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\nmpsz19_shp_3414\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nData Wrangling\nPoint-in-Polygon count: count the number of pre-schools in each planning sub-zone\n\nmpsz19_shp_3414 &lt;- mpsz19_shp_3414 %&gt;% mutate(`PreSch Count` = lengths(st_intersects(mpsz19_shp_3414, preschool_kml_3414)))\n\nWrite a single line code to perform the following tasks:\n\nDerive the area of each planning sub-zone.\nDrop the unit of measurement of the area (i.e. m^2)\nCalculate the density of pre-school at the planning sub-zone level\n\n\nmpsz19_shp_3414 &lt;- mpsz19_shp_3414 %&gt;% \n  mutate(\n    Area = units::drop_units(st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n    )\n\n\n\nStatistical Analysis\nUsing Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.\n\nmpsz19_shp_3414$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp_3414$`PreSch Density`))\nmpsz19_shp_3414$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp_3414$`PreSch Count`))\nmpsz19_shp_3414 &lt;- as.data.frame(mpsz19_shp_3414)\n\nggscatterstats(\n  data = mpsz19_shp_3414,\n  x = `PreSch Density`,\n  y = `PreSch Count`,\n  type = 'parametric'\n)\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nPrepare a data frame using the population data\n\npopdata2023 = popdata2023 %&gt;% \n  group_by(PA,SZ,AG) %&gt;% \n  summarise(POP=sum(Pop)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = AG,values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\npivot_wider() transposes the data table structure for easier function application\n\nExamine the data structure\n\nstr(popdata2023)\n\ntibble [332 × 21] (S3: tbl_df/tbl/data.frame)\n $ PA         : chr [1:332] \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" ...\n $ SZ         : chr [1:332] \"Ang Mo Kio Town Centre\" \"Cheng San\" \"Chong Boon\" \"Kebun Bahru\" ...\n $ 0_to_4     : num [1:332] 160 860 680 600 190 730 190 530 0 150 ...\n $ 10_to_14   : num [1:332] 300 1000 890 870 390 720 360 830 0 210 ...\n $ 15_to_19   : num [1:332] 310 1080 1020 970 430 730 450 860 0 240 ...\n $ 20_to_24   : num [1:332] 280 1210 1220 1050 480 850 520 830 0 250 ...\n $ 25_to_29   : num [1:332] 290 1570 1470 1250 510 1050 590 1110 0 320 ...\n $ 30_to_34   : num [1:332] 330 1950 1740 1470 400 1310 540 1400 0 260 ...\n $ 35_to_39   : num [1:332] 320 1860 1640 1390 320 1060 380 1200 0 240 ...\n $ 40_to_44   : num [1:332] 400 2100 1690 1580 380 1110 400 1490 0 300 ...\n $ 45_to_49   : num [1:332] 440 1910 1790 1640 480 1180 520 1530 0 300 ...\n $ 50_to_54   : num [1:332] 420 2070 1780 1680 550 1230 600 1400 0 340 ...\n $ 55_to_59   : num [1:332] 340 2050 1980 1720 540 1310 600 1410 0 300 ...\n $ 5_to_9     : num [1:332] 260 970 790 810 350 730 300 690 0 210 ...\n $ 60_to_64   : num [1:332] 300 2070 2080 1710 520 1410 660 1570 0 310 ...\n $ 65_to_69   : num [1:332] 270 2080 2070 1680 420 1270 630 1530 0 310 ...\n $ 70_to_74   : num [1:332] 280 1980 1900 1570 370 1150 440 1480 0 230 ...\n $ 75_to_79   : num [1:332] 160 1210 1410 1120 280 790 280 1050 0 150 ...\n $ 80_to_84   : num [1:332] 120 760 990 710 190 580 220 750 0 90 ...\n $ 85_to_89   : num [1:332] 50 360 450 360 120 310 150 400 0 50 ...\n $ 90_and_Over: num [1:332] 30 200 250 210 90 180 80 210 0 30 ...\n\n\n\nNote: age ranges are not in sequential order\n\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\nNote: index starts from 1\n\nFix the data table (override the previous)\nWrite a code chunk to derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\npopdata2023 = popdata2023 %&gt;% \n  # CALCULATING AGE GROUP TOTALS\n  mutate(`YOUNG`=rowSums(.[3:6])+rowSums(.[14])) %&gt;%                # CREATES new col 'YOUNG'\n  mutate(`ECONOMY ACTIVE`=rowSums(.[7:13])+rowSums(.[15])) %&gt;%   # CREATES new col `ECONOMY ACTIVE`\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%                              # CREATES new col `AGED`\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%                              # CREATES new col `TOTAL`\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%   # CREATES new col `DEPENDENCY` to calculate dependency ratio\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`) # determines column order and contents in OUTPUT DATASET\n\nBecause R is case sensitive, convert into all same uppercase or lowercase in the datasets.\n\npopdata2023 = popdata2023 %&gt;% \n  mutate_at(\n    .vars = vars(PA,SZ),\n    .funs = list(toupper)\n    )\n\nPerform left-join whereby the join fields are SUBZONE_N from the mpsz19_shp sf data.frame and SZ from the popdata2023 data.frame.\n\nmpsz_popdata2023 = left_join(mpsz19_shp_3414,popdata2023, by = c('SUBZONE_N'='SZ'))\n\n\nNote: In the c() function, the column names’ positions correspond to which data table is the left table\n\nPlot the choropleth map.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(st_sf(mpsz_popdata2023)) +\n  tm_fill( # either a fixed color or a color palette is mapped to the variable\n    'DEPENDENCY',\n    style = 'quantile',\n    palette = 'Blues',\n    title = 'Dependency ratio'\n  ) +\n  tm_layout(\n    main.title = \"Distribution of Dependency Ratio by planning subzone\",\n    main.title.position = \"center\",\n    main.title.size = 1,\n    legend.title.size = 1,\n    legend.height = 0.45, \n    legend.width = 0.35,\n    bg.color = \"#E4D5C9\",\n    frame = F\n  ) +\n  \n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics (DOS)\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "resources/ICEs/ex4/ice4.html",
    "href": "resources/ICEs/ex4/ice4.html",
    "title": "ICE 4: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "Background\n\nSpatio-temporal point process (stpp) is a random collection of points, where each point represents the time and location of an event\nfor geographically and temporally indexed data\nContext:\n\nA real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023\n\n\n\n\nObjectives\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\nNotes:\n\nspace-time KDE (STKDE) - bullet point 4-5 of THE1 where data is across-time, rather than the use of cross-sectional data in KDE (single-point in time) previously\n\n\n\nCode:\n\nLoad packages\n\nNOTE THAT sparr HAS AN ANIMATING FEATURE TO SEE HOW ST PATTERNS DIFFUSE\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sparr)\n\n\n\nImport and Prepare Study Area\n\nImport and remove ‘z’\n\nkbb &lt;- st_read(dsn = 'data/rawdata/', layer = 'Kepulauan_Bangka_Belitung') %&gt;% \n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n“desolve” ‘z’ boundaries before preparing study area\nkbb contains a new geometry type: polygonz, denoting as height — drop ‘z’ otherwise will incur an error when converting to ppp object class\n\n\nRevised code chunk to account for the above\n\nkbb_sf &lt;- st_read(dsn = 'data/rawdata/', layer = 'Kepulauan_Bangka_Belitung') %&gt;% \n  # addition\n  st_union() %&gt;% \n  st_zm(drop = TRUE, what = 'ZM') %&gt;% \n  # --------\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\n\n\nConvert to OWIN\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\n\n\nConfirm class of output\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\nIf using kbb with ‘z’, the following error will occur:\n\n# kbb_owin_error &lt;- as.owin(kbb)\n\n# error:\n# Error in owinInternalPoly(xrange, yrange, ..., poly = poly, unitname = unitname) : \n#   poly must be either a list(x,y) or a list of list(x,y)\n\n\n\n\nImport and Prepare Forest Data\n\nfire_sf &lt;- read_csv('data/rawdata/forestfires.csv') %&gt;% \n  st_as_sf(coords = c('longitude', 'latitude'), crs = 4326) %&gt;% # combines columns to convert into geospatial data\n                                                                # order must be long then lat (follows x,y)\n  st_transform(crs = 32748)                                     # converts to UTM 48\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nNote that ‘longitude’ and ‘latitude’ combined to form ‘geometry’ in UTM48 from WGS84\nIf st_as_sf() and st_transform not used:\n\n\n\nfire &lt;- read_csv('data/rawdata/forestfires.csv')\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# will output an ASPATIAL data file\n\nBecause ppp object only accepts numerical or characters as mark, the code chunk below is used to convert data type of acq_date to numeric\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate('DayofYear' = yday(acq_date)) %&gt;% \n  mutate('Month_num' = month(acq_date)) %&gt;% \n  mutate('Month_fac' = month(\n    acq_date, \n    label = TRUE, # display the month as a character string e.g. \"January.\"; FALSE will display the month as a number.\n    abbr = FALSE # display the month as a character string label, e.g. \"January\"; TRUE displays abbr version of the label, like \"Jan\"\n    ))\n\n\nfire_sf\n\nSimple feature collection with 741 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 521564.1 ymin: 9658137 xmax: 695791 ymax: 9828767\nProjected CRS: WGS 84 / UTM zone 48S\n# A tibble: 741 × 17\n   brightness  scan track acq_date   acq_time satellite instrument confidence\n *      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;\n 1       312.   1.3   1.1 2023-01-10      629 Aqua      MODIS              67\n 2       314.   1.2   1.1 2023-01-10      629 Aqua      MODIS              70\n 3       315.   1.2   1.1 2023-01-10      629 Aqua      MODIS              71\n 4       309.   1.2   1.1 2023-01-10      629 Aqua      MODIS              54\n 5       308.   1.2   1.1 2023-01-10      629 Aqua      MODIS              33\n 6       322.   1.3   1.1 2023-01-10      629 Aqua      MODIS              72\n 7       318.   1.2   1.1 2023-01-10      629 Aqua      MODIS              71\n 8       318.   1.2   1.1 2023-01-10      629 Aqua      MODIS              75\n 9       327.   2     1.4 2023-01-12      616 Aqua      MODIS              73\n10       321.   2     1.4 2023-01-12      616 Aqua      MODIS              75\n# ℹ 731 more rows\n# ℹ 9 more variables: version &lt;dbl&gt;, bright_t31 &lt;dbl&gt;, frp &lt;dbl&gt;,\n#   daynight &lt;chr&gt;, type &lt;dbl&gt;, geometry &lt;POINT [m]&gt;, DayofYear &lt;dbl&gt;,\n#   Month_num &lt;dbl&gt;, Month_fac &lt;ord&gt;\n\n\n\n\n\nFire points Visualisation\n\nTaskCode\n\n\nPrepare a point symbol map showing the distribution of fire points\n\n\n\ntm_shape(kbb_sf) + tm_polygons() + # plot polygon overview layer first\n  tm_shape(fire_sf) + tm_dots()    # plot dot layer next (otherwise dots cant be seen)\n\n\n\n\n\n\n\n\n\n\n\n\nTaskCode\n\n\nUsing steps learned in Hands-on Exercise 2, prepare a point symbol map showing the monthly geographic distribution of forest fires in 2023.\n\n\n\ntm_shape(kbb_sf) + tm_polygons() + \n  tm_shape(fire_sf) + tm_dots(size = 0.1) +\ntm_facets(\n  by= 'Month_fac', # data variable name by which the data is split\n  free.coords = FALSE, # should each map has its own coordinate ranges? if TRUE the map visual will look awkward (different zooms)\n  drop.units = TRUE) # should non-selected spatial units be dropped?\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Monthly STKDE\n\nExtract monthly forest fires\nRemove unwanted fields from fire_sf dataframe because as.ppp() only needs the mark field and geometry field from the input sf dataframe\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)\n\n\n\nCreate ppp object\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\n\nVerify output\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\nsum(duplicated(fire_month_ppp))\n\n[1] 0\n\n\n\nDuplicates are highly unlikely because the likelihood of a fire being detected at the exact location from outer-space sats is very low\n\n\n\nInclude owin object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\nComputing STKDE\n\nlibrary(sparr)\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n# Error in spattemp.density(fire_month_owin) : \n#   could not find function \"spattemp.density\"\n\n\n\nPlotting STKDE object\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\n\nfor (i in tims){\n  plot(st_kde, i,\n    override.par=FALSE,\n    fix.range=TRUE,\n    main=paste(\"Monthly KDE\",i)\n  )\n}\n\n\n\n\n\n\n\n\n\n\n\nComputing STKDE by Year\n\nCreating ppp object\n\nhead(fire_sf)\n\nSimple feature collection with 6 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 606178.8 ymin: 9682757 xmax: 669933.6 ymax: 9703062\nProjected CRS: WGS 84 / UTM zone 48S\n# A tibble: 6 × 17\n  brightness  scan track acq_date   acq_time satellite instrument confidence\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;\n1       312.   1.3   1.1 2023-01-10      629 Aqua      MODIS              67\n2       314.   1.2   1.1 2023-01-10      629 Aqua      MODIS              70\n3       315.   1.2   1.1 2023-01-10      629 Aqua      MODIS              71\n4       309.   1.2   1.1 2023-01-10      629 Aqua      MODIS              54\n5       308.   1.2   1.1 2023-01-10      629 Aqua      MODIS              33\n6       322.   1.3   1.1 2023-01-10      629 Aqua      MODIS              72\n# ℹ 9 more variables: version &lt;dbl&gt;, bright_t31 &lt;dbl&gt;, frp &lt;dbl&gt;,\n#   daynight &lt;chr&gt;, type &lt;dbl&gt;, geometry &lt;POINT [m]&gt;, DayofYear &lt;dbl&gt;,\n#   Month_num &lt;dbl&gt;, Month_fac &lt;ord&gt;\n\n\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayofYear) %&gt;% \n  as.ppp()\n\n\n\nInclude owin object\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\nCompute STKDE\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\n\nPlotting STKDE object\n\nplot(kde_yday)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing STKDE by Day of Year: Improved method\n\nDetermine both the spatial bandwidth and the scalar temporal bandwidth using BOOT.spattemp()\n\nset.seed(1234) # for reproducible result\nBOOT.spattemp(fire_yday_owin)\n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n         h     lambda \n9105.73611   18.85762 \n\n# TLDR:\n# allows computing of kernel density over time and space together\n# allows the kernel bandwidth to vary in both space and time\n# computes densities across three dimensions (two spatial, one temporal), which is essential for realistic spatio-temporal modeling\n# flexibility in the choice of kernel\n\n\n\nComputing STKDE object\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,\n  h = 9000, # radius around each data point over which influence is spread: bigger BW, more smoothin, less sens to small-scale variation; ROUNDED DOWN b/c balanced between noise and smoother aesthetics\n  lambda = 19) # same concept as spatial BW; marginal change + smooth out short-term fluctuations or noise and emphasize longer-term trends\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]\n\n\n\n\nPlotting STKDE object\n\nplot(kde_yday)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReadings\nJonatan A. González, et. al. (2016) “Spatio-temporal point process statistics: A review”, Spatial Statistics, Volume 18, Part B, November 2016, Pages 505-544.\nAlexander Hohl et. al.“Spatiotemporal Point Pattern Analysis Using Ripley’s K” in Geospatial Data Science Techniques and Applications.\nTonini, Marj et. al. (2017) “Evolution of forest fires in Portugal: from spatio-temporal point events to smoothed density maps”, Natural hazards (Dordrecht), 2017-02, Vol.85 (3), p.1489-1510. Available at SMU eJournal.\nJuan, P et. al. (2012)“Pinpointing spatio-temporal interactions in wildfire patterns”, Stochastic environmental research and risk assessment, 2012-12, Vol.26 (8), p.1131-1150. Available at SMU eJournal.\n\n\nAbout R"
  },
  {
    "objectID": "resources/ICEs/ex4/reference.html",
    "href": "resources/ICEs/ex4/reference.html",
    "title": "ICE 4 Readings: Summarised + chatGPT-ed",
    "section": "",
    "text": "“Spatio-temporal point process statistics: A review”\nTypes of Spatio-Temporal Point Patterns\nThe paper categorizes spatio-temporal point patterns into three main types:\n\nInstantaneous events: Data are treated as a collection of instantaneous events, each occurring at a given spatial location and time point. Examples include earthquakes and disease outbreaks.\nPoints that arrive, obtain a location, and stay for a period: During the study period, points arrive at some time, obtain a spatial location, and stay for a given period before being removed. Examples include modeling forest stands where each tree has a birth time and lifetime.\nContinuously moving objects sampled at discrete times: Objects move continuously through space and form paths, which are sampled at discrete time points. Examples include analyzing animal movement patterns.\n\nStatistical Characteristics\nThe paper discusses important characteristics of spatio-temporal point processes, including:\n\nProduct densities: Generalize the concept of intensity functions to higher orders.\nIntensity functions: Describe the expected number of events per unit space and time. Separability into spatial and temporal components is an important property.\nConditional intensity functions: Uniquely characterize certain spatio-temporal point processes and govern the expected number of future events given the history of the process.\nSecond-order summary statistics: Such as the pair correlation function, K-function, and J-function, can be used to quantify spatial and temporal interactions.\n\nEmpirical Models\nVarious empirical models for spatio-temporal point processes are reviewed, including:\n\nHomogeneous and inhomogeneous Poisson processes\nNeyman-Scott processes\nGeometric anisotropic Poisson cluster processes\nInhibition processes\nStrauss processes\nCox processes\nLog-Gaussian Cox processes\n\nThese models can be fitted to data using likelihood-based inference methods.\nMechanistic Models\nConditional intensity-based models, referred to as mechanistic models, treat the spatial locations as marks of a temporal point process. The conditional intensity function governs the expected number of future events given the history. Mechanistic models are commonly used for analyzing earthquake data and other applications.\nInference Methods\nThe paper covers likelihood inference and partial likelihood methods for parameter estimation. Graphical tools like residual plots and Q-Q plots are discussed for assessing goodness-of-fit.\nReal-World Applications\nThree motivating examples are analyzed throughout the paper to illustrate the application of the discussed techniques to real data:\n\nHuman outbreaks of Ebola\nEuphausia glacialis (a type of krill)\nTornadoes in South Carolina\n\nThese examples highlight the growing availability of spatio-temporal data and the importance of understanding the mechanisms governing event occurrences in space and time across various scientific fields.\n\n\n“Spatiotemporal Point Pattern Analysis Using Ripley’s K”\nGlobal Ripley’s K Function for Spatiotemporal Point Patterns\n\nThe global space-time Ripley’s K function evaluates the spatiotemporal characteristics of a point pattern at the aggregated level using the entire dataset\nIt is calculated by dividing the number of events expected to fall within a given spatial distance d and temporal distance t by the intensity λ of the point events\nThe global space-time K function is the cumulative distribution of observed point events with increasing space and time distance\nIt can indicate clustering, randomness, or regularity in the spatiotemporal point pattern\n\nLocal Ripley’s K Function for Spatiotemporal Point Patterns\n\nThe local form of Ripley’s K function quantifies the characteristics of the point pattern and its deviation from expected patterns locally\nIt provides insights into the spatiotemporal dynamics of the point process at a more granular level compared to the global K function\n\nCase Study: Dengue Fever in Cali, Colombia\n\nThe authors applied global and local forms of Ripley’s K function to study the spatiotemporal patterns of dengue fever in Cali, Colombia\nThe case study illustrates the benefits of using the combined global and local Ripley’s K function approach for analyzing dynamic geospatial phenomena\n\nIn conclusion, the article demonstrates the capability of Ripley’s K function, both in its global and local forms, for studying spatiotemporal point patterns The case study on dengue fever highlights the insights that can be gained by applying this methodology to real-world geospatial data\n\n\n“Evolution of forest fires in Portugal: from spatio-temporal point events to smoothed density maps”, Natural hazards (Dordrecht)\nThis article analyzes the spatial and temporal distribution of forest fires in Portugal from 1990 to 2013 using spatio-temporal statistical methods. The authors used the Portuguese National Mapping Burnt Areas (NMBA) dataset, which contains 27,273 fire events with a burned area greater than 5 hectares\nKey findings:\n\nThe northern half of Portugal is much more affected by forest fires than the southern half, with 25,322 and 1,951 events respectively\nFires were categorized into small (5-15 ha), medium (15-100 ha), and large (&gt;100 ha) based on burned area. Medium fires tend to aggregate around small fires, while large fires aggregate at larger distances and longer times\nDensity maps show hot spots are present almost every year in the northern region, with higher concentrations, while the southern half has lower densities mainly in the 2000-2007 period\nThe largest total annual burned areas occurred in 2003 and 2005, despite not having the highest number of events in those years. The years with the most fires were 1998, 2001, and 2002 with around 1,850 events each\n\nThe authors applied four spatio-temporal statistical methods to explore the data:\n\nGeographically weighted summary statistics to examine how average burned area varies locally\nBivariate K function to test space-time interaction and spatial attraction/independence between fires of different sizes\nSpace-time K function to test the interaction between space and time\nSpace-time kernel density to create smoothed density surfaces representing over-densities of fires\n\nThe results help identify vulnerable areas and time periods where fire hazard is more likely to occur, which is crucial information for fire prevention and management strategies.\n\n\n“Pinpointing spatio-temporal interactions in wildfire patterns”, Stochastic environmental research and risk assessment\nIntroduction\nThe introduction defines wildfires as uncontrolled fires in vegetation, emphasizing their unique characteristics, such as rapid spread and potential for unexpected direction changes. It highlights the Mediterranean region’s high fire risk due to climatic conditions and landscape dynamics, particularly in Catalonia, where afforestation and rural abandonment have increased vulnerability to fires. The authors argue that understanding the spatial and temporal patterns of wildfires is crucial for effective management and prevention.\nData and Methodology\nThe study focuses on a dataset of 3,083 wildfires recorded in Catalonia during the specified period. The authors categorize the causes of these wildfires into natural, negligence, intentional (arson), and unknown. They also analyze spatial covariates such as slope, aspect, hill shade, and land use, utilizing the CORINE land cover database.The authors employ point process models to evaluate the spatial distribution of wildfires and assess clustering patterns. They utilize statistical methods to test for deviations from complete spatial randomness (CSR), which helps identify whether wildfires are randomly distributed or exhibit clustering.\nResults\nThe analysis reveals that negligence is the most common cause of wildfires, followed by intentional and unknown causes. The study notes a significant increase in wildfires from 2004 to 2005, followed by a decrease in subsequent years, with 2008 recording the lowest number of incidents.Spatially, the distribution of wildfires varies by cause, with intentional and unknown causes displaying similar patterns. The paper discusses the implications of these findings for wildfire management, suggesting that understanding clustering can aid in resource allocation and risk assessment.\nStatistical Analysis\nThe authors delve into functional summary statistics and the mathematical theory of point processes, explaining how these tools can model the irregular distribution of wildfire events. They emphasize the importance of testing CSR to classify observed patterns as regular, random, or aggregated, which informs further modeling efforts.\nConclusion\nThe paper concludes by reiterating the significance of spatio-temporal analysis in understanding wildfire dynamics. The authors advocate for the use of advanced statistical modeling techniques to improve wildfire management strategies, emphasizing the need for ongoing research in this area.Overall, the study provides valuable insights into the factors influencing wildfire patterns in Catalonia, highlighting the interplay between environmental variables and human activities."
  },
  {
    "objectID": "resources/ICEs/ex7/ice7.html",
    "href": "resources/ICEs/ex7/ice7.html",
    "title": "ICE 7: Cluster Analysis",
    "section": "",
    "text": "Lecture Notes:\n\nRather than using absolute figures for comparison during analysis, consider deriving ratios or percentages to account for external factors (e.g. compute % of observations across total population rather than abolute raw data)\nPairwise plots indicate linearity only, so if there is no correlation, it only means that the comparison variables are not linearly related, but could possibly exhibit other forms of relationship.\nChoose best optimal method (e.g. Gap Statistics) then decide how many clusters to retain\n\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, # modify as needed\n                    B = 50)\n\n\n\nusually look for anything after 3\n\nBeware of lone rangers, very unique/highly dissimilar values (possibly due to rare combination of attributes), consider removing (depends on context)\nconsider isolating input and output fields for prototype interface\nAlternative view of clustering\n\nParallel coordinates\n\nplotly, giraffe"
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Nothing for now."
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#aggregating-by-province",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#aggregating-by-province",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Aggregating by Province",
    "text": "Aggregating by Province\n\nRelational Join\n\nset.seed(69)\n\n\nprovince_drug_offences &lt;- thai_drug_offences_sf %&gt;% \n  group_by(province_en) %&gt;%\n  summarize(total_cases = sum(no_cases), .groups = 'drop')\nhead(province_drug_offences)\n\n\ncombined_prepped_drug_offences_ &lt;- left_join(province_drug_offences, thai_admin1_sf,by = c('province_en'='ADM1_EN')) %&gt;% st_as_sf()\nglimpse(combined_prepped_drug_offences_)\n\n\ntmap_mode('plot')\n\ntm_shape(combined_prepped_drug_offences_)+\n  tm_polygons() +\n  tm_fill(alpha = .5,col = combined_prepped_drug_offences_$total_cases)\n  tm_text(combined_prepped_drug_offences_$province_en)\n\n\n\nLandmine\nThis is where I encountered the first landmine of sorts. The above code results in:\nError in `$&lt;-`:\n! Assigned data `as.numeric(...)` must be compatible with existing data.\n✖ Existing data has 77 rows.\n✖ Assigned data has 75 rows.\nℹ Only vectors of size 1 are recycled.\nCaused by error in `vectbl_recycle_rhs_rows()`:\n! Can't recycle input of size 75 to size 77.\nSo I went to re-check the left-joined table prepped_drug_offences . I realised for the “buogkan” and “Loburi” rows, besides the ‘total_cases’ field, the rest of the fields were empty.\nSeeing how suspiciously “buogkan” looks like a typo, I went to Google both “buogkan” and “Loburi” along with Thailand. Sure enough, the suggested words of “buogkan” and “Loburi” turned out to be “Bueng Kan” and “Lop buri” respectively.\nTurned out the Thailand Drug Offenses had the 2 erroneous province names, while the shapefiles’ province labels checked out.\nI will have to do manual replacements for all affected fields in thai_drug_offences_sf\n\n\nFixing Mispelled Province Names\nCheck before\n\nunique(thai_drug_offences_sf$province_en)[6]\n\n[1] \"Loburi\"\n\nunique(thai_drug_offences_sf$province_en)[30]\n\n[1] \"buogkan\"\n\n\nRename and Standardise Case\n\nthai_drug_offences_sf$province_en[which(thai_drug_offences_sf$province_en == \"Loburi\")] &lt;- 'Lop buri'\nthai_drug_offences_sf$province_en[which(thai_drug_offences_sf$province_en == \"buogkan\")] &lt;- 'Bueng Kan'\n\nthai_drug_offences_sf &lt;- thai_drug_offences_sf %&gt;% mutate(province_en = toupper(province_en))\n\nCheck fix\n\nunique(thai_drug_offences_sf$province_en)[6]\n\n[1] \"LOP BURI\"\n\nunique(thai_drug_offences_sf$province_en)[30]\n\n[1] \"BUENG KAN\"\n\n\nThat should resolve the landmine.\nSeparating suspected cases using grepl()\n\n# suspected\nsuspected_offenses_sf &lt;- thai_drug_offences_sf %&gt;% filter(grepl(\"suspects\", types_of_drug_offenses))\n\n\n# actual\noffenses_sf &lt;- thai_drug_offences_sf %&gt;% filter(!grepl(\"suspects\", types_of_drug_offenses)) \n\nI split thai_drug_offences_sf into confirmed cases (offenses_sf) and suspected cases(suspected_offenses_sf), because including suspected cases may skew the overall analysis results, adding noise and uncertainty to confirmed drug abuse activity. Splitting allows for separate modelling of suspected cases, which can value-add to the detection of drug abuse in areas of concern.\n\n\n[Again] Relational Join\n\n# actual\ncombined_offenses_sf &lt;- left_join(\n  (\n    offenses_sf %&gt;% \n      group_by(province_en) %&gt;%\n      summarize(total_cases = sum(no_cases), .groups = 'drop')),\n  \n    thai_admin1_sf,\n  \n  by = c('province_en'='ADM1_EN')) %&gt;% \n  st_as_sf()\n\nstr(combined_offenses_sf)\n\n\n# suspected\ncombined_suspected_offenses_sf &lt;- left_join(\n  (\n    suspected_offenses_sf %&gt;% \n      mutate(province_en = toupper(province_en)) %&gt;%\n      group_by(province_en) %&gt;%\n      summarize(total_cases = sum(no_cases), .groups = 'drop')),\n  \n  (\n    thai_admin1_sf %&gt;% \n      mutate(\n        ADM1_EN = toupper(ADM1_EN),\n        ADM1_PCODE = substr(ADM1_PCODE, 3, nchar(ADM1_PCODE)))),\n  \n  by = c('province_en'='ADM1_EN')) %&gt;% \n  st_as_sf()\n\nstr(combined_suspected_offenses_sf)\n\n\n\nDistribution of no_cases\n\nBig PictureAggregated Cases by Province across 2017-2022\n\n\nOverall Visualisations\n\n\nCode\nbasemap &lt;- tm_shape(combined_offenses_sf) + tm_polygons() + tm_text(\"ADM1_PCODE\",size = 0.4)\noffenses &lt;- qtm(combined_offenses_sf,\"total_cases\",title = 'confirmed offenses')\nsuspects &lt;- qtm(combined_suspected_offenses_sf,\"total_cases\", title = 'suspected offenses')\ntmap_arrange(suspects, basemap, offenses, asp=1, ncol=3)\n\n\n\n\n\n\n\n\n\nOverall Distribution\n\nActual\n\n\nCode\npar(mfrow=c(1,2))\nplot(offenses_sf$no_cases)\nplot(fitdist(offenses_sf$no_cases, 'norm'))\n\n\n\n\n\n\n\n\n\n\n\n\nSuspected\n\n\nCode\nplot(suspected_offenses_sf$no_cases)\nplot(fitdist(suspected_offenses_sf$no_cases, 'norm'))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActual\n\n\nCode\nplot(combined_offenses_sf$total_cases, )\nplot(fitdist(combined_offenses_sf$total_cases, 'norm'))\n\n\n\n\n\n\n\n\n\n\n\n\nSuspected\n\n\nCode\nplot(combined_suspected_offenses_sf$total_cases)\nplot(fitdist(combined_suspected_offenses_sf$total_cases, 'norm'))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusions: Right Skewed, heavy right tail, outliers present; Actual and Suspected cases follow the similar distribution\nHence, to visualise the continuous variable total_cases , lets experiment with:\n\nquantile\nlog10\norder\nheadtails\nlog10_pretty\ncont\n\n\n\n\n\nVisualise actual cases\n\nVisual styling\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nstyle = “quantile”style = “log10”style = “order”style = ‘headtails’style = ‘log10_pretty’style = ‘cont’\n\n\n\n\nCode\noffenses_qt &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"quantile\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 0.666\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_qt &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"quantile\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 0.666\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_qt, suspected_qt, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noffenses_log &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"log10\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_log &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"log10\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_log, suspected_log, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noffenses_odr &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"order\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_odr &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"order\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_odr, suspected_odr, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noffenses_ht &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"headtails\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_ht &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"headtails\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_ht, suspected_ht, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noffenses_lgprty &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"log10_pretty\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_lgprty &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"log10_pretty\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_lgprty, suspected_lgprty, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noffenses_cont &lt;- tm_shape(combined_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"cont\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\nsuspected_cont &lt;- tm_shape(combined_suspected_offenses_sf) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"-RdYlGn\",\n    style = \"cont\",    # Use quantiles to emphasize hotspots\n    border.col = \"white\",\n    lwd = 0.666,             # Adjust line width of province borders\n  ) +\n  tm_text(\n    \"ADM1_PCODE\",    # Province NUMERIC code\n    size = \"total_cases\",  # proportional symbols\n    col = \"black\",\n    # auto.placement = TRUE,\n    shadow = TRUE\n  ) +\n  \n  tm_borders(lwd = 0.666) +  # Border thickness\n  tm_compass(type=\"8star\", size = 1.666) +\n  tm_scale_bar(width = 0.156, position = c(\"right\", \"bottom\"))  +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  \n  tm_layout(\n    legend.outside = TRUE, \n    frame = FALSE,\n    main.title = \"Thailand Drug Suspected Offenses (2017-2022)\",\n    main.title.size = 1.0\n  ) +\n  tm_legend(position = c(\"right\", \"bottom\")) # Legend Position\n\ntmap_arrange(offenses_cont, suspected_cont, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n'log10' style had the best visualisation of the distribution drug offenses in terms of contrast between ‘hot’ and ‘cold’ spots and overall aesthetics."
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#aggregating-by-time-province-same-as-on-profs-site",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#aggregating-by-time-province-same-as-on-profs-site",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Aggregating by Time & Province (Same as on Prof’s site)",
    "text": "Aggregating by Time & Province (Same as on Prof’s site)\n\nRelational Join\n\noffences_sf_joined &lt;- left_join(\n    (offenses_sf  %&gt;% group_by(fiscal_year)),\n    thai_admin1_sf,\n    by = c('province_en'='ADM1_EN')) %&gt;%\n    st_as_sf()\n\nsuspected_offenses_sf_joined &lt;- left_join(\n    (suspected_offenses_sf %&gt;% group_by(fiscal_year)),\n    thai_admin1_sf,\n    by = c('province_en'='ADM1_EN')) %&gt;%\n    st_as_sf()\n\n\n\nModify\n\noffences_sf_by_province_year &lt;- offences_sf_joined %&gt;% \n    group_by(fiscal_year,province_en,ADM1_PCODE, geometry) %&gt;%\n    summarise(total_cases = sum(no_cases, na.rm = TRUE), .groups = \"drop\")\n\nsuspected_offences_sf_by_province_year &lt;- suspected_offenses_sf_joined %&gt;% \n    group_by(fiscal_year,province_en,ADM1_PCODE, geometry) %&gt;%\n    summarise(total_cases = sum(no_cases, na.rm = TRUE), .groups = \"drop\")\n\n\n.groups = \"drop\" avoids creating unnecessary group structure\n\n\n\nCheck\n\nglimpse(offences_sf_by_province_year)\n\nRows: 462\nColumns: 5\n$ fiscal_year &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017…\n$ province_en &lt;chr&gt; \"AMNAT CHAROEN\", \"ANG THONG\", \"BANGKOK\", \"BUENG KAN\", \"BUR…\n$ ADM1_PCODE  &lt;chr&gt; \"37\", \"15\", \"10\", \"38\", \"31\", \"24\", \"18\", \"36\", \"22\", \"50\"…\n$ geometry    &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((104.9598 16..., MULTIPOLYGON …\n$ total_cases &lt;dbl&gt; 2499, 748, 28747, 2070, 2411, 4566, 729, 3134, 1952, 7438,…\n\n\n\nglimpse(suspected_offences_sf_by_province_year)\n\nRows: 462\nColumns: 5\n$ fiscal_year &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017…\n$ province_en &lt;chr&gt; \"AMNAT CHAROEN\", \"ANG THONG\", \"BANGKOK\", \"BUENG KAN\", \"BUR…\n$ ADM1_PCODE  &lt;chr&gt; \"37\", \"15\", \"10\", \"38\", \"31\", \"24\", \"18\", \"36\", \"22\", \"50\"…\n$ geometry    &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((104.9598 16..., MULTIPOLYGON …\n$ total_cases &lt;dbl&gt; 2577, 866, 31320, 2242, 2650, 4752, 807, 3301, 2069, 8182,…\n\n\n\n\nVisualise using tmap\nAs previously plotted, the distribution of drug offenses in Thailand (across time periods and within province areas) is characteristic of a right-skewed distribution or heavy-tailed distribution. Hence, a logarithmic scale or a Jenks Natural Breaks method would be suitable to handle the skewness and emphasize meaningful breaks in the data.\n\nLog\n\n\nCode\ntm_shape(offences_sf_by_province_year) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"Blues\",       # Use a blue color palette similar to the image\n    style = \"log10\",      # Adjust based on the distribution of your data\n    n = 5,                   # Define number of bins for colors\n    title = \"Drug use cases\"\n  ) +\n  tm_borders() +\n  tm_facets(by = \"fiscal_year\", nrow = 2, ncol = 3) +  # Facet by year, 2 rows and 3 columns\n  tm_layout(\n    title = \"Drug use cases by year\",               # Title for the entire plot\n    legend.position = c(\"right\", \"bottom\"),         # Position the legend on the right\n    panel.label.size = 1.333,                         # Adjust the size of the year labels\n    legend.title.size = .666,                        # Customize the size of the legend title\n    legend.text.size = .666                          # Customize the size of the legend text\n  )\n\n\n\n\n\n\n\n\n\nCode\ntm_shape(suspected_offences_sf_by_province_year) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"Blues\",       # Use a blue color palette similar to the image\n    style = \"log10\",      # Adjust based on the distribution of your data\n    n = 5,                   # Define number of bins for colors\n    title = \"Suspected Drug uses\"\n  ) +\n  tm_borders() +\n  tm_facets(by = \"fiscal_year\", nrow = 2, ncol = 3) +  # Facet by year, 2 rows and 3 columns\n  tm_layout(\n    title = \"Suspected Drug uses by year\",               # Title for the entire plot\n    legend.position = c(\"right\", \"bottom\"),         # Position the legend on the right\n    panel.label.size = 1.333,                         # Adjust the size of the year labels\n    legend.title.size = .666,                        # Customize the size of the legend title\n    legend.text.size = .666                          # Customize the size of the legend text\n  )\n\n\n\n\n\n\n\n\n\n\n\nJenks\n\n#| code-fold: true\n\ntm_shape(offences_sf_by_province_year) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"Blues\",       # Use a blue color palette similar to the image\n    style = \"jenks\",      # Adjust based on the distribution of your data\n    n = 5,                   # Define number of bins for colors\n    title = \"Drug use cases\"\n  ) +\n  tm_borders() +\n  tm_facets(by = \"fiscal_year\", nrow = 2, ncol = 3) +  # Facet by year, 2 rows and 3 columns\n  tm_layout(\n    title = \"Drug use cases by year\",               # Title for the entire plot\n    legend.position = c(\"right\", \"bottom\"),         # Position the legend on the right\n    panel.label.size = 1.333,                         # Adjust the size of the year labels\n    legend.title.size = .666,                        # Customize the size of the legend title\n    legend.text.size = .666                          # Customize the size of the legend text\n  )\n\n\n\n\n\n\n\ntm_shape(suspected_offences_sf_by_province_year) +\n  tm_fill(\n    col = \"total_cases\",\n    palette = \"Blues\",       # Use a blue color palette similar to the image\n    style = \"jenks\",      # Adjust based on the distribution of your data\n    n = 5,                   # Define number of bins for colors\n    title = \"Suspected Drug uses\"\n  ) +\n  tm_borders() +\n  tm_facets(by = \"fiscal_year\", nrow = 2, ncol = 3) +  # Facet by year, 2 rows and 3 columns\n  tm_layout(\n    title = \"Suspected Drug uses by year\",               # Title for the entire plot\n    legend.position = c(\"right\", \"bottom\"),         # Position the legend on the right\n    panel.label.size = 1.333,                         # Adjust the size of the year labels\n    legend.title.size = .666,                        # Customize the size of the legend title\n    legend.text.size = .666                          # Customize the size of the legend text\n  )\n\n\n\n\n\n\n\n\n\nJenks has better contrast between hot and cold spots overall compared to the logarithmic method"
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#global-morans-i-with-permutation-testing",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#global-morans-i-with-permutation-testing",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Global Moran’s I with permutation testing",
    "text": "Global Moran’s I with permutation testing\n\ndrug_usepossessionpossession_with_intent_to_distributetraffickingproductionimportexportconspiracy\n\n\n\n\nCode\ndrug_use_cases &lt;- drug_use %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    drug_use_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n\n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.0822\"\n\n\n[1] \"2018 statistic: 0.0952\"\n\n\n[1] \"2019 statistic: 0.141\"\n\n\n[1] \"2020 statistic: -0.0227\"\n\n\n[1] \"2021 statistic: 0.1816\"\n\n\n[1] \"2022 statistic: -0.0744\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2020 and 2022, the observed Moran’s I is positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\npossession_cases &lt;- possession %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    possession_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.3132\"\n\n\n[1] \"2018 statistic: 0.2765\"\n\n\n[1] \"2019 statistic: 0.3724\"\n\n\n[1] \"2020 statistic: 0.3694\"\n\n\n[1] \"2021 statistic: 0.1969\"\n\n\n[1] \"2022 statistic: -0.0827\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2022, the observed Moran’s I is greatly positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests strong clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\npossession_with_intent_to_distribute_cases &lt;- possession_with_intent_to_distribute %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.1581\"\n\n\n[1] \"2018 statistic: 0.1801\"\n\n\n[1] \"2019 statistic: 0.163\"\n\n\n[1] \"2020 statistic: 0.1161\"\n\n\n[1] \"2021 statistic: 0.1722\"\n\n\n[1] \"2022 statistic: -0.0264\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2022, the observed Moran’s I is greatly positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests strong clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\ntrafficking_cases &lt;- trafficking %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    trafficking_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.123\"\n\n\n[1] \"2018 statistic: 0.1232\"\n\n\n[1] \"2019 statistic: 0.1876\"\n\n\n[1] \"2020 statistic: 0.0776\"\n\n\n[1] \"2021 statistic: 0.0597\"\n\n\n[1] \"2022 statistic: -0.064\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2022, the observed Moran’s I is positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\nproduction_cases &lt;- production %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    production_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.5561\"\n\n\n[1] \"2018 statistic: 0.51\"\n\n\n[1] \"2019 statistic: 0.3899\"\n\n\n[1] \"2020 statistic: 0.2683\"\n\n\n[1] \"2021 statistic: 0.421\"\n\n\n[1] \"2022 statistic: 0.0211\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2022, the observed Moran’s I is greatly positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests strong clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\nimport_cases &lt;- import %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    import_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.2107\"\n\n\n[1] \"2018 statistic: 0.2143\"\n\n\n[1] \"2019 statistic: 0.1895\"\n\n\n[1] \"2020 statistic: 0.1309\"\n\n\n[1] \"2021 statistic: 0.0972\"\n\n\n[1] \"2022 statistic: -0.0598\"\n\n\n\n\n\n\n\n\n\nWith the exception of 2022, the observed Moran’s I is greatly positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests strong clustering, meaning areas with high cases tend to be near other areas with high cases.\n\n\n\n\nCode\nexport_cases &lt;- export %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  mi_perm &lt;- global_moran_perm(\n    export_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n  \n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: -0.0502\"\n\n\n[1] \"2018 statistic: 0.0076\"\n\n\n[1] \"2019 statistic: 0.0792\"\n\n\n[1] \"2020 statistic: -0.0668\"\n\n\n[1] \"2021 statistic: -0.071\"\n\n\n[1] \"2022 statistic: -0.0208\"\n\n\n\n\n\n\n\n\n\nThis had an unusual pattern compared to the rest. With the exception of 2018 and 2019, the observed Moran’s I is negative and smaller than the most of the Moran’s I values in the simulated distribution, which suggests a more dispersed, checkerboard spatial pattern, where high and low number of cases alternate spatially.\n\n\n\nHad to account for the years with 0 cases\n\n\n\nCode\nconspiracy_cases &lt;- conspiracy %&gt;% dplyr::select(1,3)\n\npar(mfrow=c(2,3))\nfor (year in yr){\n  cases = conspiracy_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2)\n  mi_perm &lt;- global_moran_perm(\n    # x = integer(nrow(wm_q)),\n    cases,\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  # debugging\n  # print(year)\n  # print(cases)\n\n  # checks if the year's vector has no_case = 0\n  if (sum(cases)==0) {\n    message(paste(\"Skipping year\", year, \"due to empty data (0 cases)\"))\n    next  # continue to next iteration\n  }\n  \n  print(paste(year, \"statistic:\",round(mi_perm$statistic,4)))\n\n  hist(mi_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Moran's I\"), main=paste(\"Histogram for\", year))\n  abline(v=mi_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.1216\"\n\n\n[1] \"2018 statistic: 0.207\"\n\n\n[1] \"2019 statistic: 0.0162\"\n\n\n[1] \"2020 statistic: 0.0168\"\n\n\nSkipping year 2021 due to empty data (0 cases)\n\n\nSkipping year 2022 due to empty data (0 cases)\n\n\n\n\n\n\n\n\n\nThe observed Moran’s I is positive and significantly larger than the most of the Moran’s I values in the simulated distribution, which suggests clustering, meaning areas with high cases tend to be near other areas with high cases."
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#gearys-c",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#gearys-c",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Geary’s C",
    "text": "Geary’s C\n\ndrug_usepossessionpossession_with_intent_to_distributetraffickingproductionimportexportconspiracy\n\n\n\n\nCode\nset.seed(69)\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    drug_use_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 1.0258\"\n\n\n[1] \"2018 statistic: 1.0037\"\n\n\n[1] \"2019 statistic: 0.9167\"\n\n\n[1] \"2020 statistic: 1.14\"\n\n\n[1] \"2021 statistic: 0.7809\"\n\n\n[1] \"2022 statistic: 1.0367\"\n\n\n\n\n\n\n\n\n\nC &lt; 1 for 2019, 2021: stronger positive spatial autocorrelation (cases of similar values group together spatially)\nC ~ 1 for 2017, 2018: no significant spatial autocorrelation (case values are randomly distributed spatially)\nC &gt; 1 for 2020, 2022: stronger negative spatial autocorrelation (cases of dissimilar values group together spatially)\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    possession_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.7603\"\n\n\n[1] \"2018 statistic: 0.8117\"\n\n\n[1] \"2019 statistic: 0.6932\"\n\n\n[1] \"2020 statistic: 0.7879\"\n\n\n[1] \"2021 statistic: 0.7613\"\n\n\n[1] \"2022 statistic: 1.0432\"\n\n\n\n\n\n\n\n\n\nC &lt; 1 for 2017, 2018, 2019, 2020, 2021: stronger positive spatial autocorrelation (cases of similar values group together spatially)\nC &gt; 1 for 2022: stronger negative spatial autocorrelation (cases of dissimilar values group together spatially)\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.9771\"\n\n\n[1] \"2018 statistic: 0.9372\"\n\n\n[1] \"2019 statistic: 0.9403\"\n\n\n[1] \"2020 statistic: 1.0417\"\n\n\n[1] \"2021 statistic: 0.7518\"\n\n\n[1] \"2022 statistic: 1.0646\"\n\n\n\n\n\n\n\n\n\nSame pattern as drug_use\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    trafficking_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.9121\"\n\n\n[1] \"2018 statistic: 0.8823\"\n\n\n[1] \"2019 statistic: 0.7766\"\n\n\n[1] \"2020 statistic: 0.9155\"\n\n\n[1] \"2021 statistic: 0.8283\"\n\n\n[1] \"2022 statistic: 1.0195\"\n\n\n\n\n\n\n\n\n\nSame pattern as possession\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    production_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.5471\"\n\n\n[1] \"2018 statistic: 0.5773\"\n\n\n[1] \"2019 statistic: 0.6932\"\n\n\n[1] \"2020 statistic: 0.7544\"\n\n\n[1] \"2021 statistic: 0.5693\"\n\n\n[1] \"2022 statistic: 0.9292\"\n\n\n\n\n\n\n\n\n\nC &lt; 1 for all years: strong positive spatial autocorrelation (cases of similar values group together spatially)\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    import_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.9166\"\n\n\n[1] \"2018 statistic: 0.7272\"\n\n\n[1] \"2019 statistic: 0.939\"\n\n\n[1] \"2020 statistic: 1.0753\"\n\n\n[1] \"2021 statistic: 1.0812\"\n\n\n[1] \"2022 statistic: 1.0938\"\n\n\n\n\n\n\n\n\n\nC &lt; 1 for 2017 to 2019: stronger positive spatial autocorrelation (cases of similar values group together spatially)\nC &gt; 1 for 2020 to 2022: stronger negative spatial autocorrelation (cases of dissimilar values group together spatially)\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  gc_perm &lt;- global_c_perm(\n    export_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    nb,\n    wm_q$wt,\n    nsim = 99)\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n  \n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 1.0594\"\n\n\n[1] \"2018 statistic: 0.9383\"\n\n\n[1] \"2019 statistic: 0.6677\"\n\n\n[1] \"2020 statistic: 1.0626\"\n\n\n[1] \"2021 statistic: 0.9808\"\n\n\n[1] \"2022 statistic: 1.0983\"\n\n\n\n\n\n\n\n\n\nC &lt; 1 for 2018, 2019: stronger positive spatial autocorrelation (cases of similar values group together spatially)\nC ~ 1 for 2021: no significant spatial autocorrelation (case values are randomly distributed spatially)\nC &gt; 1 for 2017, 2020, 2022: stronger negative spatial autocorrelation (cases of dissimilar values group together spatially)\n\n\n\nHad to account for the years with 0 cases\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  cases = conspiracy_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2)\n  gc_perm &lt;- global_c_perm(\n    # x = integer(nrow(wm_q)),\n    cases,\n    nb,\n    wm_q$wt,\n    nsim = 99)\n  \n  # debugging\n  # print(year)\n  # print(cases)\n\n  # checks if the year's vector has no_case = 0\n  if (sum(cases)==0) {\n    message(paste(\"Skipping year\", year, \"due to empty data (0 cases)\"))\n    next  # continue to next iteration\n  }\n    \n  print(paste(year, \"statistic:\",round(gc_perm$statistic,4)))\n\n  hist(gc_perm$res, freq=TRUE, breaks=20, xlab=paste(\"Simulated Geary's C\"), main=paste(\"Histogram for\", year))\n  abline(v=gc_perm$statistic,col=\"red\")\n}\n\n\n[1] \"2017 statistic: 0.9139\"\n\n\n[1] \"2018 statistic: 0.852\"\n\n\n[1] \"2019 statistic: 1.1644\"\n\n\n[1] \"2020 statistic: 1.2466\"\n\n\nSkipping year 2021 due to empty data (0 cases)\n\n\nSkipping year 2022 due to empty data (0 cases)\n\n\n\n\n\n\n\n\n\nC &lt; 1 for 2017, 2018: stronger positive spatial autocorrelation (cases of similar values group together spatially)\nC &gt; 1 for 2019, 2020: stronger negative spatial autocorrelation (cases of dissimilar values group together spatially)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#spatial-correlogram",
    "href": "resources/Take-home_Ex/ex2/Take-home_Ex_2.html#spatial-correlogram",
    "title": "Take-Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\n\nMoran’s I\n\ndrug usepossessionpossession with intent to distributetraffickingproductionimportexportconspiracy\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    drug_use_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"drug_use_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77)  0.0821634  -0.0131579  0.0036650           1.5745          0.1154\n2 (76)  0.0266710  -0.0133333  0.0022351           0.8462          0.3975\n3 (77) -0.0324661  -0.0131579  0.0017748          -0.4583          0.6467\n4 (77)  0.0156920  -0.0131579  0.0018770           0.6659          0.5055\n5 (77) -0.0599058  -0.0131579  0.0021004          -1.0200          0.3077\n6 (77) -0.0164010  -0.0131579  0.0029873          -0.0593          0.9527\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.0952025  -0.0131579  0.0039477           1.7246         0.08459 .\n2 (76)  0.0074005  -0.0133333  0.0024110           0.4223         0.67283  \n3 (77) -0.0114557  -0.0131579  0.0019106           0.0389         0.96894  \n4 (77)  0.0345456  -0.0131579  0.0020195           1.0615         0.28846  \n5 (77) -0.0693915  -0.0131579  0.0022563          -1.1839         0.23647  \n6 (77) -0.0250539  -0.0131579  0.0032047          -0.2101         0.83356  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.1410203  -0.0131579  0.0050350           2.1728         0.02979 *\n2 (76) -0.0225695  -0.0133333  0.0030875          -0.1662         0.86798  \n3 (77)  0.0020717  -0.0131579  0.0024333           0.3087         0.75752  \n4 (77)  0.0415944  -0.0131579  0.0025679           1.0805         0.27993  \n5 (77) -0.0673589  -0.0131579  0.0028562          -1.0142         0.31050  \n6 (77) -0.0191477  -0.0131579  0.0040411          -0.0942         0.92493  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77) -0.0226885  -0.0131579  0.0053015          -0.1309          0.8959\n2 (76) -0.0176267  -0.0133333  0.0032532          -0.0753          0.9400\n3 (77)  0.0331893  -0.0131579  0.0025614           0.9158          0.3598\n4 (77) -0.0046441  -0.0131579  0.0027023           0.1638          0.8699\n5 (77) -0.0085435  -0.0131579  0.0030032           0.0842          0.9329\n6 (77) -0.0809329  -0.0131579  0.0042461          -1.0401          0.2983\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1815510  -0.0131579  0.0057689           2.5635        0.010361 * \n2 (76)  0.0798288  -0.0133333  0.0035441           1.5649        0.117604   \n3 (77) -0.1156738  -0.0131579  0.0027860          -1.9422        0.052111 . \n4 (77)  0.1598054  -0.0131579  0.0029380           3.1910        0.001418 **\n5 (77) -0.1386056  -0.0131579  0.0032611          -2.1968        0.028038 * \n6 (77) -0.2031245  -0.0131579  0.0046057          -2.7992        0.005123 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77) -0.0743724  -0.0131579  0.0058364          -0.8013          0.4230\n2 (76) -0.0517227  -0.0133333  0.0035860          -0.6411          0.5215\n3 (77) -0.0823651  -0.0131579  0.0028185          -1.3036          0.1924\n4 (77)  0.0441815  -0.0131579  0.0029720           1.0518          0.2929\n5 (77)  0.0524637  -0.0131579  0.0032983           1.1426          0.2532\n6 (77) -0.0327280  -0.0131579  0.0046576          -0.2868          0.7743\n\n\n2017 - 2019, 2021: Significant Short-distance Positive Correlation (High Moran’s I values at low lags) suggests a clustered pattern; Significant Long-distance Negative Correlation (Negative Moran’s I values at larger distances) suggest that dissimilar values are found near each other\n2020, 2022: Correlogram is flat and close to zero across all distances, suggests no significant spatial autocorrelation at any lag, meaning that the spatial distribution of values is random\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    possession_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"possession_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.3132301  -0.0131579  0.0048723           4.6759       2.926e-06 ***\n2 (76)  0.1532018  -0.0133333  0.0029862           3.0475        0.002308 ** \n3 (77)  0.1007286  -0.0131579  0.0023551           2.3468        0.018937 *  \n4 (77)  0.0240663  -0.0131579  0.0024859           0.7466        0.455306    \n5 (77) -0.0206022  -0.0131579  0.0027664          -0.1415        0.887448    \n6 (77)  0.0213155  -0.0131579  0.0039160           0.5509        0.581710    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.2764915  -0.0131579  0.0045216           4.3075       1.651e-05 ***\n2 (76)  0.1290588  -0.0133333  0.0027681           2.7064        0.006801 ** \n3 (77)  0.0746536  -0.0131579  0.0021865           1.8779        0.060394 .  \n4 (77)  0.0410845  -0.0131579  0.0023090           1.1288        0.258972    \n5 (77) -0.0156378  -0.0131579  0.0025730          -0.0489        0.961007    \n6 (77)  0.0240339  -0.0131579  0.0036462           0.6159        0.537947    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.3723814  -0.0131579  0.0050578           5.4211       5.922e-08 ***\n2 (76)  0.1432547  -0.0133333  0.0031016           2.8117        0.004928 ** \n3 (77)  0.0722020  -0.0131579  0.0024442           1.7266        0.084245 .  \n4 (77)  0.0079637  -0.0131579  0.0025794           0.4159        0.677497    \n5 (77) -0.0386579  -0.0131579  0.0028687          -0.4761        0.634006    \n6 (77)  0.0104707  -0.0131579  0.0040586           0.3709        0.710717    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n          estimate expectation    variance standard deviate Pr(I) two sided    \n1 (77)  0.36942323 -0.01315789  0.00524894           5.2807       1.287e-07 ***\n2 (76)  0.10694259 -0.01333333  0.00322055           2.1194         0.03406 *  \n3 (77)  0.00081767 -0.01315789  0.00253611           0.2775         0.78139    \n4 (77)  0.00941161 -0.01315789  0.00267579           0.4363         0.66261    \n5 (77) -0.04853504 -0.01315789  0.00297422          -0.6487         0.51654    \n6 (77) -0.12691678 -0.01315789  0.00420568          -1.7542         0.07940 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.1969197  -0.0131579  0.0054673           2.8412        0.004495 ** \n2 (76)  0.2006583  -0.0133333  0.0033564           3.6937        0.000221 ***\n3 (77)  0.1348548  -0.0131579  0.0026410           2.8801        0.003975 ** \n4 (77)  0.3850645  -0.0131579  0.0027859           7.5447       4.532e-14 ***\n5 (77) -0.0169954  -0.0131579  0.0030947          -0.0690        0.945003    \n6 (77) -0.1341956  -0.0131579  0.0043736          -1.8302        0.067219 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77) -0.0827032  -0.0131579  0.0058006          -0.9131          0.3612\n2 (76) -0.0338451  -0.0133333  0.0035638          -0.3436          0.7312\n3 (77) -0.0774696  -0.0131579  0.0028013          -1.2151          0.2243\n4 (77)  0.0626648  -0.0131579  0.0029540           1.3951          0.1630\n5 (77) -0.0262732  -0.0131579  0.0032786          -0.2291          0.8188\n6 (77) -0.0190224  -0.0131579  0.0046300          -0.0862          0.9313\n\n\n2017 - 2021: Significant Short-distance Positive Correlation (High Moran’s I values at low lags) suggests a clustered pattern; Significant Long-distance Negative Correlation (Negative Moran’s I values at larger distances) suggest that dissimilar values are found near each other\n2022: Correlogram is flat and close to zero across all distances, suggests no significant spatial autocorrelation at any lag, meaning that the spatial distribution of values is random\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"possession_with_intent_to_distribute_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1580999  -0.0131579  0.0031630           3.0451        0.002326 **\n2 (76)  0.0162369  -0.0133333  0.0019227           0.6744        0.500080   \n3 (77) -0.0609857  -0.0131579  0.0015335          -1.2214        0.221951   \n4 (77) -0.0268098  -0.0131579  0.0016238          -0.3388        0.734771   \n5 (77) -0.0409738  -0.0131579  0.0018234          -0.6514        0.514781   \n6 (77) -0.0206921  -0.0131579  0.0026011          -0.1477        0.882559   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1801406  -0.0131579  0.0039007           3.0950        0.001968 **\n2 (76) -0.0022833  -0.0133333  0.0023817           0.2264        0.820873   \n3 (77) -0.0674658  -0.0131579  0.0018880          -1.2498        0.211356   \n4 (77) -0.0225452  -0.0131579  0.0019958          -0.2101        0.833571   \n5 (77) -0.0287503  -0.0131579  0.0022304          -0.3302        0.741279   \n6 (77) -0.0223764  -0.0131579  0.0031685          -0.1638        0.869913   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1630313  -0.0131579  0.0045084           2.6240         0.00869 **\n2 (76) -0.0506937  -0.0133333  0.0027598          -0.7112         0.47698   \n3 (77) -0.0808850  -0.0131579  0.0021802          -1.4505         0.14692   \n4 (77) -0.0283234  -0.0131579  0.0023023          -0.3161         0.75196   \n5 (77) -0.0015985  -0.0131579  0.0025657           0.2282         0.81948   \n6 (77) -0.0272291  -0.0131579  0.0036360          -0.2334         0.81549   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.1160863  -0.0131579  0.0051706           1.7974         0.07227 .\n2 (76)  0.0882911  -0.0133333  0.0031718           1.8045         0.07116 .\n3 (77)  0.0445712  -0.0131579  0.0024984           1.1549         0.24811  \n4 (77) -0.0176631  -0.0131579  0.0026363          -0.0877         0.93008  \n5 (77) -0.1050787  -0.0131579  0.0029310          -1.6979         0.08953 .\n6 (77) -0.1202366  -0.0131579  0.0041454          -1.6631         0.09629 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.1722358  -0.0131579  0.0058253           2.4290       0.0151390 *  \n2 (76)  0.0812325  -0.0133333  0.0035792           1.5807       0.1139518    \n3 (77) -0.0383423  -0.0131579  0.0028132          -0.4748       0.6349113    \n4 (77)  0.1874144  -0.0131579  0.0029665           3.6826       0.0002309 ***\n5 (77) -0.0765379  -0.0131579  0.0032922          -1.1046       0.2693299    \n6 (77) -0.1956846  -0.0131579  0.0046491          -2.6770       0.0074291 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77) -0.0264389  -0.0131579  0.0057183          -0.1756         0.86058  \n2 (76) -0.1012529  -0.0133333  0.0035126          -1.4835         0.13795  \n3 (77)  0.0149777  -0.0131579  0.0027617           0.5354         0.59238  \n4 (77) -0.0282964  -0.0131579  0.0029125          -0.2805         0.77909  \n5 (77)  0.0770946  -0.0131579  0.0032332           1.5872         0.11246  \n6 (77) -0.1370510  -0.0131579  0.0045667          -1.8333         0.06675 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor all years,\nSignificant Short-distance Positive Correlation (High Moran’s I values at low lags) suggests a clustered pattern; Significant Long-distance Negative Correlation (Negative Moran’s I values at larger distances) suggest that dissimilar values are found near each other.\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"possession_with_intent_to_distribute_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1580999  -0.0131579  0.0031630           3.0451        0.002326 **\n2 (76)  0.0162369  -0.0133333  0.0019227           0.6744        0.500080   \n3 (77) -0.0609857  -0.0131579  0.0015335          -1.2214        0.221951   \n4 (77) -0.0268098  -0.0131579  0.0016238          -0.3388        0.734771   \n5 (77) -0.0409738  -0.0131579  0.0018234          -0.6514        0.514781   \n6 (77) -0.0206921  -0.0131579  0.0026011          -0.1477        0.882559   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1801406  -0.0131579  0.0039007           3.0950        0.001968 **\n2 (76) -0.0022833  -0.0133333  0.0023817           0.2264        0.820873   \n3 (77) -0.0674658  -0.0131579  0.0018880          -1.2498        0.211356   \n4 (77) -0.0225452  -0.0131579  0.0019958          -0.2101        0.833571   \n5 (77) -0.0287503  -0.0131579  0.0022304          -0.3302        0.741279   \n6 (77) -0.0223764  -0.0131579  0.0031685          -0.1638        0.869913   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.1630313  -0.0131579  0.0045084           2.6240         0.00869 **\n2 (76) -0.0506937  -0.0133333  0.0027598          -0.7112         0.47698   \n3 (77) -0.0808850  -0.0131579  0.0021802          -1.4505         0.14692   \n4 (77) -0.0283234  -0.0131579  0.0023023          -0.3161         0.75196   \n5 (77) -0.0015985  -0.0131579  0.0025657           0.2282         0.81948   \n6 (77) -0.0272291  -0.0131579  0.0036360          -0.2334         0.81549   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.1160863  -0.0131579  0.0051706           1.7974         0.07227 .\n2 (76)  0.0882911  -0.0133333  0.0031718           1.8045         0.07116 .\n3 (77)  0.0445712  -0.0131579  0.0024984           1.1549         0.24811  \n4 (77) -0.0176631  -0.0131579  0.0026363          -0.0877         0.93008  \n5 (77) -0.1050787  -0.0131579  0.0029310          -1.6979         0.08953 .\n6 (77) -0.1202366  -0.0131579  0.0041454          -1.6631         0.09629 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.1722358  -0.0131579  0.0058253           2.4290       0.0151390 *  \n2 (76)  0.0812325  -0.0133333  0.0035792           1.5807       0.1139518    \n3 (77) -0.0383423  -0.0131579  0.0028132          -0.4748       0.6349113    \n4 (77)  0.1874144  -0.0131579  0.0029665           3.6826       0.0002309 ***\n5 (77) -0.0765379  -0.0131579  0.0032922          -1.1046       0.2693299    \n6 (77) -0.1956846  -0.0131579  0.0046491          -2.6770       0.0074291 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77) -0.0264389  -0.0131579  0.0057183          -0.1756         0.86058  \n2 (76) -0.1012529  -0.0133333  0.0035126          -1.4835         0.13795  \n3 (77)  0.0149777  -0.0131579  0.0027617           0.5354         0.59238  \n4 (77) -0.0282964  -0.0131579  0.0029125          -0.2805         0.77909  \n5 (77)  0.0770946  -0.0131579  0.0032332           1.5872         0.11246  \n6 (77) -0.1370510  -0.0131579  0.0045667          -1.8333         0.06675 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSimilar autocorrelation pattern and significance with possession with intent to distribute\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    production_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"production_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.5561174  -0.0131579  0.0043424           8.6388       &lt; 2.2e-16 ***\n2 (76)  0.3961935  -0.0133333  0.0026566           7.9455       1.934e-15 ***\n3 (77)  0.1971685  -0.0131579  0.0021004           4.5893       4.448e-06 ***\n4 (77)  0.0595033  -0.0131579  0.0022186           1.5426          0.1229    \n5 (77) -0.0104617  -0.0131579  0.0024741           0.0542          0.9568    \n6 (77) -0.0415630  -0.0131579  0.0035084          -0.4796          0.6315    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n          estimate expectation    variance standard deviate Pr(I) two sided    \n1 (77)  0.50997666 -0.01315789  0.00441889           7.8697       3.556e-15 ***\n2 (76)  0.39172438 -0.01333333  0.00270413           7.7894       6.734e-15 ***\n3 (77)  0.25346637 -0.01315789  0.00213714           5.7674       8.049e-09 ***\n4 (77)  0.09427400 -0.01315789  0.00225719           2.2613         0.02374 *  \n5 (77)  0.00030724 -0.01315789  0.00251628           0.2684         0.78837    \n6 (77) -0.03745034 -0.01315789  0.00356719          -0.4067         0.68420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.3899209  -0.0131579  0.0044361           6.0519       1.432e-09 ***\n2 (76)  0.2850221  -0.0133333  0.0027148           5.7261       1.027e-08 ***\n3 (77)  0.1984241  -0.0131579  0.0021454           4.5680       4.925e-06 ***\n4 (77)  0.0618549  -0.0131579  0.0022659           1.5759          0.1151    \n5 (77) -0.0154304  -0.0131579  0.0025258          -0.0452          0.9639    \n6 (77) -0.0249549  -0.0131579  0.0035804          -0.1972          0.8437    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.2682891  -0.0131579  0.0052346           3.8900       0.0001002 ***\n2 (76)  0.0013204  -0.0133333  0.0032116           0.2586       0.7959642    \n3 (77) -0.0204744  -0.0131579  0.0025292          -0.1455       0.8843295    \n4 (77)  0.0454432  -0.0131579  0.0026686           1.1344       0.2566257    \n5 (77) -0.0113841  -0.0131579  0.0029663           0.0326       0.9740187    \n6 (77) -0.1078964  -0.0131579  0.0041947          -1.4628       0.1435284    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.4209831  -0.0131579  0.0056304           5.7858       7.219e-09 ***\n2 (76)  0.1121723  -0.0133333  0.0034579           2.1343        0.032818 *  \n3 (77)  0.1273393  -0.0131579  0.0027195           2.6942        0.007056 ** \n4 (77)  0.2339539  -0.0131579  0.0028682           4.6141       3.947e-06 ***\n5 (77)  0.0081866  -0.0131579  0.0031847           0.3782        0.705262    \n6 (77) -0.1567977  -0.0131579  0.0044991          -2.1415        0.032237 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77)  0.0211452  -0.0131579  0.0055824           0.4591          0.6462\n2 (76) -0.0137077  -0.0133333  0.0034280          -0.0064          0.9949\n3 (77) -0.0180212  -0.0131579  0.0026964          -0.0937          0.9254\n4 (77)  0.0538960  -0.0131579  0.0028440           1.2574          0.2086\n5 (77) -0.0614679  -0.0131579  0.0031582          -0.8596          0.3900\n6 (77) -0.0792520  -0.0131579  0.0044622          -0.9894          0.3224\n\n\nSimilar autocorrelation pattern and significance with possession with intent to distribute\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    import_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"import_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.2107355  -0.0131579  0.0026864           4.3197       1.562e-05 ***\n2 (76)  0.0011857  -0.0133333  0.0016263           0.3600          0.7188    \n3 (77) -0.0034934  -0.0131579  0.0013044           0.2676          0.7890    \n4 (77) -0.0053145  -0.0131579  0.0013835           0.2109          0.8330    \n5 (77) -0.0113093  -0.0131579  0.0015605           0.0468          0.9627    \n6 (77) -0.0389332  -0.0131579  0.0022345          -0.5453          0.5856    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.2143448  -0.0131579  0.0039368           3.6259        0.000288 ***\n2 (76) -0.0310609  -0.0133333  0.0024042          -0.3615        0.717692    \n3 (77) -0.0441780  -0.0131579  0.0019054          -0.7106        0.477311    \n4 (77) -0.0190011  -0.0131579  0.0020141          -0.1302        0.896408    \n5 (77) -0.0206069  -0.0131579  0.0022503          -0.1570        0.875223    \n6 (77) -0.0518814  -0.0131579  0.0031964          -0.6849        0.493389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (77)  0.1895404  -0.0131579  0.0024799           4.0704       4.694e-05 ***\n2 (76) -0.0199501  -0.0133333  0.0014978          -0.1710          0.8642    \n3 (77) -0.0158861  -0.0131579  0.0012052          -0.0786          0.9374    \n4 (77) -0.0117500  -0.0131579  0.0012794           0.0394          0.9686    \n5 (77) -0.0187799  -0.0131579  0.0014465          -0.1478          0.8825    \n6 (77) -0.0295314  -0.0131579  0.0020757          -0.3594          0.7193    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.1308516  -0.0131579  0.0045347           2.1385         0.03247 *\n2 (76)  0.0945194  -0.0133333  0.0027762           2.0469         0.04066 *\n3 (77) -0.0244920  -0.0131579  0.0021928          -0.2420         0.80875  \n4 (77) -0.0512433  -0.0131579  0.0023156          -0.7915         0.42868  \n5 (77) -0.0751745  -0.0131579  0.0025802          -1.2209         0.22212  \n6 (77) -0.0700093  -0.0131579  0.0036563          -0.9402         0.34712  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.0971524  -0.0131579  0.0025827           2.1706         0.02996 *\n2 (76) -0.0466511  -0.0133333  0.0015617          -0.8431         0.39918  \n3 (77) -0.0267697  -0.0131579  0.0012546          -0.3843         0.70076  \n4 (77) -0.0227164  -0.0131579  0.0013312          -0.2620         0.79333  \n5 (77) -0.0268900  -0.0131579  0.0015032          -0.3542         0.72320  \n6 (77) -0.0342302  -0.0131579  0.0021547          -0.4540         0.64986  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77) -0.0597902  -0.0131579  0.0044985          -0.6953        0.486888   \n2 (76) -0.0388081  -0.0133333  0.0027537          -0.4855        0.627349   \n3 (77)  0.0398512  -0.0131579  0.0021754           1.1365        0.255737   \n4 (77)  0.1134260  -0.0131579  0.0022973           2.6410        0.008267 **\n5 (77) -0.0762542  -0.0131579  0.0025602          -1.2470        0.212398   \n6 (77) -0.1055464  -0.0131579  0.0036284          -1.5338        0.125088   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSimilar autocorrelation pattern and significance with possession with intent to distribute\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  MI_corr &lt;- sp.correlogram(\n    nb,\n    export_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"export_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77) -0.0501879  -0.0131579  0.0038920          -0.5936          0.5528  \n2 (76) -0.0318509  -0.0133333  0.0023763          -0.3799          0.7040  \n3 (77)  0.0157234  -0.0131579  0.0018839           0.6654          0.5058  \n4 (77)  0.0758895  -0.0131579  0.0019915           1.9954          0.0460 *\n5 (77) -0.0086340  -0.0131579  0.0022256           0.0959          0.9236  \n6 (77) -0.0545765  -0.0131579  0.0031619          -0.7366          0.4614  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.0076491  -0.0131579  0.0050189           0.2937         0.76899  \n2 (76)  0.0783952  -0.0133333  0.0030775           1.6535         0.09823 .\n3 (77) -0.0798739  -0.0131579  0.0024256          -1.3546         0.17553  \n4 (77) -0.0182770  -0.0131579  0.0025598          -0.1012         0.91941  \n5 (77) -0.0350293  -0.0131579  0.0028473          -0.4099         0.68189  \n6 (77) -0.0481676  -0.0131579  0.0040288          -0.5516         0.58124  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77)  0.0791753  -0.0131579  0.0046525           1.3537          0.1758\n2 (76)  0.0042422  -0.0133333  0.0028494           0.3293          0.7420\n3 (77) -0.0147440  -0.0131579  0.0022494          -0.0334          0.9733\n4 (77) -0.0504912  -0.0131579  0.0023750          -0.7661          0.4436\n5 (77) -0.0735313  -0.0131579  0.0026451          -1.1739          0.2404\n6 (77) -0.0146220  -0.0131579  0.0037469          -0.0239          0.9809\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77) -0.0667544  -0.0131579  0.0048971          -0.7659         0.44374  \n2 (76) -0.0863345  -0.0133333  0.0030016          -1.3324         0.18271  \n3 (77)  0.0999080  -0.0131579  0.0023670           2.3240         0.02013 *\n4 (77) -0.0671379  -0.0131579  0.0024984          -1.0800         0.28016  \n5 (77) -0.0142748  -0.0131579  0.0027801          -0.0212         0.98310  \n6 (77) -0.0102655  -0.0131579  0.0039350           0.0461         0.96322  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (77) -0.0710458  -0.0131579  0.0053430          -0.7919          0.4284\n2 (76) -0.0029742  -0.0133333  0.0032791           0.1809          0.8564\n3 (77)  0.0418536  -0.0131579  0.0025813           1.0828          0.2789\n4 (77) -0.0747826  -0.0131579  0.0027232          -1.1809          0.2376\n5 (77)  0.0223828  -0.0131579  0.0030261           0.6461          0.5182\n6 (77) -0.0669589  -0.0131579  0.0042780          -0.8226          0.4108\n\n\n\n\n\n\n\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Moran's I\n          estimate expectation    variance standard deviate Pr(I) two sided  \n1 (77) -0.02081516 -0.01315789  0.00141145          -0.2038         0.83850  \n2 (76) -0.00261891 -0.01333333  0.00083303           0.3712         0.71047  \n3 (77) -0.02002237 -0.01315789  0.00069160          -0.2610         0.79407  \n4 (77) -0.03192043 -0.01315789  0.00074052          -0.6895         0.49052  \n5 (77) -0.02633163 -0.01315789  0.00085706          -0.4500         0.65272  \n6 (77) -0.09223381 -0.01315789  0.00125380          -2.2332         0.02553 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor most of the years, correlogram is flat and close to zero across all distances, suggests no significant spatial autocorrelation at any lag, meaning that the spatial distribution of values is random.\n\n\nRemember to handle the years with no cases\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  cases = conspiracy_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2)\n  \n    # checks if the year's vector has no_case = 0\n  if (sum(cases)==0) {\n    message(paste(\"Skipping year\", year, \"due to empty data (0 cases)\"))\n    next  # continue to next iteration\n  }\n  \n  MI_corr &lt;- sp.correlogram(\n    nb,\n    cases,\n    order = 6,\n    method=\"I\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(MI_corr, main = paste(year, \"conspiracy_cases\"))\n  print(MI_corr)}\n\n\nSpatial correlogram for cases \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.1215807  -0.0131579  0.0053259           1.8463         0.06485 .\n2 (76)  0.0230655  -0.0133333  0.0032685           0.6367         0.52434  \n3 (77) -0.1276333  -0.0131579  0.0025731          -2.2567         0.02402 *\n4 (77) -0.0060479  -0.0131579  0.0027146           0.1365         0.89145  \n5 (77) -0.0143282  -0.0131579  0.0030167          -0.0213         0.98300  \n6 (77) -0.1098682  -0.0131579  0.0042649          -1.4809         0.13864  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for cases \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided   \n1 (77)  0.2070047  -0.0131579  0.0045987           3.2466        0.001168 **\n2 (76) -0.0436656  -0.0133333  0.0028160          -0.5716        0.567595   \n3 (77) -0.0333358  -0.0131579  0.0022236          -0.4279        0.668717   \n4 (77) -0.0206808  -0.0131579  0.0023479          -0.1553        0.876619   \n5 (77) -0.0504201  -0.0131579  0.0026155          -0.7286        0.466242   \n6 (77) -0.0550177  -0.0131579  0.0037055          -0.6877        0.491666   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for cases \nmethod: Moran's I\n          estimate expectation    variance standard deviate Pr(I) two sided\n1 (77)  0.01621459 -0.01315789  0.00106794           0.8988          0.3688\n2 (76)  0.00978584 -0.01333333  0.00061931           0.9290          0.3529\n3 (77) -0.01255721 -0.01315789  0.00052649           0.0262          0.9791\n4 (77) -0.01883223 -0.01315789  0.00056728          -0.2382          0.8117\n5 (77) -0.02896492 -0.01315789  0.00066755          -0.6118          0.5407\n6 (77) -0.02738208 -0.01315789  0.00098956          -0.4522          0.6511\n\n\nSpatial correlogram for cases \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided  \n1 (77)  0.0168143  -0.0131579  0.0046729           0.4385         0.66106  \n2 (76)  0.0838190  -0.0133333  0.0028622           1.8160         0.06938 .\n3 (77) -0.0582069  -0.0131579  0.0022592          -0.9478         0.34324  \n4 (77) -0.0208558  -0.0131579  0.0023853          -0.1576         0.87476  \n5 (77) -0.0338693  -0.0131579  0.0026564          -0.4018         0.68780  \n6 (77) -0.0481529  -0.0131579  0.0037626          -0.5705         0.56833  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSkipping year 2021 due to empty data (0 cases)\n\n\nSkipping year 2022 due to empty data (0 cases)\n\n\n\n\n\n\n\n\n\nSimilar autocorrelation pattern and significance with possession with intent to distribute\n\n\n\n\n\nGeary’s C\n\ndrug usepossessionpossession with intent to distributetraffickingproductionimportexportconspiracy\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    drug_use_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"drug_use_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 1.025845    1.000000 0.020655           0.1798          0.8573\n2 (76) 1.007516    1.000000 0.015434           0.0605          0.9518\n3 (77) 0.957695    1.000000 0.017516          -0.3197          0.7492\n4 (77) 0.941691    1.000000 0.026950          -0.3552          0.7224\n5 (77) 1.096812    1.000000 0.056515           0.4072          0.6838\n6 (77) 0.992459    1.000000 0.112669          -0.0225          0.9821\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 1.003652    1.000000 0.018924           0.0265          0.9788\n2 (76) 1.032794    1.000000 0.014041           0.2768          0.7820\n3 (77) 0.943228    1.000000 0.015794          -0.4517          0.6515\n4 (77) 0.920995    1.000000 0.024139          -0.5085          0.6111\n5 (77) 1.095522    1.000000 0.050271           0.4260          0.6701\n6 (77) 1.006909    1.000000 0.099991           0.0219          0.9826\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9166967   1.0000000 0.0122647          -0.7522          0.4519\n2 (76) 1.0306111   1.0000000 0.0086813           0.3285          0.7425\n3 (77) 0.9385333   1.0000000 0.0091712          -0.6418          0.5210\n4 (77) 0.9063930   1.0000000 0.0133234          -0.8110          0.4174\n5 (77) 1.0746359   1.0000000 0.0262469           0.4607          0.6450\n6 (77) 1.0121803   1.0000000 0.0512189           0.0538          0.9571\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 1.1399926   1.0000000 0.0106329           1.3576          0.1746\n2 (76) 1.0289152   1.0000000 0.0073678           0.3369          0.7362\n3 (77) 0.9905066   1.0000000 0.0075482          -0.1093          0.9130\n4 (77) 1.0570936   1.0000000 0.0106732           0.5526          0.5805\n5 (77) 1.0262406   1.0000000 0.0203599           0.1839          0.8541\n6 (77) 1.2054465   1.0000000 0.0392674           1.0368          0.2998\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided   \n1 (77) 0.7808514   1.0000000 0.0077702          -2.4861        0.012914 * \n2 (76) 0.8945700   1.0000000 0.0050636          -1.4816        0.138444   \n3 (77) 1.0781699   1.0000000 0.0047010           1.1401        0.254243   \n4 (77) 0.8332144   1.0000000 0.0060238          -2.1489        0.031640 * \n5 (77) 1.1066271   1.0000000 0.0100322           1.0646        0.287076   \n6 (77) 1.4450022   1.0000000 0.0183006           3.2895        0.001004 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for drug_use_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided   \n1 (77) 1.0366729   1.0000000 0.0073570           0.4276        0.668972   \n2 (76) 1.0461574   1.0000000 0.0047310           0.6711        0.502179   \n3 (77) 1.0890895   1.0000000 0.0042900           1.3602        0.173772   \n4 (77) 1.0654429   1.0000000 0.0053527           0.8945        0.371059   \n5 (77) 1.1431019   1.0000000 0.0085414           1.5484        0.121527   \n6 (77) 1.3389397   1.0000000 0.0152739           2.7425        0.006097 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    possession_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"possession_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.7603383   1.0000000 0.0132611          -2.0812         0.03742 *\n2 (76) 0.8662146   1.0000000 0.0094833          -1.3738         0.16950  \n3 (77) 0.8193554   1.0000000 0.0101622          -1.7920         0.07314 .\n4 (77) 0.8402066   1.0000000 0.0149417          -1.3072         0.19113  \n5 (77) 0.9030045   1.0000000 0.0298417          -0.5615         0.57447  \n6 (77) 0.8588501   1.0000000 0.0585169          -0.5835         0.55956  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 0.811681    1.000000 0.015409          -1.5171          0.1292\n2 (76) 0.902420    1.000000 0.011212          -0.9216          0.3568\n3 (77) 0.853329    1.000000 0.012298          -1.3226          0.1860\n4 (77) 0.856354    1.000000 0.018430          -1.0581          0.2900\n5 (77) 0.936246    1.000000 0.037589          -0.3288          0.7423\n6 (77) 0.868239    1.000000 0.074246          -0.4836          0.6287\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided   \n1 (77) 0.6932033   1.0000000 0.0121255          -2.7861        0.005334 **\n2 (76) 0.9142878   1.0000000 0.0085692          -0.9259        0.354490   \n3 (77) 0.8628823   1.0000000 0.0090327          -1.4427        0.149098   \n4 (77) 0.8724798   1.0000000 0.0130973          -1.1143        0.265166   \n5 (77) 0.9476489   1.0000000 0.0257447          -0.3263        0.744217   \n6 (77) 0.8866702   1.0000000 0.0501994          -0.5058        0.612984   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.7879428   1.0000000 0.0109546          -2.0261         0.04276 *\n2 (76) 0.9204468   1.0000000 0.0076268          -0.9109         0.36233  \n3 (77) 0.9784123   1.0000000 0.0078682          -0.2434         0.80772  \n4 (77) 0.9720050   1.0000000 0.0111957          -0.2646         0.79133  \n5 (77) 0.9995664   1.0000000 0.0215205          -0.0030         0.99764  \n6 (77) 1.0162565   1.0000000 0.0416236           0.0797         0.93649  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (77) 0.7612748   1.0000000 0.0096176          -2.4343        0.014923 *  \n2 (76) 0.7511029   1.0000000 0.0065506          -3.0752        0.002103 ** \n3 (77) 0.8657770   1.0000000 0.0065384          -1.6599        0.096927 .  \n4 (77) 0.6194235   1.0000000 0.0090242          -4.0062       6.169e-05 ***\n5 (77) 0.8773414   1.0000000 0.0166970          -0.9492        0.342495    \n6 (77) 1.3032569   1.0000000 0.0318311           1.6998        0.089178 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for possession_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 1.0431955   1.0000000 0.0075762           0.4963          0.6197\n2 (76) 0.9989580   1.0000000 0.0049074          -0.0149          0.9881\n3 (77) 1.0822602   1.0000000 0.0045080           1.2252          0.2205\n4 (77) 0.9795580   1.0000000 0.0057087          -0.2706          0.7867\n5 (77) 1.0536915   1.0000000 0.0093322           0.5558          0.5784\n6 (77) 1.1035071   1.0000000 0.0168794           0.7967          0.4256\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"possession_with_intent_to_distribute_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 0.977063    1.000000 0.023729          -0.1489          0.8816\n2 (76) 1.067462    1.000000 0.017909           0.5041          0.6142\n3 (77) 0.995481    1.000000 0.020574          -0.0315          0.9749\n4 (77) 0.983634    1.000000 0.031944          -0.0916          0.9270\n5 (77) 1.059173    1.000000 0.067608           0.2276          0.8200\n6 (77) 0.947804    1.000000 0.135189          -0.1420          0.8871\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 0.937178    1.000000 0.019212          -0.4532          0.6504\n2 (76) 1.072144    1.000000 0.014273           0.6039          0.5459\n3 (77) 1.008058    1.000000 0.016081           0.0635          0.9493\n4 (77) 0.980108    1.000000 0.024606          -0.1268          0.8991\n5 (77) 1.043606    1.000000 0.051310           0.1925          0.8473\n6 (77) 0.958147    1.000000 0.102100          -0.1310          0.8958\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 0.940253    1.000000 0.015490          -0.4801          0.6312\n2 (76) 1.114501    1.000000 0.011277           1.0782          0.2809\n3 (77) 1.032378    1.000000 0.012379           0.2910          0.7710\n4 (77) 0.990147    1.000000 0.018561          -0.0723          0.9423\n5 (77) 1.006700    1.000000 0.037882           0.0344          0.9725\n6 (77) 0.951949    1.000000 0.074840          -0.1756          0.8606\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 1.0417446   1.0000000 0.0114345           0.3904          0.6963\n2 (76) 0.9721116   1.0000000 0.0080131          -0.3115          0.7554\n3 (77) 0.9516943   1.0000000 0.0083455          -0.5288          0.5970\n4 (77) 1.0018557   1.0000000 0.0119751           0.0170          0.9865\n5 (77) 1.0267890   1.0000000 0.0232519           0.1757          0.8605\n6 (77) 1.0309239   1.0000000 0.0451386           0.1456          0.8843\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided   \n1 (77) 0.7518440   1.0000000 0.0074246          -2.8800        0.003977 **\n2 (76) 0.8756346   1.0000000 0.0047855          -1.7978        0.072211 . \n3 (77) 0.9848215   1.0000000 0.0043573          -0.2299        0.818136   \n4 (77) 0.7836293   1.0000000 0.0054626          -2.9275        0.003417 **\n5 (77) 1.0235045   1.0000000 0.0087855           0.2508        0.801995   \n6 (77) 1.2763997   1.0000000 0.0157695           2.2010        0.027733 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for possession_with_intent_to_distribute_cases %&gt;% filter(fiscal_year ==      year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 1.0646334   1.0000000 0.0080802           0.7190         0.47212  \n2 (76) 1.1600256   1.0000000 0.0053131           2.1954         0.02813 *\n3 (77) 1.0396696   1.0000000 0.0050093           0.5605         0.57515  \n4 (77) 1.0436376   1.0000000 0.0065273           0.5401         0.58911  \n5 (77) 0.8659941   1.0000000 0.0111506          -1.2690         0.20443  \n6 (77) 1.0936620   1.0000000 0.0205711           0.6530         0.51374  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    trafficking_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"trafficking_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9121279   1.0000000 0.0112647          -0.8279          0.4077\n2 (76) 1.0134923   1.0000000 0.0078764           0.1520          0.8792\n3 (77) 0.8683637   1.0000000 0.0081767          -1.4558          0.1455\n4 (77) 0.9022347   1.0000000 0.0116994          -0.9039          0.3661\n5 (77) 1.0946627   1.0000000 0.0226395           0.6291          0.5293\n6 (77) 0.9552492   1.0000000 0.0438952          -0.2136          0.8309\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.8823127   1.0000000 0.0082248          -1.2977          0.1944\n2 (76) 0.9758939   1.0000000 0.0054295          -0.3271          0.7436\n3 (77) 0.8911844   1.0000000 0.0051532          -1.5158          0.1296\n4 (77) 0.9495700   1.0000000 0.0067622          -0.6133          0.5397\n5 (77) 1.1313537   1.0000000 0.0116723           1.2158          0.2241\n6 (77) 0.9170223   1.0000000 0.0216301          -0.5642          0.5726\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.7765561   1.0000000 0.0123205          -2.0130         0.04411 *\n2 (76) 0.8453994   1.0000000 0.0087262          -1.6550         0.09792 .\n3 (77) 0.7813954   1.0000000 0.0092267          -2.2758         0.02286 *\n4 (77) 0.8775559   1.0000000 0.0134141          -1.0572         0.29042  \n5 (77) 1.0678267   1.0000000 0.0264484           0.4171         0.67663  \n6 (77) 1.0655954   1.0000000 0.0516280           0.2887         0.77282  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.9155115   1.0000000 0.0128276          -0.7460         0.45568  \n2 (76) 0.8270832   1.0000000 0.0091344          -1.8092         0.07041 .\n3 (77) 0.8220777   1.0000000 0.0097311          -1.8036         0.07129 .\n4 (77) 0.7689026   1.0000000 0.0142377          -1.9368         0.05278 .\n5 (77) 0.8165201   1.0000000 0.0282780          -1.0911         0.27523  \n6 (77) 0.7470304   1.0000000 0.0553423          -1.0753         0.28223  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.8283227   1.0000000 0.0128718          -1.5132         0.13023  \n2 (76) 0.8886772   1.0000000 0.0091700          -1.1625         0.24503  \n3 (77) 0.8619619   1.0000000 0.0097751          -1.3962         0.16266  \n4 (77) 0.7763758   1.0000000 0.0143095          -1.8694         0.06156 .\n5 (77) 0.9392638   1.0000000 0.0284374          -0.3602         0.71872  \n6 (77) 1.2151645   1.0000000 0.0556659           0.9120         0.36179  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for trafficking_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 1.0195273   1.0000000 0.0090885           0.2048         0.83770  \n2 (76) 1.1141181   1.0000000 0.0061247           1.4582         0.14479  \n3 (77) 1.1090360   1.0000000 0.0060122           1.4062         0.15966  \n4 (77) 0.9343341   1.0000000 0.0081649          -0.7267         0.46740  \n5 (77) 0.7925758   1.0000000 0.0147882          -1.7057         0.08806 .\n6 (77) 0.9682140   1.0000000 0.0279560          -0.1901         0.84923  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    production_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"production_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided    \n1 (77) 0.547079    1.000000 0.016506          -3.5253       0.0004229 ***\n2 (76) 0.830325    1.000000 0.012095          -1.5428       0.1228777    \n3 (77) 0.749610    1.000000 0.013390          -2.1639       0.0304740 *  \n4 (77) 0.587882    1.000000 0.020212          -2.8988       0.0037460 ** \n5 (77) 0.639593    1.000000 0.041549          -1.7681       0.0770384 .  \n6 (77) 0.780957    1.000000 0.082284          -0.7636       0.4450994    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided    \n1 (77) 0.577316    1.000000 0.016038          -3.3377       0.0008449 ***\n2 (76) 0.785412    1.000000 0.011718          -1.9823       0.0474453 *  \n3 (77) 0.686025    1.000000 0.012924          -2.7618       0.0057479 ** \n4 (77) 0.555840    1.000000 0.019452          -3.1847       0.0014493 ** \n5 (77) 0.631699    1.000000 0.039860          -1.8447       0.0650747 .  \n6 (77) 0.778642    1.000000 0.078855          -0.7883       0.4305323    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided   \n1 (77) 0.693166    1.000000 0.015933          -2.4309        0.015063 * \n2 (76) 0.826324    1.000000 0.011634          -1.6102        0.107353   \n3 (77) 0.748382    1.000000 0.012819          -2.2223        0.026260 * \n4 (77) 0.604742    1.000000 0.019281          -2.8466        0.004419 **\n5 (77) 0.662805    1.000000 0.039480          -1.6971        0.089687 . \n6 (77) 0.792895    1.000000 0.078083          -0.7412        0.458597   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided  \n1 (77) 0.7544069   1.0000000 0.0110423          -2.3371         0.01943 *\n2 (76) 0.9101698   1.0000000 0.0076974          -1.0239         0.30589  \n3 (77) 0.9741034   1.0000000 0.0079555          -0.2903         0.77155  \n4 (77) 0.9322100   1.0000000 0.0113382          -0.6366         0.52436  \n5 (77) 1.0046266   1.0000000 0.0218372           0.0313         0.97502  \n6 (77) 0.9641394   1.0000000 0.0422664          -0.1744         0.86153  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (77) 0.5692587   1.0000000 0.0086183          -4.6399       3.486e-06 ***\n2 (76) 0.8192017   1.0000000 0.0057463          -2.3851         0.01708 *  \n3 (77) 0.8838705   1.0000000 0.0055445          -1.5596         0.11886    \n4 (77) 0.8136249   1.0000000 0.0074013          -2.1664         0.03028 *  \n5 (77) 0.9229837   1.0000000 0.0130919          -0.6731         0.50088    \n6 (77) 1.3217895   1.0000000 0.0245122           2.0553         0.03985 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for production_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9291860   1.0000000 0.0089123          -0.7501          0.4532\n2 (76) 1.0196384   1.0000000 0.0059829           0.2539          0.7996\n3 (77) 0.9297275   1.0000000 0.0058370          -0.9198          0.3577\n4 (77) 0.8892738   1.0000000 0.0078788          -1.2474          0.2122\n5 (77) 1.0418370   1.0000000 0.0141526           0.3517          0.7251\n6 (77) 1.0584190   1.0000000 0.0266656           0.3577          0.7205\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    import_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"import_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 0.916624    1.000000 0.026648          -0.5108         0.60952  \n2 (76) 1.257868    1.000000 0.020258           1.8117         0.07003 .\n3 (77) 0.874629    1.000000 0.023477          -0.8182         0.41322  \n4 (77) 0.741813    1.000000 0.036683          -1.3480         0.17765  \n5 (77) 0.595490    1.000000 0.078137          -1.4471         0.14787  \n6 (77) 0.677256    1.000000 0.156563          -0.8157         0.41469  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 0.727231    1.000000 0.018990          -1.9794         0.04777 *\n2 (76) 1.088242    1.000000 0.014095           0.7433         0.45732  \n3 (77) 0.956848    1.000000 0.015860          -0.3426         0.73186  \n4 (77) 0.840919    1.000000 0.024246          -1.0216         0.30696  \n5 (77) 0.658409    1.000000 0.050510          -1.5199         0.12854  \n6 (77) 0.711559    1.000000 0.100478          -0.9100         0.36284  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 0.938956    1.000000 0.027912          -0.3654         0.71483  \n2 (76) 1.292537    1.000000 0.021276           2.0055         0.04491 *\n3 (77) 0.879547    1.000000 0.024734          -0.7659         0.44374  \n4 (77) 0.736212    1.000000 0.038737          -1.3403         0.18016  \n5 (77) 0.591165    1.000000 0.082700          -1.4217         0.15512  \n6 (77) 0.668998    1.000000 0.165827          -0.8128         0.41631  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 1.075297    1.000000 0.015328           0.6082          0.5431\n2 (76) 1.051441    1.000000 0.011147           0.4872          0.6261\n3 (77) 1.036754    1.000000 0.012218           0.3325          0.7395\n4 (77) 1.046771    1.000000 0.018299           0.3458          0.7295\n5 (77) 0.959159    1.000000 0.037300          -0.2115          0.8325\n6 (77) 0.936544    1.000000 0.073659          -0.2338          0.8151\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 1.081196    1.000000 0.027283           0.4916         0.62302  \n2 (76) 1.309788    1.000000 0.020770           2.1496         0.03159 *\n3 (77) 0.885670    1.000000 0.024109          -0.7363         0.46153  \n4 (77) 0.754552    1.000000 0.037715          -1.2639         0.20628  \n5 (77) 0.662688    1.000000 0.080429          -1.1894         0.23429  \n6 (77) 0.752906    1.000000 0.161217          -0.6154         0.53829  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\nSpatial correlogram for import_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 1.093830    1.000000 0.015550           0.7524         0.45178  \n2 (76) 0.963555    1.000000 0.011326          -0.3425         0.73201  \n3 (77) 1.024622    1.000000 0.012439           0.2208         0.82528  \n4 (77) 0.967850    1.000000 0.018660          -0.2354         0.81393  \n5 (77) 1.226193    1.000000 0.038100           1.1588         0.24653  \n6 (77) 1.648729    1.000000 0.075283           2.3644         0.01806 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  GC_corr &lt;- sp.correlogram(\n    nb,\n    export_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2),\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"export_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided   \n1 (77) 1.059393    1.000000 0.019265           0.4279          0.6687   \n2 (76) 0.960370    1.000000 0.014316          -0.3312          0.7405   \n3 (77) 1.021797    1.000000 0.016133           0.1716          0.8637   \n4 (77) 0.978973    1.000000 0.024692          -0.1338          0.8936   \n5 (77) 0.973676    1.000000 0.051500          -0.1160          0.9077   \n6 (77) 1.946839    1.000000 0.102487           2.9576          0.0031 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9382775   1.0000000 0.0123631          -0.5551          0.5788\n2 (76) 1.0007909   1.0000000 0.0087605           0.0084          0.9933\n3 (77) 1.0236243   1.0000000 0.0092691           0.2454          0.8062\n4 (77) 0.9199682   1.0000000 0.0134833          -0.6892          0.4907\n5 (77) 0.9497646   1.0000000 0.0266022          -0.3080          0.7581\n6 (77) 0.8831825   1.0000000 0.0519402          -0.5126          0.6082\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided    \n1 (77) 0.667707    1.000000 0.014607          -2.7494        0.005971 ** \n2 (76) 0.590160    1.000000 0.010567          -3.9869       6.694e-05 ***\n3 (77) 0.791347    1.000000 0.011501          -1.9456        0.051705 .  \n4 (77) 0.805151    1.000000 0.017128          -1.4888        0.136537    \n5 (77) 0.930226    1.000000 0.034699          -0.3746        0.707980    \n6 (77) 0.964470    1.000000 0.068378          -0.1359        0.891920    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 1.0626253   1.0000000 0.0131094           0.5470          0.5844\n2 (76) 1.0194888   1.0000000 0.0093612           0.2014          0.8404\n3 (77) 0.8977201   1.0000000 0.0100113          -1.0222          0.3067\n4 (77) 1.0221411   1.0000000 0.0146953           0.1826          0.8551\n5 (77) 0.9263348   1.0000000 0.0292944          -0.4304          0.6669\n6 (77) 0.8262667   1.0000000 0.0574057          -0.7251          0.4684\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9808435   1.0000000 0.0103786          -0.1880          0.8508\n2 (76) 1.0003824   1.0000000 0.0071631           0.0045          0.9964\n3 (77) 0.8762922   1.0000000 0.0072953          -1.4484          0.1475\n4 (77) 0.9750185   1.0000000 0.0102602          -0.2466          0.8052\n5 (77) 0.8527969   1.0000000 0.0194425          -1.0557          0.2911\n6 (77) 0.9438121   1.0000000 0.0374049          -0.2905          0.7714\n\n\n\n\n\n\n\n\n\nSpatial correlogram for export_cases %&gt;% filter(fiscal_year == year) %&gt;% dplyr::pull(2) \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided   \n1 (77) 1.098305    1.000000 0.034456           0.5296        0.596392   \n2 (76) 0.886452    1.000000 0.026543          -0.6970        0.485832   \n3 (77) 1.154979    1.000000 0.031243           0.8768        0.380596   \n4 (77) 1.292731    1.000000 0.049365           1.3175        0.187661   \n5 (77) 1.459443    1.000000 0.106306           1.4091        0.158796   \n6 (77) 2.192125    1.000000 0.213752           2.5785        0.009923 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nRemember to handle the years with no cases\n\n\nCode\npar(mfrow=c(2,3))\nfor (year in yr){\n  cases = conspiracy_cases %&gt;% filter(fiscal_year==year) %&gt;% dplyr::pull(2)\n  \n    # checks if the year's vector has no_case = 0\n  if (sum(cases)==0) {\n    message(paste(\"Skipping year\", year, \"due to empty data (0 cases)\"))\n    next  # continue to next iteration\n  }\n  \n  GC_corr &lt;- sp.correlogram(\n    nb,\n    cases,\n    order = 6,\n    method=\"C\", \n    style=\"W\",\n    zero.policy = TRUE) # handle Phuket, an isolated province\n  plot(GC_corr, main = paste(year, \"conspiracy_cases\"))\n  print(GC_corr)}\n\n\nSpatial correlogram for cases \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided\n1 (77) 0.9139050   1.0000000 0.0104830          -0.8409          0.4004\n2 (76) 0.9221307   1.0000000 0.0072472          -0.9147          0.3603\n3 (77) 1.1159238   1.0000000 0.0073991           1.3477          0.1778\n4 (77) 0.8985914   1.0000000 0.0104298          -0.9930          0.3207\n5 (77) 0.9031464   1.0000000 0.0198192          -0.6880          0.4915\n6 (77) 1.1275210   1.0000000 0.0381696           0.6527          0.5139\n\n\nSpatial correlogram for cases \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 0.851959    1.000000 0.014937          -1.2113          0.2258\n2 (76) 1.121384    1.000000 0.010832           1.1663          0.2435\n3 (77) 1.042988    1.000000 0.011829           0.3953          0.6927\n4 (77) 1.031040    1.000000 0.017663           0.2336          0.8153\n5 (77) 0.974864    1.000000 0.035887          -0.1327          0.8944\n6 (77) 0.882162    1.000000 0.070790          -0.4429          0.6578\n\n\nSpatial correlogram for cases \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (77) 1.164386    1.000000 0.036560           0.8597          0.3899\n2 (76) 1.089671    1.000000 0.028237           0.5336          0.5936\n3 (77) 0.951268    1.000000 0.033335          -0.2669          0.7895\n4 (77) 1.000735    1.000000 0.052781           0.0032          0.9974\n5 (77) 1.071845    1.000000 0.113896           0.2129          0.8314\n6 (77) 0.936610    1.000000 0.229160          -0.1324          0.8947\n\n\nSpatial correlogram for cases \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided  \n1 (77) 1.246554    1.000000 0.014482           2.0488         0.04048 *\n2 (76) 1.004436    1.000000 0.010466           0.0434         0.96542  \n3 (77) 1.075149    1.000000 0.011377           0.7046         0.48109  \n4 (77) 0.996022    1.000000 0.016925          -0.0306         0.97561  \n5 (77) 0.928111    1.000000 0.034248          -0.3885         0.69768  \n6 (77) 0.979559    1.000000 0.067461          -0.0787         0.93727  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSkipping year 2021 due to empty data (0 cases)\n\n\nSkipping year 2022 due to empty data (0 cases)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "I will be using armed conflict data of Myanmar from January 2021 to June 2024, aka Armed Conflict Location & Event Data (ACLED).\nAlong the way, I will be exploring the use of different functions to obtain more aesthetically pleasing outputs for fun, and documenting my findings and conclusion as and when needed."
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#packages",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#packages",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Packages",
    "text": "Packages\nThese R packages will be used:\n\nsf: importing, managing, and processing geospatial data, and\ntidyverse: performing data science tasks such as importing, wrangling and visualising data.\nreadr\n\nread_csv(): reading ACLED csv data\n\njanitor: data cleaning\nlubridate: date formatting\nsparr : Spatio-temporal analysis\nExtra (TBD):\n\njanitor: data cleaning\nskimr: provide summary statistics\nraster: raster()\nterra: writeRaster()\ngridExtra, patchwork: +ggplot2 for ease of control of grid output layout\ngganimate + gifski: animated STKDE output\n\n\n\npacman:::p_load(sf,tidyverse,sparr,spatstat,stpp,raster,terra,janitor,skimr,lubridate,tmap,gridExtra,patchwork,gganimate,gifski)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#acled",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#acled",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "ACLED",
    "text": "ACLED\n\nacled_sf &lt;- read_csv('data/2021-01-01-2024-07-01-Myanmar.csv')"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#metadata",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#metadata",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Metadata",
    "text": "Metadata\nClick to expand –&gt;\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\n‘event_id_cnty’\nunique alphanumeric ID by number & country acronym\n\n\n‘event_date’\nday-month-year of event\n\n\n‘year’\nself-explanatory\n\n\n‘time_precison’\nnumeric code for level of precison of data records\n\n\n‘disorder_type’\ni.e. ‘Demonstrations’,‘Political violence’,‘Political violence; Demonstrations’,‘Strategic developments’\n\n\n‘event_type’\nnature of event\n\n\n‘sub_event_type’\nprovides further classification to event_type\n\n\n‘actor1’\n‘assoc_actor_1’\n‘actor2’\n‘assoc_actor_2’\ninvolved actors along with their respective affiliates\n\n\n‘inter1’\n‘inter2’\nnumeric code between 0 and 8 encoding different actors\n\n\n\n‘interaction’\nindicates the 2 actor types interacting in the event (encoded inter1 & inter2 by concatenation)\n\n\n‘civilian_targeting’\nindicates whether the event involved civilian targeting (e.g. null if false)\n\nNote: no data format irregularity\n\n\n\n‘iso’\nunique 3-digit numeric code assigned to each country or territory according to ISO 3166\n\n\n‘region’\nregion of the world where the event took place\n\n\n‘country’\nself-explanatory\n\n\n‘admin1’\n‘admin2’\n‘admin3’\nnational administrative regions where the event took place (admin1 being the largest)\n\n\n‘location’\nself-explanatory\n\n\n‘latitude’\nself-explanatory\n\n\n‘longitude’\nself-explanatory\n\n\n‘geo_precision’\nnumeric code for level of precison of event location\n\n\n‘source’\nsource of event report\n\n\n‘source_scale’\nscale (e.g. local, international) of the source\n\n\n‘notes’\ndescription of the event\n\n\n‘fatalities’\nnumber of reported fatalities in the event\n\n\n‘tags’\ntargets (type and estimate counts)\n\n\n‘time’\nUnix Timestamp of event"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#myammars-administrative-boundary-data",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#myammars-administrative-boundary-data",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Myammar’s Administrative Boundary data",
    "text": "Myammar’s Administrative Boundary data\nBackground:\n\nadmin 0: country boundary (full overview)\n1: state/region\n2: district-level\n3: township (greatest resolution)\n\nApproach:\n\nIn the working file directory, group the shapefiles according to admin classification (admin0, admin1, etc.)\nLoad\nCheck structure and boundary plot\n\nFor the purposes of exploring the differences in detail:\n\nadmin 0admin 1admin 2admin 3\n\n\n\nthe1_mymr_shp4326_admin0 &lt;- st_read(dsn = 'data/gadm41_MMR_0/', layer = 'gadm41_MMR_0')\n\n\nstr(the1_mymr_shp4326_admin0)\n\n# geometry: \"XY\" \"MULTIPOLYGON\"\n\n\nplot(the1_mymr_shp4326_admin0$geometry)\n\n\n\n\nthe1_mymr_shp4326_admin1 &lt;- st_read(dsn = 'data/gadm41_MMR_1/', layer = 'gadm41_MMR_1')\n\nReading layer `gadm41_MMR_1' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Take-home_Ex/ex1/data/gadm41_MMR_1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1725 ymin: 8.824445 xmax: 101.1768 ymax: 28.54326\nGeodetic CRS:  WGS 84\n\n\n\nstr(the1_mymr_shp4326_admin1)\n\n\nplot(the1_mymr_shp4326_admin1$geometry)\n\n\n\n\nthe1_mymr_shp4326_admin2 &lt;- st_read(dsn = 'data/gadm41_MMR_2/', layer = 'gadm41_MMR_2')\n\n\nstr(the1_mymr_shp4326_admin2)\n\n\nplot(the1_mymr_shp4326_admin2$geometry)\n\n\n\n\nthe1_mymr_shp4326_admin3 &lt;- st_read(dsn = 'data/gadm41_MMR_3/', layer = 'gadm41_MMR_3')\n\n\nstr(the1_mymr_shp4326_admin3)\n\n\nplot(the1_mymr_shp4326_admin3$geometry)\n\n\n\n\n\nStudy Area\nTo balance spatial detail and computational efficiency, I think using the1_mymr_shp4326_admin1 (state/region) boundary data will be the best fit. While looking at district-/township-level provides fine granularity for analysis, for potato machines like my macbook, the1_mymr_shp4326_admin1 provides the best compromise.\n\nsummary(the1_mymr_shp4326_admin1)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#wrangling",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#wrangling",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Wrangling",
    "text": "Wrangling\n\nReference system\n\nst_crs(acled_sf)\n\n\nacled_sf &lt;- acled_sf %&gt;% \n  st_as_sf(coords = c('longitude','latitude'), crs = 4326) %&gt;% \n  st_transform(crs = 32646)\nst_crs(acled_sf) # last line: ID[\"EPSG\",32646]]\n\n\nst_crs(the1_mymr_shp4326_admin1) # last line: ID[\"EPSG\",4326]]\n\n\nthe1_mymr_shp32646_admin1 &lt;- the1_mymr_shp4326_admin1 %&gt;% \n  st_transform(crs = 32646)\nst_crs(the1_mymr_shp32646_admin1) # now should be: ID[\"EPSG\",32646]]\n\nCoordinate Reference System:\n  User input: EPSG:32646 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 46N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 46N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",93,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 90°E and 96°E, northern hemisphere between equator and 84°N, onshore and offshore. Bangladesh. Bhutan. China. Indonesia. Mongolia. Myanmar (Burma). Russian Federation.\"],\n        BBOX[0,90,84,96]],\n    ID[\"EPSG\",32646]]\n\n\n\n\nDate format\n\nlubridate package\n\nas_datetime(): converts UNIX time-stamps into workable date-time object\nquarter(): extracts quarter info\n\n\n\n# to-do: assign variable; mix in geospatial data too\nacled_sf_prepped &lt;- acled_sf %&gt;% \n  group_by(event_id_cnty) %&gt;%\n  arrange(timestamp) %&gt;% \n  mutate(\n    # convert UNIX timestamp into datetime object\n    datetime = as_datetime(timestamp, tz = 'Asia/Yangon'),\n    \n    # extract quarter info\n    quarter_num = quarter(datetime),\n    \n    # concatenate\n    quarter_period = paste(year,'Q', quarter_num, sep = '')\n  ) %&gt;% \n  ungroup()\n\n\nNote: Unix timestamps count the number of seconds since the Unix epoch (January 1st, 1970 at UTC)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#saving-derived-data",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#saving-derived-data",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Saving Derived Data",
    "text": "Saving Derived Data\nSave working data files and check data structures and attributes if needed before proceeding with analysis\n\nACLEDBoundary shapefileDerived Datasets\n\n\n\nacled_sf_prepped\n\n\n\n\n# | eval: false\nthe1_mymr_shp32646_admin1\n\nSimple feature collection with 15 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 414101 ymin: 978844.6 xmax: 1348458 ymax: 3165949\nProjected CRS: WGS 84 / UTM zone 46N\nFirst 10 features:\n      GID_1 GID_0 COUNTRY     NAME_1                        VARNAME_1 NL_NAME_1\n1   MMR.1_1   MMR Myanmar Ayeyarwady Irrawaddy|Ayeyarwaddy|Ayeyawady|        NA\n2   MMR.2_1   MMR Myanmar       Bago                       Pégou|Pegu        NA\n3   MMR.3_1   MMR Myanmar       Chin                       Chin Hills        NA\n4   MMR.4_1   MMR Myanmar     Kachin                 Jingphaw Mungdaw        NA\n5   MMR.5_1   MMR Myanmar      Kayah                          Karenni        NA\n6   MMR.6_1   MMR Myanmar      Kayin Kawthulei|Karen|Karin|Kawthoolei        NA\n7   MMR.7_1   MMR Myanmar     Magway                      Magwe|Minbu        NA\n8   MMR.8_1   MMR Myanmar   Mandalay                               NA        NA\n9   MMR.9_1   MMR Myanmar        Mon                              Mun        NA\n10 MMR.10_1   MMR Myanmar  Naypyitaw            Naypyidaw|Nay Pyi Taw        NA\n            TYPE_1       ENGTYPE_1 CC_1 HASC_1 ISO_1\n1              Yin        Division   NA  MM.AY MM-07\n2              Yin        Division   NA  MM.BA MM-02\n3            Pyine           State   NA  MM.CH    NA\n4            Pyine           State   NA  MM.KC MM-11\n5            Pyine           State   NA  MM.KH MM-12\n6            Pyine           State   NA  MM.KN MM-13\n7              Yin        Division   NA  MM.MG MM-03\n8              Yin        Division   NA  MM.MD MM-04\n9            Pyine           State   NA  MM.MO MM-15\n10 Union territory Union territory   NA  MM.NY    NA\n                         geometry\n1  MULTIPOLYGON (((676171.4 17...\n2  MULTIPOLYGON (((916141.6 18...\n3  MULTIPOLYGON (((465603.4 23...\n4  MULTIPOLYGON (((903011.7 26...\n5  MULTIPOLYGON (((959987.5 20...\n6  MULTIPOLYGON (((1097974 178...\n7  MULTIPOLYGON (((793981.3 21...\n8  MULTIPOLYGON (((854656.9 21...\n9  MULTIPOLYGON (((1015173 165...\n10 MULTIPOLYGON (((829548.3 21...\n\n\n\n\n\n# refer to previously, \n# \"Strategic developments\"\n# \"Explosions/Remote violence\"\n# \"Battles\"\n# \"Protests\"\n# \"Violence against civilians\"\n# \"Riots\"\n\nacled_stratdev_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Strategic developments') %&gt;% \n  dplyr::select(1,33,30,3,32) \n# if i did not specify dplyr unknown error pops: Error: unable to find an inherited method for function ‘select’ for signature ‘x = \"sf\"’\n\nacled_explo_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Explosions/Remote violence') %&gt;% \n  dplyr::select(1,33,30,3,32)\n\nacled_battle_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Battles') %&gt;% \n  dplyr::select(1,33,30,3,32)\n\nacled_protest_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Protests') %&gt;% \n  dplyr::select(1,33,30,3,32)\n\nacled_civi_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Violence against civilians') %&gt;% \n  dplyr::select(1,33,30,3,32)\n\nacled_riot_sf &lt;- acled_sf_prepped %&gt;% \n  filter(event_type=='Riots') %&gt;% \n  dplyr::select(1,33,30,3,32)\n\nwrite_rds(acled_stratdev_sf, 'data/rds/acled_stratdev_sf.rds')\nwrite_rds(acled_explo_sf, 'data/rds/acled_explo_sf.rds')\nwrite_rds(acled_battle_sf, 'data/rds/acled_battle_sf.rds')\nwrite_rds(acled_protest_sf, 'data/rds/acled_protest_sf.rds')\nwrite_rds(acled_civi_sf, 'data/rds/acled_civi_sf.rds')\nwrite_rds(acled_riot_sf, 'data/rds/acled_riot_sf.rds')\n\nwrite_rds(acled_sf_prepped, 'data/rds/acled_sf_prepped.rds')\nwrite_rds(the1_mymr_shp32646_admin1, 'data/rds/the1_mymr_shp32646_admin1.rds')\n# event_id_cnty,1\n# quarter_period,33\n# geometry,30"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#rds-checkpoint-event_types-sf",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#rds-checkpoint-event_types-sf",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "RDS Checkpoint: event_types sf",
    "text": "RDS Checkpoint: event_types sf\n\nacled_sf_prepped &lt;- read_rds('data/rds/acled_sf_prepped.rds')\nthe1_mymr_shp32646_admin1 &lt;- read_rds('data/rds/the1_mymr_shp32646_admin1.rds')\n\nacled_stratdev_sf &lt;- read_rds('data/rds/acled_stratdev_sf.rds')\nacled_explo_sf    &lt;- read_rds('data/rds/acled_explo_sf.rds')\nacled_battle_sf   &lt;- read_rds('data/rds/acled_battle_sf.rds')\nacled_protest_sf  &lt;- read_rds('data/rds/acled_protest_sf.rds')\nacled_civi_sf     &lt;- read_rds('data/rds/acled_civi_sf.rds')\nacled_riot_sf     &lt;- read_rds('data/rds/acled_riot_sf.rds')"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#overview-plots-by-event_type",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#overview-plots-by-event_type",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Overview plots by event_type",
    "text": "Overview plots by event_type\n\nCompute\n\n# remove(p,plot,plot_list,events,event_type, event_type_list)\n\nplot_list &lt;- list()\n\nevent_type_list &lt;- list(\n  acled_battle_sf,\n  acled_explo_sf,\n  acled_protest_sf,\n  acled_riot_sf,\n  acled_stratdev_sf,\n  acled_civi_sf\n  )\n\nevent = sort(unique(acled_sf_prepped$event_type))\n\nfor (i in seq_along(event_type_list)) {\n  event_type &lt;- event_type_list[[i]]\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n  tm_shape(event_type) +\n    tm_dots(size = 0.005) +\n  tm_layout(title = toString(event[i]))\n  plot_list[[i]] &lt;- plot\n}\n\n\nNote: Append the plots to a separate list, otherwise tmap plot will not work (due to how tmap output works)\n\n\n\nSave\n\nwrite_rds(plot_list,'data/rds/event_overview_plot_list.rds')\n\n\n\nVisualise\n\nevent_overview_plot_list &lt;- read_rds('data/rds/event_overview_plot_list.rds')\ntmap_arrange(event_overview_plot_list, ncol = 6)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#quarterly-plots",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#quarterly-plots",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Quarterly plots",
    "text": "Quarterly plots\n\nCompute Quarterly plots\n\nBattlesExplosions/Remote violenceProtestsRiotStrategic DevelopmentsViolence against Civilian\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_battle_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_battle_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_battle_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_battle_list[[i]] &lt;- plot\n}\n\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_explo_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_explo_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_explo_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_explo_list[[i]] &lt;- plot\n}\n\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_protest_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_protest_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_protest_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_protest_list[[i]] &lt;- plot\n}\n\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_riot_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_riot_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_riot_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_riot_list[[i]] &lt;- plot\n}\n\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_stratdev_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_stratdev_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_stratdev_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_stratdev_list[[i]] &lt;- plot\n}\n\n\n\n\n# Extract unique quarters from the data\nqtrs &lt;- unique(acled_civi_sf$quarter_period)\n\n# Create an empty list to store plots\nplot_civi_list &lt;- list()\n\n# Loop through each unique quarter and generate plots\nfor (i in seq_along(qtrs)) {\n  qtr &lt;- qtrs[i]\n  \n  # Filter data for the current quarter\n  qtr_data &lt;- acled_civi_sf %&gt;% filter(quarter_period==qtr)\n  \n  # Create plot for the current quarter\n  plot &lt;- tm_shape(the1_mymr_shp32646_admin1) +\n    tm_polygons() +\n    tm_shape(qtr_data) +\n    tm_dots(size = 0.005) +\n    tm_layout(title = toString(qtr))\n  \n  # Store the plot in the list\n  plot_civi_list[[i]] &lt;- plot\n}\n\n\n\n\n\n\nSave as RDS\n\nwrite_rds(plot_battle_list, 'data/rds/plot_battle_list.rds')\nwrite_rds(plot_explo_list, 'data/rds/plot_explo_list.rds')\nwrite_rds(plot_protest_list, 'data/rds/plot_protest_list.rds')\nwrite_rds(plot_riot_list, 'data/rds/plot_riot_list.rds')\nwrite_rds(plot_stratdev_list, 'data/rds/plot_stratdev_list.rds')\nwrite_rds(plot_civi_list, 'data/rds/plot_civi_list.rds')\n\n\nplot_battle_list   &lt;- read_rds('data/rds/plot_battle_list.rds')\nplot_explo_list    &lt;- read_rds('data/rds/plot_explo_list.rds')\nplot_protest_list  &lt;- read_rds('data/rds/plot_protest_list.rds')\nplot_riot_list     &lt;- read_rds('data/rds/plot_riot_list.rds')\nplot_stratdev_list &lt;- read_rds('data/rds/plot_stratdev_list.rds')\nplot_civi_list     &lt;- read_rds('data/rds/plot_civi_list.rds')\n\n\n\nVisualise\n\nBattlesExplosions/ViolenceProtestsRiotsStrategic DevsViolence against Civilians\n\n\n\n# | eval: false\ntmap_arrange(plot_battle_list, ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\ntmap_arrange(plot_explo_list, ncol = 4)\n\n\n\n\ntmap_arrange(plot_protest_list, ncol = 4)\n\n\n\n\ntmap_arrange(plot_riot_list, ncol = 4)\n\n\n\n\ntmap_arrange(plot_stratdev_list, ncol = 4)\n\n\n\n\ntmap_arrange(plot_civi_list, ncol = 4)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#overview-kdes",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#overview-kdes",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Overview KDEs",
    "text": "Overview KDEs\n\nCreating ppp object\nas.ppp() from spatstat.geom\n\nacled_ppp &lt;- as.ppp(acled_sf_prepped)\n\nWarning in as.ppp.sf(acled_sf_prepped): only first attribute column is used for\nmarks\n\nsummary(acled_ppp)\n\nMarked planar point pattern:  51576 points\nAverage intensity 3.122579e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    51576 character character \n\nWindow: rectangle = [415262.5, 1265315.1] x [1108593.6, 3051663.8] units\n                    (850100 x 1943000 units)\nWindow area = 1.65171e+12 square units\n\n\n\n\nCreating owin object of admin1 boundary\n\nthe1_mymr_shp4326_admin1_owin &lt;- as.owin(the1_mymr_shp32646_admin1)\n\n\n\nCombine ppp and owin\n\nacled_ppp &lt;- acled_ppp[the1_mymr_shp4326_admin1_owin]\n\n\n\nRescale m to km\n\nacled_ppp_km &lt;- rescale.ppp(acled_ppp,1000,'km')\n\n\nVarying admin1 geographical boundaries — ideal adaptive bandwidth KDE, but because of computational limitation, fixed BW is used:\n\n\n\nCompute KDEs\n\nBig Picture KDEs\n\nkde_acled_bw_diggle &lt;- density(\n  acled_ppp_km,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\n\n\nkde_acled_bw_scott &lt;- density(\n  acled_ppp_km,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\n\n\nkde_acled_bw_ppl &lt;- density(\n  acled_ppp_km,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)# choosing this\n\n\nkde_acled_bw_cvl &lt;- density(\n  acled_ppp_km,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\n\n\npar(mfrow=c(1,4))\nplot(kde_acled_bw_cvl)\nplot(kde_acled_bw_diggle)\nplot(kde_acled_bw_ppl)\nplot(kde_acled_bw_scott)\n\n\n\n\n\n\n\n\n\nOnly kde_acled_bw_cvl and kde_acled_bw_scott produced discernible plots with notable differences:\n\nkde_acled_bw_cvl : smoother — provides a cleaner overall trend without excessive noise\nkde_acled_bw_scott : greater detail — capture small variations or nuances in the data\nSmoother plots might help with observing overall trends across quarterly event_type data, hence I will opt to use bw_scott\n\n\n\ntable(acled_sf_prepped$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing    Mandalay      Magway      Yangon  Shan-North      Kachin \n      14043        5051        4587        3893        3439        3198 \nTanintharyi     Rakhine       Kayin         Mon        Chin  Shan-South \n       2852        2344        1994        1881        1742        1536 \n  Bago-East       Kayah  Ayeyarwady   Bago-West Nay Pyi Taw   Shan-East \n       1402        1398        1063         718         340          95 \n\n\n\nFrom kde_acled_bw_cvl and kde_acled_bw_scott plots and the table counts of admin1, the 2 most apparent event clusters are situated at/in the Sagaing-Mandalay city areas and Yangon city.\n\n\n\nevent_type KDEs\n\n# rather simple to obtain so doesnt warrant converting to rds files\nacled_battle_ppp &lt;- as.ppp(acled_battle_sf)\nacled_explo_ppp &lt;- as.ppp(acled_explo_sf)\nacled_protest_ppp &lt;- as.ppp(acled_protest_sf)\nacled_stratdev_ppp &lt;- as.ppp(acled_stratdev_sf)\nacled_civi_ppp &lt;- as.ppp(acled_civi_sf)\n\n\nacled_battle_ppp   &lt;- acled_battle_ppp[the1_mymr_shp4326_admin1_owin]\nacled_explo_ppp    &lt;- acled_explo_ppp[the1_mymr_shp4326_admin1_owin]\nacled_protest_ppp  &lt;- acled_protest_ppp[the1_mymr_shp4326_admin1_owin]\nacled_stratdev_ppp &lt;- acled_stratdev_ppp[the1_mymr_shp4326_admin1_owin]\nacled_civi_ppp     &lt;- acled_civi_ppp[the1_mymr_shp4326_admin1_owin]\n\n\nwrite_rds(acled_battle_ppp, 'data/rds/acled_battle_ppp.rds')\nwrite_rds(acled_explo_ppp, 'data/rds/acled_explo_ppp.rds')\nwrite_rds(acled_protest_ppp, 'data/rds/acled_protest_ppp.rds')\nwrite_rds(acled_stratdev_ppp, 'data/rds/acled_stratdev_ppp.rds')\nwrite_rds(acled_civi_ppp, 'data/rds/acled_civi_ppp.rds')\n\n\nacled_battle_ppp   &lt;- read_rds('data/rds/acled_battle_ppp.rds')\nacled_explo_ppp    &lt;- read_rds('data/rds/acled_explo_ppp.rds')\nacled_protest_ppp  &lt;- read_rds('data/rds/acled_protest_ppp.rds')\nacled_stratdev_ppp &lt;- read_rds('data/rds/acled_stratdev_ppp.rds')\nacled_civi_ppp     &lt;- read_rds('data/rds/acled_civi_ppp.rds')\n\nEven though only bw.CvL and bw.scout results in discernible plots, I will explore the use of the other 2 (diggle and ppl) bandwidths to be thorough."
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#battles-2",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#battles-2",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Battles",
    "text": "Battles\n\nbw.CvLbw.scottbw.digglebw.ppl\n\n\n\nkde_battle_cvl &lt;- density(\n  acled_battle_ppp,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_battle_cvl)\n\n\n\n\n\n\n\n\n\n\n\nkde_battle_scott &lt;- density(\n  acled_battle_ppp,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_battle_scott)\n\n\n\n\n\n\n\n\n\n\n\nkde_battle_diggle &lt;- density(\n  acled_battle_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_battle_diggle)\n\n\n\n\n\n\n\n\n\n\n\nkde_battle_ppl &lt;- density(\n  acled_battle_ppp,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_battle_ppl)\n\n\n\n\n\n\n\n\n\n\n\n\n# in hindsight i should have included admin1 in the prepped dataset, but future me did not realise until the last minute\ntable((acled_sf_prepped %&gt;% filter(event_type==\"Battles\"))$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing  Shan-North      Kachin      Magway       Kayin Tanintharyi \n       2980        1283        1122        1115         755         744 \n       Chin       Kayah    Mandalay     Rakhine         Mon  Shan-South \n        708         647         606         549         481         422 \n  Bago-East   Bago-West      Yangon  Ayeyarwady Nay Pyi Taw   Shan-East \n        282         176         124          46          21           2 \n\n\n\nKDE Plots, verified with the above table counts, depict significant clusters of battles at Sagaing-Magway areas, Shan-North, Kachin and the near the start of Myanmar’s ‘tail’ at Kayin\nBoth bw.CvL and bw.scott yielded comparable plots in terms of smoothness but bw.scott is better in detail (more distinct clusters, less over-smoothing)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#explosionsremote-violence-1",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#explosionsremote-violence-1",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Explosions/Remote violence",
    "text": "Explosions/Remote violence\n\nbw.CvLbw.scottbw.digglebw.ppl\n\n\n\nkde_explo_cvl &lt;- density(\n  acled_explo_ppp,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_explo_cvl)\n\n\n\n\n\n\n\n\n\n\n\nkde_explo_scott &lt;- density(\n  acled_explo_ppp,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_explo_scott)\n\n\n\n\n\n\n\n\n\n\n\nkde_explo_diggle &lt;- density(\n  acled_explo_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_explo_diggle)\n\n\n\n\n\n\n\n\n\n\n\nkde_explo_ppl &lt;- density(\n  acled_explo_ppp,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_explo_ppl)\n\n\n\n\n\n\n\n\n\n\n\n\ntable((acled_sf_prepped %&gt;% filter(event_type==\"Explosions/Remote violence\"))$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing      Magway    Mandalay      Yangon  Shan-North     Rakhine \n       2978        1142        1034         917         870         805 \n     Kachin         Mon       Kayin   Bago-East Tanintharyi       Kayah \n        783         642         632         560         435         370 \n Shan-South        Chin  Ayeyarwady   Bago-West Nay Pyi Taw   Shan-East \n        343         293         209         128          51          20 \n\n\n\nSimilar clustering patterns with Battle-type events with one additional cluster at Yangon\nBoth bw.CvL and bw.scott yielded comparable plots in terms of smoothness but bw.scott is better in detail (more distinct clusters, less over-smoothing)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#protests-2",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#protests-2",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Protests",
    "text": "Protests\n\nbw.CvLbw.scottbw.digglebw.ppl\n\n\n\nkde_protest_cvl &lt;- density(\n  acled_protest_ppp,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_protest_cvl)\n\n\n\n\n\n\n\n\n\n\n\nkde_protest_scott &lt;- density(\n  acled_protest_ppp,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_protest_scott)\n\n\n\n\n\n\n\n\n\n\n\nkde_protest_diggle &lt;- density(\n  acled_protest_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_protest_diggle)\n\n\n\n\n\n\n\n\n\n\n\nkde_protest_ppl &lt;- density(\n  acled_protest_ppp,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_protest_ppl)\n\n\n\n\n\n\n\n\n\n\n\n\ntable((acled_sf_prepped %&gt;% filter(event_type==\"Protests\"))$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing    Mandalay      Yangon Tanintharyi  Shan-North      Kachin \n       2900        1433        1229         606         494         420 \n     Magway  Ayeyarwady         Mon        Chin   Bago-East       Kayin \n        401         205         198         184         176         162 \n Shan-South   Bago-West Nay Pyi Taw       Kayah     Rakhine   Shan-East \n        100          79          71          69          64          39 \n\n\n\nSimilar event clustering in the Sagaing-Mandalay and Yangon region (like those in Battles, Explosions/Violence) but seems more localised to those regions;\nThis timebw.scott clearly yielded the best plot in terms of level of cluster detail: with reference to the bw.CvL plot, that middle-ish cluster turned out to be 2 distinct clusters in bw.scott ’s plot."
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#strategic-developments-1",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#strategic-developments-1",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Strategic Developments",
    "text": "Strategic Developments\n\nbw.CvLbw.scottbw.digglebw.ppl\n\n\n\nkde_stratdev_cvl &lt;- density(\n  acled_stratdev_ppp,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_stratdev_cvl)\n\n\n\n\n\n\n\n\n\n\n\nkde_stratdev_scott &lt;- density(\n  acled_stratdev_ppp,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_stratdev_scott)\n\n\n\n\n\n\n\n\n\n\n\nkde_stratdev_diggle &lt;- density(\n  acled_stratdev_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_stratdev_diggle)\n\n\n\n\n\n\n\n\n\n\n\nkde_stratdev_ppl &lt;- density(\n  acled_stratdev_ppp,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_stratdev_ppl)\n\n\n\n\n\n\n\n\n\n\n\n\ntable((acled_sf_prepped %&gt;% filter(event_type==\"Strategic developments\"))$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing      Magway    Mandalay      Yangon     Rakhine Tanintharyi \n       3524        1339        1127        1042         678         630 \n     Kachin  Ayeyarwady        Chin  Shan-North  Shan-South       Kayin \n        543         479         432         426         423         325 \n        Mon   Bago-East       Kayah   Bago-West Nay Pyi Taw   Shan-East \n        323         231         207         194         178          28 \n\n\n\nEvent clustering in the Sagaing, Mandalay, Magway and Yangon regions (like those in Battles, Explosions/Violence)\nAt this juncture of the analysis, I have realised that while event clusters do occur in their corresponding admin1 regional boundaries, there is a significant portion of the respective regions that are likely rural (mountainous, undeveloped areas, dense forested areas, etc.). It is worth noting that while my current direction is to study the big picture and quarterly trends of event_types, zooming further down into the admin boundaries for conflict-prone areas should be done to gain more area-specific (district-/township- level) insights.\nBoth bw.CvL and bw.scott yielded comparable plots in terms of smoothness but bw.scott is better in detail (more distinct clusters, less over-smoothing)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#violence-against-civilians-1",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#violence-against-civilians-1",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Violence against Civilians",
    "text": "Violence against Civilians\n\nbw.CvLbw.scottbw.digglebw.ppl\n\n\n\nkde_civi_cvl &lt;- density(\n  acled_civi_ppp,\n  sigma=bw.CvL,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_civi_cvl)\n\n\n\n\n\n\n\n\n\n\n\nkde_civi_scott &lt;- density(\n  acled_civi_ppp,\n  sigma=bw.scott,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_civi_scott)\n\n\n\n\n\n\n\n\n\n\n\nkde_civi_diggle &lt;- density(\n  acled_civi_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_civi_diggle)\n\n\n\n\n\n\n\n\n\n\n\nkde_civi_ppl &lt;- density(\n  acled_civi_ppp,\n  sigma=bw.ppl,\n  edge=TRUE,\n  kernel='gaussian'\n)\nplot(kde_civi_ppl)\n\n\n\n\n\n\n\n\n\n\n\n\ntable((acled_sf_prepped %&gt;% filter(event_type==\"Violence against civilians\"))$admin1) %&gt;% sort(decreasing = TRUE)\n\n\n    Sagaing    Mandalay      Magway      Yangon Tanintharyi  Shan-North \n       1646         840         584         525         434         363 \n     Kachin     Rakhine  Shan-South         Mon   Bago-East   Bago-West \n        328         248         244         234         148         141 \n       Chin  Ayeyarwady       Kayin       Kayah Nay Pyi Taw   Shan-East \n        124         120         120         103          18           6 \n\n\n\nBoth bw.CvL and bw.scott yielded comparable plots in terms of smoothness but bw.scott is better in detail (more distinct clusters, less over-smoothing)\nSimilar clustering in the Sagaing, Mandalay, Magway and Yangon, with a new moderate cluster down south at Tanintharyi region."
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#quarterly-kde-layers-excluding-riots",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#quarterly-kde-layers-excluding-riots",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Quarterly KDE layers (excluding Riots)",
    "text": "Quarterly KDE layers (excluding Riots)\n\nCompute\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against Civilians\n\n\n\n# initialise\nquarters &lt;- unique(acled_battle_sf$quarter_period)\nkde_battles_list &lt;- list()\nppp_battles_list &lt;- list()\n\n# test\n# acled_battle_sf %&gt;% filter(quarter_period=='2021Q1')\n\nfor (quarter in quarters) {\n\n    # filter quarter\n    acled_battle_sf_qtr &lt;- acled_battle_sf %&gt;% filter(quarter_period == quarter)\n\n    # create ppp object\n    acled_battle_ppp_qtr &lt;- as.ppp(acled_battle_sf_qtr)\n\n    # create owin object\n    acled_battle_ppp_qtr &lt;- acled_battle_ppp_qtr[the1_mymr_shp4326_admin1_owin]\n    \n    # rescale to KM\n    acled_battle_ppp_km_qtr &lt;- rescale.ppp(acled_battle_ppp_qtr,1000,'km')\n    \n    # Append ppp object to list\n    ppp_battles_list[[quarter]] &lt;- acled_battle_ppp_km_qtr\n    \n    # compute KDE\n    kde_acled_battle_qtr_bw_cvl &lt;- density(\n      acled_battle_ppp_km_qtr,\n      sigma=bw.scott,\n      edge=TRUE,\n      kernel='gaussian'\n    )\n    \n    # Append to list\n    kde_battles_list[[quarter]] &lt;- kde_acled_battle_qtr_bw_cvl\n    print('qtr done!')\n}\n\n\n\n\n# initialise\nquarters &lt;- unique(acled_explo_sf$quarter_period)\nkde_explo_list &lt;- list()\nppp_explo_list &lt;- list()\n\n# test\n# acled_battle_sf %&gt;% filter(quarter_period=='2021Q1')\n\nfor (quarter in quarters) {\n\n    # filter quarter\n    acled_explo_sf_qtr &lt;- acled_explo_sf %&gt;% filter(quarter_period == quarter)\n\n    # create ppp object\n    acled_explo_ppp_qtr &lt;- as.ppp(acled_explo_sf_qtr)\n\n    # create owin object\n    acled_explo_ppp_qtr &lt;- acled_explo_ppp_qtr[the1_mymr_shp4326_admin1_owin]\n    \n    # rescale to KM\n    acled_explo_ppp_km_qtr &lt;- rescale.ppp(acled_explo_ppp_qtr,1000,'km')\n    \n    # Append ppp object to list\n    ppp_explo_list[[quarter]] &lt;- acled_battle_ppp_km_qtr\n    \n    # compute KDE\n    kde_acled_explo_qtr_bw_cvl &lt;- density(\n      acled_explo_ppp_km_qtr,\n      sigma=bw.scott,\n      edge=TRUE,\n      kernel='gaussian'\n    )\n    \n    # Append to list\n    kde_explo_list[[quarter]] &lt;- kde_acled_explo_qtr_bw_cvl\n    print('qtr done!')\n}\n\n\n\n\n# initialise\nquarters &lt;- unique(acled_protest_sf$quarter_period)\nkde_protest_list &lt;- list()\nppp_protest_list &lt;- list()\n\n# test\n# acled_battle_sf %&gt;% filter(quarter_period=='2021Q1')\n\nfor (quarter in quarters) {\n\n    # filter quarter\n    acled_protest_sf_qtr &lt;- acled_protest_sf %&gt;% filter(quarter_period == quarter)\n\n    # create ppp object\n    acled_protest_ppp_qtr &lt;- as.ppp(acled_protest_sf_qtr)\n\n    # create owin object\n    acled_protest_ppp_qtr &lt;- acled_protest_ppp_qtr[the1_mymr_shp4326_admin1_owin]\n    \n    # rescale to KM\n    acled_protest_ppp_km_qtr &lt;- rescale.ppp(acled_protest_ppp_qtr,1000,'km')\n    \n    # Append ppp object to list\n    ppp_protest_list[[quarter]] &lt;- acled_battle_ppp_km_qtr\n    \n    # compute KDE\n    kde_acled_protest_qtr_bw_cvl &lt;- density(\n      acled_protest_ppp_km_qtr,\n      sigma=bw.scott,\n      edge=TRUE,\n      kernel='gaussian'\n    )\n    \n    # Append to list\n    kde_protest_list[[quarter]] &lt;- kde_acled_protest_qtr_bw_cvl\n    print('qtr done!')\n}\n\n\n\n\n# initialise\nquarters &lt;- unique(acled_stratdev_sf$quarter_period)\nkde_stratdev_list &lt;- list()\nppp_stratdev_list &lt;- list()\n\n# test\n# acled_battle_sf %&gt;% filter(quarter_period=='2021Q1')\n\nfor (quarter in quarters) {\n\n    # filter quarter\n    acled_stratdev_sf_qtr &lt;- acled_stratdev_sf %&gt;% filter(quarter_period == quarter)\n\n    # create ppp object\n    acled_stratdev_ppp_qtr &lt;- as.ppp(acled_stratdev_sf_qtr)\n\n    # create owin object\n    acled_stratdev_ppp_qtr &lt;- acled_stratdev_ppp_qtr[the1_mymr_shp4326_admin1_owin]\n    \n    # rescale to KM\n    acled_stratdev_ppp_km_qtr &lt;- rescale.ppp(acled_stratdev_ppp_qtr,1000,'km')\n    \n    # Append ppp object to list\n    ppp_protest_list[[quarter]] &lt;- acled_battle_ppp_km_qtr\n    \n    # compute KDE\n    kde_acled_stratdev_qtr_bw_cvl &lt;- density(\n      acled_stratdev_ppp_km_qtr,\n      sigma=bw.scott,\n      edge=TRUE,\n      kernel='gaussian'\n    )\n    \n    # Append to list\n    kde_stratdev_list[[quarter]] &lt;- kde_acled_stratdev_qtr_bw_cvl\n    print('qtr done!')\n}\n\n\n\n\n# initialise\nquarters &lt;- unique(acled_civi_sf$quarter_period)\nkde_civi_list &lt;- list()\nppp_civi_list &lt;- list()\n\n# test\n# acled_battle_sf %&gt;% filter(quarter_period=='2021Q1')\n\nfor (quarter in quarters) {\n\n    # filter quarter\n    acled_civi_sf_qtr &lt;- acled_civi_sf %&gt;% filter(quarter_period == quarter)\n\n    # create ppp object\n    acled_civi_ppp_qtr &lt;- as.ppp(acled_civi_sf_qtr)\n\n    # create owin object\n    acled_civi_ppp_qtr &lt;- acled_civi_ppp_qtr[the1_mymr_shp4326_admin1_owin]\n    \n    # rescale to KM\n    acled_civi_ppp_km_qtr &lt;- rescale.ppp(acled_civi_ppp_qtr,1000,'km')\n    \n    # Append ppp object to list\n    ppp_protest_list[[quarter]] &lt;- acled_battle_ppp_km_qtr\n    \n    # compute KDE\n    kde_acled_civi_qtr_bw_cvl &lt;- density(\n      acled_civi_ppp_km_qtr,\n      sigma=bw.scott,\n      edge=TRUE,\n      kernel='gaussian'\n    )\n    \n    # Append to list\n    kde_civi_list[[quarter]] &lt;- kde_acled_civi_qtr_bw_cvl\n    print('qtr done!')\n}\n\n\n\n\n\n\nSave as RDS\n\nwrite_rds(kde_battles_list, 'data/rds/kde_battles_list.rds')\nwrite_rds(kde_explo_list, 'data/rds/kde_explo_list.rds')\nwrite_rds(kde_protest_list, 'data/rds/kde_protest_list.rds')\nwrite_rds(kde_stratdev_list, 'data/rds/kde_stratdev_list.rds')\nwrite_rds(kde_civi_list, 'data/rds/kde_civi_list.rds')\n\n\nwrite_rds(ppp_battles_list, 'data/rds/ppp_battles_list.rds')\nwrite_rds(ppp_explo_list, 'data/rds/ppp_explo_list.rds')\nwrite_rds(ppp_protest_list, 'data/rds/ppp_protest_list.rds')\nwrite_rds(ppp_stratdev_list, 'data/rds/ppp_stratdev_list.rds')\nwrite_rds(ppp_civi_list, 'data/rds/ppp_civi_list.rds')\n\n\nppp_battles_list  &lt;- read_rds('data/rds/kde_battles_list.rds')\nppp_explo_list    &lt;- read_rds('data/rds/kde_explo_list.rds')\nppp_protest_list  &lt;- read_rds('data/rds/kde_protest_list.rds')\nppp_stratdev_list &lt;- read_rds('data/rds/kde_stratdev_list.rds')\nppp_civi_list     &lt;- read_rds('data/rds/kde_civi_list.rds')\n\n\nkde_battles_list  &lt;- read_rds('data/rds/kde_battles_list.rds')\nkde_explo_list    &lt;- read_rds('data/rds/kde_explo_list.rds')\nkde_protest_list  &lt;- read_rds('data/rds/kde_protest_list.rds')\nkde_stratdev_list &lt;- read_rds('data/rds/kde_stratdev_list.rds')\nkde_civi_list     &lt;- read_rds('data/rds/kde_civi_list.rds')\n\n\n\nVisualise\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against Civilians\n\n\n\n# Create a list to store ggplot objects\nkde_plots &lt;- list()\n\n# Loop through each KDE and create a ggplot object\nfor (quarter in names(kde_battles_list)) {\n  kde_df &lt;- as.data.frame(kde_battles_list[[quarter]])  # Convert KDE raster to data frame\n  \n  # Create a plot\n  p &lt;- ggplot() +\n    geom_raster(aes(x, y, fill = value), data = kde_df) +\n    scale_fill_viridis_c() +\n    ggtitle(paste(\"KDE for\", quarter)) +\n    \n    # Reduce the size of titles, legends, and axis text\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 5),               # Reduce title size\n      axis.title = element_blank(),                      # Remove axis titles\n      axis.text = element_text(size = 5),                # Minimize axis text size\n      legend.title = element_text(size = 5),             # Reduce legend title size\n      legend.text = element_text(size = 5),              # Reduce legend text size\n      legend.key.size = unit(0.3, \"cm\"),                 # Minimize legend key size\n      plot.margin = margin(1, 1, 1, 1, \"mm\")             # Minimize margins around the plot\n    )\n  \n  kde_plots[[quarter]] &lt;- p\n}\n\n# Combine plots into a grid with 4 columns\ncombined_plot &lt;- wrap_plots(kde_plots) + plot_layout(ncol = 4)\n# Display the combined plot\ncombined_plot\n\n\nBattle clusters seem to be most localised in Q1 and Q2 of all years excluding 2024\nBattle density appear to have a cycle until 2024: where battle events disperses around its initial dense cluster location as time passes from Q1 to Q4\n2024 data seem sparse or spread out.\n\n\n\n\n# Create a list to store ggplot objects\nkde_plots &lt;- list()\n\n# Loop through each KDE and create a ggplot object\nfor (quarter in names(kde_explo_list)) {\n  kde_df &lt;- as.data.frame(kde_explo_list[[quarter]])  # Convert KDE raster to data frame\n  \n  # Create a plot\n  p &lt;- ggplot() +\n    geom_raster(aes(x, y, fill = value), data = kde_df) +\n    scale_fill_viridis_c() +\n    ggtitle(paste(\"KDE for\", quarter)) +\n    \n    # Reduce the size of titles, legends, and axis text\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 5),               # Reduce title size\n      axis.title = element_blank(),                      # Remove axis titles\n      axis.text = element_text(size = 5),                # Minimize axis text size\n      legend.title = element_text(size = 5),             # Reduce legend title size\n      legend.text = element_text(size = 5),              # Reduce legend text size\n      legend.key.size = unit(0.3, \"cm\"),                 # Minimize legend key size\n      plot.margin = margin(1, 1, 1, 1, \"mm\")             # Minimize margins around the plot\n    )\n  \n  kde_plots[[quarter]] &lt;- p\n}\n\n# Combine plots into a grid with 4 columns\ncombined_plot &lt;- wrap_plots(kde_plots) + plot_layout(ncol = 4)\n# Display the combined plot\ncombined_plot\n\n\nClusters often appear to re-converge at the same regions as previously mentioned under the corresponding ‘event_type KDEs’ section\nAgain, 2024 data seem sparse or spread out\n\n\n\n\n# Create a list to store ggplot objects\nkde_plots &lt;- list()\n\n# Loop through each KDE and create a ggplot object\nfor (quarter in names(kde_protest_list)) {\n  kde_df &lt;- as.data.frame(kde_protest_list[[quarter]])  # Convert KDE raster to data frame\n  \n  # Create a plot\n  p &lt;- ggplot() +\n    geom_raster(aes(x, y, fill = value), data = kde_df) +\n    scale_fill_viridis_c() +\n    ggtitle(paste(\"KDE for\", quarter)) +\n    \n    # Reduce the size of titles, legends, and axis text\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 5),               # Reduce title size\n      axis.title = element_blank(),                      # Remove axis titles\n      axis.text = element_text(size = 5),                # Minimize axis text size\n      legend.title = element_text(size = 5),             # Reduce legend title size\n      legend.text = element_text(size = 5),              # Reduce legend text size\n      legend.key.size = unit(0.3, \"cm\"),                 # Minimize legend key size\n      plot.margin = margin(1, 1, 1, 1, \"mm\")             # Minimize margins around the plot\n    )\n  \n  kde_plots[[quarter]] &lt;- p\n}\n\n# Combine plots into a grid with 4 columns\ncombined_plot &lt;- wrap_plots(kde_plots) + plot_layout(ncol = 4)\n# Display the combined plot\ncombined_plot\n\n\nIn general, significant protest clusters are far and few between; the few clusters that exists are much more localised within the regions previously mentioned under the corresponding ‘event_type KDEs’ section\nThe sparse pattern makes sense given the oppressive nature of the conflict on civilians.\n\n\n\n\n# Create a list to store ggplot objects\nkde_plots &lt;- list()\n\n# Loop through each KDE and create a ggplot object\nfor (quarter in names(kde_stratdev_list)) {\n  kde_df &lt;- as.data.frame(kde_stratdev_list[[quarter]])  # Convert KDE raster to data frame\n  \n  # Create a plot\n  p &lt;- ggplot() +\n    geom_raster(aes(x, y, fill = value), data = kde_df) +\n    scale_fill_viridis_c() +\n    ggtitle(paste(\"KDE for\", quarter)) +\n    \n    # Reduce the size of titles, legends, and axis text\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 5),               # Reduce title size\n      axis.title = element_blank(),                      # Remove axis titles\n      axis.text = element_text(size = 5),                # Minimize axis text size\n      legend.title = element_text(size = 5),             # Reduce legend title size\n      legend.text = element_text(size = 5),              # Reduce legend text size\n      legend.key.size = unit(0.3, \"cm\"),                 # Minimize legend key size\n      plot.margin = margin(1, 1, 1, 1, \"mm\")             # Minimize margins around the plot\n    )\n  \n  kde_plots[[quarter]] &lt;- p\n}\n\n# Combine plots into a grid with 4 columns\ncombined_plot &lt;- wrap_plots(kde_plots) + plot_layout(ncol = 4)\n# Display the combined plot\ncombined_plot\n\n\nIn general, the event clusters appear to have relatively similar locality, albeit their densities seem to be fluctuating throughout the time period\n\n\n\n\n# Create a list to store ggplot objects\nkde_plots &lt;- list()\n\n# Loop through each KDE and create a ggplot object\nfor (quarter in names(kde_civi_list)) {\n  kde_df &lt;- as.data.frame(kde_civi_list[[quarter]])  # Convert KDE raster to data frame\n  \n  # Create a plot\n  p &lt;- ggplot() +\n    geom_raster(aes(x, y, fill = value), data = kde_df) +\n    scale_fill_viridis_c() +\n    ggtitle(paste(\"KDE for\", quarter)) +\n    \n    # Reduce the size of titles, legends, and axis text\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 5),               # Reduce title size\n      axis.title = element_blank(),                      # Remove axis titles\n      axis.text = element_text(size = 5),                # Minimize axis text size\n      legend.title = element_text(size = 5),             # Reduce legend title size\n      legend.text = element_text(size = 5),              # Reduce legend text size\n      legend.key.size = unit(0.3, \"cm\"),                 # Minimize legend key size\n      plot.margin = margin(1, 1, 1, 1, \"mm\")             # Minimize margins around the plot\n    )\n  \n  kde_plots[[quarter]] &lt;- p\n}\n# Combine plots into a grid with 4 columns\ncombined_plot &lt;- wrap_plots(kde_plots) + plot_layout(ncol = 4)\n# Display the combined plot\ncombined_plot\n\n\nClusters often appear to re-converge at the same regions as previously mentioned under the corresponding ‘event_type KDEs’ section\nMostly widespread"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#set-seed",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#set-seed",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Set Seed",
    "text": "Set Seed\n\nset.seed(69)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#g-function-nearest-neighbor-distance",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#g-function-nearest-neighbor-distance",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "G-Function (Nearest Neighbor Distance)",
    "text": "G-Function (Nearest Neighbor Distance)\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against CiviliansConclusion\n\n\nComputing G-function estimation\n\nG_battles &lt;- Gest(acled_battle_ppp, correction = \"border\")\nplot(G_battles, xlim=c(0,500))\n\nPerforming CSR Test\n\nG_battles.csr &lt;- envelope(acled_battle_ppp, Gest, nsim = 39)\nplot(G_battles.csr)\n\n\n\n\nG_explo &lt;- Gest(acled_explo_ppp, correction = \"border\")\nplot(G_explo, xlim=c(0,500))\n\n\nG_explo.csr &lt;- envelope(acled_explo_ppp, Gest, nsim = 39)\nplot(G_explo.csr)\n\n\n\n\nG_protest &lt;- Gest(acled_protest_ppp, correction = \"border\")\nplot(G_protest, xlim=c(0,500))\n\n\nG_protest.csr &lt;- envelope(acled_protest_ppp, Gest, nsim = 39)\nplot(G_protest.csr)\n\n\n\n\nG_stratdev &lt;- Gest(acled_stratdev_ppp, correction = \"border\")\nplot(G_stratdev, xlim=c(0,500))\n\n\nG_stratdev.csr &lt;- envelope(acled_stratdev_ppp, Gest, nsim = 39)\nplot(G_stratdev.csr)\n\n\n\n\nG_civi &lt;- Gest(acled_civi_ppp, correction = \"border\")\nplot(G_civi, xlim=c(0,500))\n\n\nG_civi.csr &lt;- envelope(acled_civi_ppp, Gest, nsim = 39)\nplot(G_civi.csr)\n\n\n\nAll plots strongly indicate clustering of events of every type (above the CSR line)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#f-function-empty-space-function",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#f-function-empty-space-function",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "F-Function (Empty Space Function)",
    "text": "F-Function (Empty Space Function)\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against CiviliansConclusion\n\n\nComputing F-function estimation\n\nF_battles &lt;- Fest(acled_battle_ppp)\nplot(F_battles)\n\nPerforming CSR Test\n\nF_battles.csr &lt;- envelope(acled_battle_ppp, Fest, nsim = 39)\nplot(F_battles.csr)\n\n\n\n\nF_explo &lt;- Fest(acled_explo_ppp)\nplot(F_explo)\n\n\nF_explo.csr &lt;- envelope(acled_explo_ppp, Fest, nsim = 39)\nplot(F_explo.csr)\n\n\n\n\nF_protest &lt;- Fest(acled_protest_ppp)\nplot(F_protest)\n\n\nF_protest.csr &lt;- envelope(acled_protest_ppp, Fest, nsim = 39)\nplot(F_protest.csr)\n\n\n\n\nF_stratdev &lt;- Fest(acled_stratdev_ppp)\nplot(F_stratdev)\n\n\nF_stratdev.csr &lt;- envelope(acled_stratdev_ppp, Fest, nsim = 39)\nplot(F_stratdev.csr)\n\n\n\n\nF_civi &lt;- Fest(acled_civi_ppp)\nplot(F_civi)\n\n\nF_civi.csr &lt;- envelope(acled_civi_ppp, Fest, nsim = 39)\nplot(F_civi.csr)\n\n\n\nAll plots strongly indicate a dispersed pattern, or large between-event point distances (below the CSR line)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#k-function-ripleys-k-function",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#k-function-ripleys-k-function",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "K-Function (Ripley’s K Function)",
    "text": "K-Function (Ripley’s K Function)\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against CiviliansConclusion\n\n\n\nK_battles = Kest(acled_battle_ppp, correction = \"Ripley\")\nplot(K_battles, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nK_battles.csr &lt;- envelope(acled_battle_ppp, Kest, nsim = 39, rank = 1, glocal=TRUE)\nplot(K_battles.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\nK_explo = Kest(acled_explo_ppp, correction = \"Ripley\")\nplot(K_explo, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nK_explo.csr &lt;- envelope(acled_explo_ppp, Kest, nsim = 39, rank = 1, glocal=TRUE)\nplot(K_explo.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\nK_protest = Kest(acled_protest_ppp, correction = \"Ripley\")\nplot(K_protest, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nK_protest.csr &lt;- envelope(acled_protest_ppp, Kest, nsim = 39, rank = 1, glocal=TRUE)\nplot(K_protest.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\nK_stratdev = Kest(acled_stratdev_ppp, correction = \"Ripley\")\nplot(K_stratdev, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nK_stratdev.csr &lt;- envelope(acled_stratdev_ppp, Kest, nsim = 39, rank = 1, glocal=TRUE)\nplot(K_stratdev.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\nK_civi = Kest(acled_civi_ppp, correction = \"Ripley\")\nplot(K_civi, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nK_civi.csr &lt;- envelope(acled_civi_ppp, Kest, nsim = 39, rank = 1, glocal=TRUE)\nplot(K_civi.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\nAll plots strongly indicate clustering of events at every given distance (above the CSR line)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#l-function-besags-l-function",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#l-function-besags-l-function",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "L-Function (Besag’s L Function)",
    "text": "L-Function (Besag’s L Function)\n\nBattlesExplosions/ViolenceProtestsStrategic DevsViolence against CiviliansConclusion\n\n\n\nL_battles = Lest(acled_battle_ppp, correction = \"Ripley\")\nplot(L_battles, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nL_battles.csr &lt;- envelope(acled_battle_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\nplot(L_battles.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nL_explo = Lest(acled_explo_ppp, correction = \"Ripley\")\nplot(L_explo, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nL_explo.csr &lt;- envelope(acled_explo_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\nplot(L_explo.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nL_protest = Lest(acled_protest_ppp, correction = \"Ripley\")\nplot(L_protest, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nL_protest.csr &lt;- envelope(acled_protest_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\nplot(L_protest.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nL_stratdev = Lest(acled_stratdev_ppp, correction = \"Ripley\")\nplot(L_stratdev, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nL_stratdev.csr &lt;- envelope(acled_stratdev_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\nplot(L_stratdev.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nL_civi = Lest(acled_civi_ppp, correction = \"Ripley\")\nplot(L_civi, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nL_civi.csr &lt;- envelope(acled_civi_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\nplot(L_civi.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\nIt is odd that all CSR lines lie along x-axis (or very near it), because it means all L-functions have positive deviations from its corresponding CSR line, indicating strong spatial dependence / clustering as observed under the K-function section"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#kdes",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#kdes",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "KDEs",
    "text": "KDEs\n\n# KDEs used:\n# kde_battle_scott\n# kde_explo_scott\n# kde_protest_scott\n# kde_stratdev_scott\n# kde_civi_scott\n\nConvert KDEs into Spatial Grids\n\ngridded_kde_battle   &lt;- as(kde_battle_scott, \"SpatialGridDataFrame\")\ngridded_kde_explo    &lt;- as(kde_explo_scott, \"SpatialGridDataFrame\")\ngridded_kde_protest  &lt;- as(kde_protest_scott, \"SpatialGridDataFrame\")\ngridded_kde_stratdev &lt;- as(kde_stratdev_scott, \"SpatialGridDataFrame\")\ngridded_kde_civi     &lt;- as(kde_civi_scott, \"SpatialGridDataFrame\")\n\nView gridded objects\n\nBattlesExplosions/ViolenceProtestStrategic DevelopmentsViolence against civilians\n\n\n\nspplot(gridded_kde_battle)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_explo)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_protest)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_stratdev)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_civi)\n\n\n\n\n\n\n\n\n\n\n\nConvert into rasters\n\nraster_kde_battle &lt;- raster(gridded_kde_battle)\nraster_kde_explo &lt;- raster(gridded_kde_explo)\nraster_kde_protest &lt;- raster(gridded_kde_protest)\nraster_kde_stratdev &lt;- raster(gridded_kde_stratdev)\nraster_kde_civi &lt;- raster(gridded_kde_civi)\n\nAssign EPSG code\n\nprojection(raster_kde_battle) &lt;- CRS(\"+init=EPSG:3414\")\nprojection(raster_kde_explo) &lt;- CRS(\"+init=EPSG:3414\")\nprojection(raster_kde_protest) &lt;- CRS(\"+init=EPSG:3414\")\nprojection(raster_kde_stratdev) &lt;- CRS(\"+init=EPSG:3414\")\nprojection(raster_kde_civi) &lt;- CRS(\"+init=EPSG:3414\")"
  },
  {
    "objectID": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#visualise-3",
    "href": "resources/Take-home_Ex/ex1/Take-home_Ex_1.html#visualise-3",
    "title": "Take-Home Exercise 1: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "Visualise",
    "text": "Visualise\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nBattlesExplosions/ViolenceProtestStrategic DevelopmentsViolence against civilians\n\n\n\ntm_shape(raster_kde_battle) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"left\",\"bottom\"),frame=FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(raster_kde_explo) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"left\",\"bottom\"),frame=FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(raster_kde_protest) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"left\",\"bottom\"),frame=FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(raster_kde_stratdev) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"left\",\"bottom\"),frame=FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(raster_kde_civi) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"left\",\"bottom\"),frame=FALSE)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex2/Hands-On_Ex_2.html",
    "href": "resources/Hands-on_Ex/ex2/Hands-On_Ex_2.html",
    "title": "Hands-on Exercise 2: Thematic Mapping & Geovisualisation with R",
    "section": "",
    "text": "Overview\nTerms & Concepts:\n\nGeovisualisation: The over-arching concept that involve any geographic data visualisation technique\nThematic mapping: Use of map types/symbols to visualise variables that are not naturally visible in a geographical area\nChoropleth mapping: Type of thematic mapping to visualise variability across a region using color\n\nI will be using these R packages to build cartographic quality thematic maps:\n\ntmap\ntidyverse p\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\n\nLoad the packages into RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nImport Data\n\nData\nThe following datasets will be used to create a choropleth map:\n\nMaster Plan 2014 SubzoneBoundary(Web) : geospatial data consisting of the geographical boundary of SGP at the planning subzone level\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 : does not contain any coordinates values, but it’s PA and SZ fields can be used as UIDs to geocode to MP14_SUBZONE_WEB_PL shapefile\n\n\n\nImport Geospatial Data using st_read() from sf\n\nmspz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmspz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\nNote: It displays only the first 10 rows (or features) by default. This is a feature of the sf package to prevent overwhelming the console with too much information at once, especially when working with large datasets.\n\nAlternatively, use the one of the following code to explore the spatial data without being limited by the default limit\n\nView(mspz) # opens a separate tab to view the data in RStudios\n\n\nstr(mspz) # check structure\n\nClasses 'sf' and 'data.frame':  323 obs. of  16 variables:\n $ OBJECTID  : int  1 2 3 4 5 6 7 8 9 10 ...\n $ SUBZONE_NO: int  1 1 3 8 3 7 9 2 13 7 ...\n $ SUBZONE_N : chr  \"MARINA SOUTH\" \"PEARL'S HILL\" \"BOAT QUAY\" \"HENDERSON HILL\" ...\n $ SUBZONE_C : chr  \"MSSZ01\" \"OTSZ01\" \"SRSZ03\" \"BMSZ08\" ...\n $ CA_IND    : chr  \"Y\" \"Y\" \"Y\" \"N\" ...\n $ PLN_AREA_N: chr  \"MARINA SOUTH\" \"OUTRAM\" \"SINGAPORE RIVER\" \"BUKIT MERAH\" ...\n $ PLN_AREA_C: chr  \"MS\" \"OT\" \"SR\" \"BM\" ...\n $ REGION_N  : chr  \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" ...\n $ REGION_C  : chr  \"CR\" \"CR\" \"CR\" \"CR\" ...\n $ INC_CRC   : chr  \"5ED7EB253F99252E\" \"8C7149B9EB32EEFC\" \"C35FEFF02B13E0E5\" \"3775D82C5DDBEFBD\" ...\n $ FMEL_UPD_D: Date, format: \"2014-12-05\" \"2014-12-05\" ...\n $ X_ADDR    : num  31596 28679 29655 26783 26202 ...\n $ Y_ADDR    : num  29220 29782 29975 29934 30006 ...\n $ SHAPE_Leng: num  5267 3506 1741 3314 2826 ...\n $ SHAPE_Area: num  1630379 559816 160807 595429 387429 ...\n $ geometry  :sfc_MULTIPOLYGON of length 323; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:157, 1:2] 31496 31981 32333 32362 32362 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"OBJECTID\" \"SUBZONE_NO\" \"SUBZONE_N\" \"SUBZONE_C\" ...\n\n\n\n\nImport Attribute Data using read_csv() from readr package\nImport respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nview(popdata)\n\n\n\nData Preparation\nPrepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData Wrangling\n\nData wrangling is the process of transforming and structuring data from one raw form into a desired format with the intent of improving data quality and making it more consumable and useful for analytics or machine learning.\n\nData wrangling & transformation functions used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  # group_by -&gt; summarise -&gt; ungroup\n  filter(Time==2020) %&gt;%   # keeps rows where the 'Time' col is 2020\n  group_by(PA,SZ,AG) %&gt;%   # needed for summarise() to work\n  summarise(POP=sum(Pop)) %&gt;% # summarises GROUPED DATA by summing 'Pop' value in each (PA,SZ,AG) group & stores in new col 'POP'\n  ungroup() %&gt;%                   # removes grouping structure, allows us to perform further operations on the data\n  pivot_wider(names_from = AG,values_from =POP)  # reshapes data to WIDE format\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nVisualise popdata2020 dataset before calculating age group totals.\n\nView(popdata2020)\n\n\npopdata2020 &lt;- popdata2020 %&gt;% \n  # CALCULATING AGE GROUP TOTALS\n  mutate(`YOUNG`=rowSums(.[3:6])+rowSums(.[14])) %&gt;%                # CREATES new col 'YOUNG'\n  mutate(`ECONOMY ACTIVE`=rowSums(.[7:13])+rowSums(.[15])) %&gt;%   # CREATES new col `ECONOMY ACTIVE`\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%                              # CREATES new col `AGED`\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%                              # CREATES new col `TOTAL`\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%   # CREATES new col `DEPENDENCY` to calculate dependency ratio\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`) # determines column order and contents in OUTPUT DATASET\n\n\n\nJoin attribute and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;% \n  mutate_at(.vars = vars(PA,SZ),.funs = list(toupper)) %&gt;% \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mspz,popdata2020,by = c('SUBZONE_N'='SZ')) # c() is a generic func which combines its args\n\n\nNote that the format of the left data table (mpsz simple feature dataframe) is preserved in the output, because of left_join\n\n\nwrite_rds(mpsz_pop2020,'data/rds/mpszpop2020.rds')\n\n\n\n\n\nChoropleth Mapping Geospatial Data Using tmap\n\nUsing qtm()\nPlot a cartographic standard choropleth map\n\ntmap_mode(\"plot\") # produce a static map; for interactive mode, “view” option should be used.\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\") # map the attribute (i.e. DEPENDENCY)\n\n\n\n\n\n\n\n\n\n\nUsing tmap elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY', \n          style = 'quantile', \n          palette = 'Blues',\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type='8star', size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits('Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS', position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nPlotting the base map\ntm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n# tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\n\nPlotting a choropleth map using tm_polygons()\nAssign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n# The default interval binning used to draw the choropleth map is called “pretty”.\n# The default colour scheme used is YlOrRd of ColorBrewer.\n# By default, Missing value will be shaded in grey.\n\n\n\nPlotting a choropleth map using tm_fill() and tm_border()\ntm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map\nWithout borders,\n\ntm_shape(mpsz_pop2020)+tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nWith borders,\n\ntm_shape(mpsz_pop2020)+tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = .1,  alpha = 1) # adds the boundary of the planning subzones\n\n\n\n\n\n\n\n# The alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\n\n# Arguments for tm_borders():\n\n# col = border colour,\n# lwd = border line width. The default is 1, and\n# lty = border line type. The default is “solid”.\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely:\n(click to jump to corresponding section)\n\nfixed,\n[sd],\n[equal],\n[pretty (default],\n[quantile],\n[kmeans],\n[hclust],\n[bclust],\nbclust, and\n[jenks].\n\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods (n=5 and n=20)\n\nquantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,                 # 5 classes\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nequal\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nsd\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\npretty (default)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nkmeans\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nhclust\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nbclust\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\nfisher\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\njenks\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,                 # 20 classes\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nPlotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. To override these defaults, set the breakpoints using the breaks argument in tm_fill(). In tmap the breaks include a minimum and maximum. Hence to have n categories, n+1 elements must be specified in the breaks option in ascending order.\nCompute and display the descriptive statistics of DEPENDENCY field\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\n\nWith reference to the results above, set break point at 0.60, 0.70, 0.80, and 0.90.\nInclude a minimum and maximum at 0 and 1.00.\nHence c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\nPlot the choropleth map\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\nNote: Values outside the breakpoints that may be essential for analysis\n\n\n\n\nColor Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\nColourBrewer palette\nTo change the colour, assign the preferred colour to palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green. To reverse the colour shading, add a “-” prefix.\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") + # lower data values = deeper green shading\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap layout\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include map objects, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY', \n          style = 'jenks', \n          palette = 'Blues', \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)',\n            main.title.position = 'center',\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c('right', 'bottom'),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\nNote: other available styles are: “white”, “gray”, “natural”, “cobalt”, “col_blind”, “albatross”, “beaver”, “bw”, “watercolor”\n\n\n\nCartographic Furniture\ntmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines\ntm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style,\n\ntmap_style(\"white\")\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nAssign multiple values to at least one of the asthetic arguments\n\nDefine ncols in tm_fill()\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\nAssign multiple values to at least one of the aesthetic arguments\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nDefine a group-by variable in tm_facets()\n\nCreate multiple small choropleth maps using tm_facets().\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\nCreate multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nMapping Spatial Object Meeting a Selection Criterion\nUse selection funtion to map spatial objects meeting the selection criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\",])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.outside.size = 0.5,               # ~0.5\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\n\nWarning: legend.width controls the width of the legend within a map. Please use legend.outside.size to control the width of the outside legend\n\n\n\n\nReadings\n\n\n\nReference\nUsage\nPros\nCons\nApplications\nNotes\n\n\n\n\nProportional Symbols\nScale symbols proportionate to data values\n\nversatile (raw & standardized data)\nmultivariate encoding\n\n\ncongested symbols are hard to read\nsize comparison\n\n\nnumerical data\norder categorical data (rating level)\n\n\ncongestion\ncomplexity\n\n\n\nChoropleth Maps\nColor intensity proportionate to data value\n\nClear regional trends\nClear contrast between intensities\nColor-coded regions can be compared less subjectively than size\n\n\nSmall areas with high data values can get overshadowed by large areas\nColor perception is still imperfect\n\n\n%s, rates, pop. density, …\ndata aggregated over a geographic area (enumeration units)\n\n\nArea bias\n\n\n\n\nData Classification\n\ndefined as grouping a large number of data values into ranges, allowing for data categorisation and subsequent visualisation on a map\nPurpose\n\nminimize misleading representations or patterns\nminimize within-group variance; maximize between-group variance (also method)\n\nMethods\nTools (for future reference)\n\nQGIS\nArcGIS\nD3 - JS libraries for visualising spatial data (web mapping)\n\n\ndplyr cheatsheets"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex11/Hands-on_Ex11.html",
    "href": "resources/Hands-on_Ex/ex11/Hands-on_Ex11.html",
    "title": "Hands-on Exercise 11:[Cont.] GWR",
    "section": "",
    "text": "Reusing derived data from previous section,\n\ncondo_resale_sp = read_rds('data/rds/condo_resale_sp.rds')\nmpsz_3414 = read_rds('data/rds/mpsz_3414.rds')\n\n\nBuilding Fixed Bandwidth GWR Model\n\n\nBuilding Adaptive Bandwidth GWR Model\n\n\nVisualise GWR Output\n\nConverting SDF into sf data.frame\n\n\nVisualise local R2\n\n\nVisualise coefficient estimates"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "I will be computing Global Measures of Spatial Autocorrelation (GMSA) by using spdep package\n\n\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics.\n\n\n\n\n\n\nOur task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,spdep,tmap,tidyverse)\n\n\n\n\n\nHunan province administrative boundary layer at county level\n\nhunan &lt;- st_read('data/geospatial', layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex6/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nHunan_2012 development indicators\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nUpdate the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;% dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nPrepare a basemap and a choropleth map showing the distribution of GDPPC 2012\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\", n = 5, style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, quantile, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncompute global spatial autocorrelation statistics and\nperform spatial complete randomness test for global spatial autocorrelation\n\n\n\n\nCompute contiguity weight matrices for the study area\n\n# builds a neighbours list based on regions with contiguous boundaries\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\nAssign equal weights (style=“W”) to each neighboring polygon\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\n\nPerform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n\nmoran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nMoran I Statistic:\n\nMoran I = 0: No spatial autocorrelation; high GDPPC values are randomly distributed.\n\n\n\nMoran I &gt; 0: Positive spatial autocorrelation; high GDPPC values cluster together.\nMoran I &lt; 0: Negative spatial autocorrelation; dissimilar GDPPC are near each other (e.g., high values next to low values).\n\nLarge Moran I statistic standard deviate and Small p-value: strong statistical evidence against H0 (no spatial autocorrelation) and conversely observed clusters of GDPPC is statistically significant.\n\n\n\n\n\nset.seed(6969)\nbperm= moran.mc(hunan$GDPPC, listw=rswm_q, nsim=99, zero.policy = TRUE, na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value = 0.01\nalternative hypothesis: greater\n\n\n\nConsistent with previous findings:\n\nstatistic = 0.30075; positive spatial autocorrelation\n0.025 &lt; significance level\n\n\n\n\n\n\nmean(bperm$res[1:99])\n\n[1] -0.01626548\n\nvar(bperm$res[1:99])\n\n[1] 0.005356579\n\nsummary(bperm$res[1:99])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.14275 -0.07003 -0.02487 -0.01627  0.02691  0.20051 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\nsimulated_results &lt;- data.frame(bperm$res)\n\n# Create the histogram using ggplot2\nggplot(simulated_results, aes(bperm$res)) +\n  geom_histogram(bin=20, fill = \"gray\", color = \"black\",) +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(x = \"Simulated Moran's I\", \n       y = \"Frequency\", \n       title = \"Histogram of Simulated Moran's I\") +\n  theme_minimal()\n\nWarning in geom_histogram(bin = 20, fill = \"gray\", color = \"black\", ): Ignoring\nunknown parameters: `bin`\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValues range from 0 to 2, where:\n\nC = 1 indicates no spatial autocorrelation (randomness),\nC &lt; 1 indicates positive spatial autocorrelation (neighbors are more similar),\nC &gt; 1 indicates negative spatial autocorrelation (neighbors are dissimilar).\n\n\nPerform Geary’s C statistics testing by using appropriate functions of spdep package\n\n\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nNote:\nSame statistical conclusion of std, p-value with Moran’s I: significant positive spatial autocorrelation.\n\n\n\n\n\n\nAn exploratory and descriptive tool.\n\nPurpose is to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.\n\n\nCompute a 6-lag spatial correlogram of GDPPC with base plot()\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nNote:\nThe above plot may be incomplete since not all autocorrelation values are statistically significant.\n\nPrint the full analysis results\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterpretation:\nAt low lags (1-3), Moran’s I values &gt; 0 , very small p-value: strong statistical evidence of strong positive spatial autocorrelation\n\nmeaning regions with similar GDPPC values tend to cluster together\n\np-value at lag 4 is statistically insignificant\n\nspatial autocorrelation is highly likely to be random\n\nLags 5 and 6, Moran’s I values &lt; 0, very small p-value: strong statistical evidence of strong negative spatial autocorrelation\n\nregions with dissimilar GDPPC values tend to cluster together\n\n\n\n\n\nCompute a 6-lag spatial correlogram of GDPPC with base plot()\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#overview",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#overview",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "import geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#setup",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#setup",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,spdep,tmap,tidyverse)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#data-wrangling",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#data-wrangling",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Hunan province administrative boundary layer at county level\n\nhunan &lt;- st_read('data/geospatial', layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex6/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nHunan_2012 development indicators\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nUpdate the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;% dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nPrepare a basemap and a choropleth map showing the distribution of GDPPC 2012\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\", n = 5, style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, quantile, asp=1, ncol=2)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "compute global spatial autocorrelation statistics and\nperform spatial complete randomness test for global spatial autocorrelation\n\n\n\n\nCompute contiguity weight matrices for the study area\n\n# builds a neighbours list based on regions with contiguous boundaries\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\nAssign equal weights (style=“W”) to each neighboring polygon\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n\nmoran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nMoran I Statistic:\n\nMoran I = 0: No spatial autocorrelation; high GDPPC values are randomly distributed.\n\n\n\nMoran I &gt; 0: Positive spatial autocorrelation; high GDPPC values cluster together.\nMoran I &lt; 0: Negative spatial autocorrelation; dissimilar GDPPC are near each other (e.g., high values next to low values).\n\nLarge Moran I statistic standard deviate and Small p-value: strong statistical evidence against H0 (no spatial autocorrelation) and conversely observed clusters of GDPPC is statistically significant.\n\n\n\n\n\nset.seed(6969)\nbperm= moran.mc(hunan$GDPPC, listw=rswm_q, nsim=99, zero.policy = TRUE, na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value = 0.01\nalternative hypothesis: greater\n\n\n\nConsistent with previous findings:\n\nstatistic = 0.30075; positive spatial autocorrelation\n0.025 &lt; significance level\n\n\n\n\n\n\nmean(bperm$res[1:99])\n\n[1] -0.01626548\n\nvar(bperm$res[1:99])\n\n[1] 0.005356579\n\nsummary(bperm$res[1:99])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.14275 -0.07003 -0.02487 -0.01627  0.02691  0.20051 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\nsimulated_results &lt;- data.frame(bperm$res)\n\n# Create the histogram using ggplot2\nggplot(simulated_results, aes(bperm$res)) +\n  geom_histogram(bin=20, fill = \"gray\", color = \"black\",) +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(x = \"Simulated Moran's I\", \n       y = \"Frequency\", \n       title = \"Histogram of Simulated Moran's I\") +\n  theme_minimal()\n\nWarning in geom_histogram(bin = 20, fill = \"gray\", color = \"black\", ): Ignoring\nunknown parameters: `bin`\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Values range from 0 to 2, where:\n\nC = 1 indicates no spatial autocorrelation (randomness),\nC &lt; 1 indicates positive spatial autocorrelation (neighbors are more similar),\nC &gt; 1 indicates negative spatial autocorrelation (neighbors are dissimilar).\n\n\nPerform Geary’s C statistics testing by using appropriate functions of spdep package\n\n\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nNote:\nSame statistical conclusion of std, p-value with Moran’s I: significant positive spatial autocorrelation."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#spatial-correlogram",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#spatial-correlogram",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "An exploratory and descriptive tool.\n\nPurpose is to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.\n\n\nCompute a 6-lag spatial correlogram of GDPPC with base plot()\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nNote:\nThe above plot may be incomplete since not all autocorrelation values are statistically significant.\n\nPrint the full analysis results\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterpretation:\nAt low lags (1-3), Moran’s I values &gt; 0 , very small p-value: strong statistical evidence of strong positive spatial autocorrelation\n\nmeaning regions with similar GDPPC values tend to cluster together\n\np-value at lag 4 is statistically insignificant\n\nspatial autocorrelation is highly likely to be random\n\nLags 5 and 6, Moran’s I values &lt; 0, very small p-value: strong statistical evidence of strong negative spatial autocorrelation\n\nregions with dissimilar GDPPC values tend to cluster together\n\n\n\n\n\nCompute a 6-lag spatial correlogram of GDPPC with base plot()\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#overview-1",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#overview-1",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Overview",
    "text": "Overview\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#setup-1",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#setup-1",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Setup",
    "text": "Setup\nSame as Global"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#data-wrangling-1",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#data-wrangling-1",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nSame as Global"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#local-indicators-of-spatial-associationlisa",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#local-indicators-of-spatial-associationlisa",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Local Indicators of Spatial Association(LISA)",
    "text": "Local Indicators of Spatial Association(LISA)\n\nComputing Contiguity Spatial Weights\nSame as Global\n\n\nRow-standardised weights matrix\nSame as Global\n\n\nComputing local Moran’s I\ncompute local Moran’s I of GDPPC2012 at the county level\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nInterpretation:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nlist the content of the local Moran matrix\n\nprintCoefmat(\n  data.frame(\n    localMI[fips,], \n    row.names=hunan$County[fips]\n    ),\n  check.names=FALSE\n  )\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping the local Moran’s I\nAppend the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\nMapping local Moran’s I values\nPlot using tmap\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nThere is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values\n\n\n\nMapping local Moran’s I p-values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nFor better visualisations\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#creating-a-lisa-cluster-map",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#creating-a-lisa-cluster-map",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\n\nPlotting Moran scatterplot\nGDPPC 2012\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\nTop right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC\n\n\n\nPlotting Moran scatterplot with standardised variable\nStandardise\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector() # convert into df for map plot\n\n# centering : subtracting the mean (omitting NAs) the corresponding columns, and \n# scaling   : dividing the (centered) variable by their std.dev\n\nPlot\n\nnci2 &lt;- moran.plot(\n  hunan$Z.GDPPC,\n  rswm_q,\n  labels=as.character(hunan$County),\n  xlab=\"z-GDPPC 2012\", \n  ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPreparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\n# derive the spatially lagged variable of interest\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\n\n# center the spatially lagged variable around its mean\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\n# center local Moran’s around the mean\nLM_I &lt;- localMI[,1] - mean(localMI[,1])\n\n# set a statistical significance level\nsignif &lt;- 0.5\n\n# define quadrants\n# low-low (1), low-high (2), high-low (3) and high-high (4)\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\n# for non-significant Morans\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nAlongside p-value map\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nStrong statistical evidence of similar GDPPC clustering together\nStrong statistical evidence of dissimilar GDPPC clustering (low-high) – indicates income disparity or uneven geographical distribution of economic development"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#hot-spot-and-cold-spot-area-analysis",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\n‘Hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\n\n\nTo detect spatial anomalies\nlooks at neighbours within a defined proximity to identify where either high or low values cluster spatially\n\n\n\n\nDeriving distance-based weight matrix (fixed/adaptive bw)\n\ncentroid\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\n# map_dbl returns an atomic (single data-type) vector; map returns a list\n\n\nNote:\nCannot simply st_centroid() on hunan$geometry;\nNeed to map the separate coordinates from the geometry column into a separate df, using map_dbl variation of map from the purrr package\n\n\n\ncut-off distance\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nLargest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour\n\n\n\nfixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nconvert the nb object into spatial weights object\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nComputing adaptive distance weight matrix\nusing k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nconvert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#computing-gi-statistics",
    "href": "resources/Hands-on_Ex/ex6/Hands-On_Ex_6.html#computing-gi-statistics",
    "title": "Hands-On Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Computing Gi statistics",
    "text": "Computing Gi statistics\n\nGi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\n\nMagnitude == Clustering intensity,\nDirection (positive or negative) indicates high or low clusters\n\n\nJoin the Gi values to their corresponding hunan sf data frame\n\nhunan.gi &lt;- cbind( # join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame\n  hunan, \n  as.matrix(gi.fixed) # convert the output vector (i.e. gi.fixed) into r matrix object\n  ) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.) # field name of the gi values is renamed to gstat_fixed\n\n\n\nMapping Gi values with fixed distance weights\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nThere are statistically significant clusters of very high GDPPC and low GDPPC\n\n\n\nGi statistics using adaptive distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with adaptive distance weights\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nStrong statistical evidence that GDPPC is unevenly distributed across Hunan, cold, low GDPPC spots tend to cluster on the left, high GDPPC spots tend to cluster on the right"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex9/Hands-On_Ex_9.html",
    "href": "resources/Hands-on_Ex/ex9/Hands-On_Ex_9.html",
    "title": "Hands-on Exericse 9: [Cont. from Hands-on 7] SKATER approach",
    "section": "",
    "text": "Last time on Hands-on Exercise 7…\n\nAnalytical Question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data.\n\nplanning and implementing targeted policies will be easier\nreduce data complexity, enabling easier analysis\nensure equitable distribution of resources to each homogeneous region\n\n\n\nPackages\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\n\n\nData\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)\n\nshan_sf &lt;- read_rds('data/rds/shan_sf.rds')\nshan_ict &lt;- read_rds('data/rds/shan_ict.rds')\nshan_sf_cluster &lt;- read_rds('../ex7/data/rds/shan_sf_cluster.rds')\n\n\n\n\nSKATER Approach\nTo derive spatially constrained cluster\n\nOverall\n\n\nCompute Neighbors list\nSKATER function only support sp objects such as SpatialPolygonDataFrame\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\nCompute neighbours list from polygon list\n\n# poly2nd() of spdep\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nApply coordinates to original shan_sf to extract polygons’ centroids, which are used as the nodes for the future plot\n\ncoords &lt;- st_coordinates(st_centroid(st_geometry(shan_sf)))\n\nPlot shan.nb on top of shan_sf\n\nshan_sf extends further than the graph, so its plotted first, otherwise some of the areas will be clipped, because plotting area is determined by the characteristics of the first plot\n\n\n\nCode\nplot(st_geometry(shan_sf), border=grey(.5))\nplot(shan.nb,\n    coords, \n    col=\"blue\", \n    add=TRUE) # adds to existing plot, otherwise will be plotted separately\n\n\n\n\n\n\n\n\n\n\n\nComputing minimum spanning tree\nCompute edge costs\n\nedge costs: distance between nodes\n\n\n# nbcosts() of spdep package\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\nGives pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\n\nConvert shan.nb to a list weights object by specifying lcosts as the weights\n\n# nb2listw() of spdep package\nshan.w &lt;- nb2listw(\n    shan.nb,\n    lcosts,\n    style = 'B' # ensures cost values arent row-standardised\n)\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\nCompute the tree using shan.w\n\n# mstree() of spdep package\nshan.mst &lt;- mstree(shan.w)\n\nCheck its class and dimension\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\nNote how n (number of dimensions) in shan.w is 55 but dim(shan.mst) = 54 , because shan.mst consists on n-1 edges (links) in order to traverse all the nodes\n\nPlot shan.mst\n\n\nCode\nplot(st_geometry(shan_sf), border = gray(.5))\n\nplot(\n    shan.mst,\n    coords,\n    cex.labels = .7,\n    cex.circles = .005,\n    add = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\nCompute the spatially constrained cluster\n\n# skater() of spdep package.\nclust6 &lt;- skater(\n    edges = shan.mst[,1:2], # exclude the 3rd col (cost)\n    data = shan_ict,\n    method = 'euclidean',\n    ncuts = 5 # one less than number of clusters\n)\n\n\nclust6 is object skater\n\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 22 43 42 15 41 38 32 53 ...\n  .. ..$ edge: num [1:17, 1:3] 22 15 42 43 41 38 15 27 15 32 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nccs6 &lt;- clust6$groups\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n18 22 11  2  1  1 \n\n\n\ngroups: shows number of observations in each cluster\n\nPlot pruned tree with 5 clusters\n\n\nCode\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(\n    clust6, \n    coords, \n    cex.labels = .7 ,\n    groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n    cex.circles=0.005,\n    add=TRUE\n    )\n\n\n\n\n\n\n\n\n\n\n\nVisualising the clusters in choropleth map\n\n# compute proximity matrix\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n# agglomeration method (ward.D) to compute the hierachical cluster\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n# retain 6 clusters\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nshan_sf_cluster &lt;- cbind(  # append groups onto shan_sf to produce an output sf object\n    shan_sf, \n    as.matrix(groups)) %&gt;% # convert 'list' object group into a matrix\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\n\nCode\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nClustGeo package\nTo perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis\n\nOverall\n\n\nWard-like hierarchical clustering\n\n\nCode\n# hclustgeo() to perform a typical Ward-like hierarchical clustering\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(\n    nongeo_cluster,\n    cex = .5\n)\nrect.hclust(\n    nongeo_cluster,\n    k = 6,\n    border = 2:5\n)\n\n\n\n\n\n\n\n\n\n\n\nForm clusters\n\n\nCode\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\nDerive Spatial Distance Matrix\n\ndist = st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist) # convert df to matrix\n\nchoicealpha() will be used to determine a suitable value for the mixing parameter alpha\n\nCode\n# determine a suitable value for the mixing paramete\n\ncr &lt;- choicealpha(\n    proxmat, \n    distmat, \n    range.alpha = seq(0, 1, 0.1), # start, stop, step\n    K=6, \n    graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nUse alpha = 0.2\n\n\nCode\n# perform a typical Ward-like hierarchical clustering\nclustG &lt;- hclustgeo(\n    proxmat,\n    distmat,\n    alpha = 0.2\n)\n\n# derive cluster object\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\n# join ClusterGeo groups list of formed clusters with shan_sf\nshan_sf_Gcluster &lt;- cbind(\n    shan_sf,\n    as.matrix(groups)) %&gt;% \n    rename(`CLUSTER` = `as.matrix.groups.`)\n\n# plot newly delineated spatially constrained clusters\nqtm(shan_sf_Gcluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n\nVisual Interpretation of Clusters\n\nUnivariate\nCompute boxplots\n\ncolnames(shan_sf_ngeo_cluster)\n\n [1] \"ST\"            \"ST_PCODE\"      \"DT.x\"          \"DT_PCODE.x\"   \n [5] \"TS.x\"          \"TS_PCODE\"      \"DT_PCODE.y\"    \"DT.y\"         \n [9] \"TS.y\"          \"TT_HOUSEHOLDS\" \"RADIO\"         \"TV\"           \n[13] \"LLPHONE\"       \"MPHONE\"        \"COMPUTER\"      \"INTERNET\"     \n[17] \"RADIO_PR\"      \"TV_PR\"         \"LLPHONE_PR\"    \"MPHONE_PR\"    \n[21] \"COMPUTER_PR\"   \"INTERNET_PR\"   \"CLUSTER\"       \"geometry\"     \n\n\n\nCode\nggplot(\n    data = shan_sf_ngeo_cluster,\n    aes(x = CLUSTER, y = RADIO_PR)) +\n    geom_boxplot()\nggplot(\n    data = shan_sf_ngeo_cluster,\n    aes(x = CLUSTER, y = LLPHONE_PR)) +\n    geom_boxplot()\nggplot(\n    data = shan_sf_ngeo_cluster,\n    aes(x = CLUSTER, y = MPHONE_PR)) +\n    geom_boxplot()\nggplot(\n    data = shan_sf_ngeo_cluster,\n    aes(x = CLUSTER, y = COMPUTER_PR)) +\n    geom_boxplot()\nggplot(\n    data = shan_sf_ngeo_cluster,\n    aes(x = CLUSTER, y = INTERNET_PR)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate\nParallel coordinate plot:\n\n\nCode\nggparcoord(\n    data = shan_sf_ngeo_cluster,\n    columns = c(17:21),\n    scale = 'globalminmax', # no scaling, determined by global data range\n    alphaLines = .2,\n    boxplot = TRUE, # boxplot overlay\n    title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30)\n)\n\n\n\n\n\n\n\n\n\n\nReveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT\nAlso note scale have other scaling methods, explore and select the optimal.\n\n\n\nCompute the summary statistics\n\n\nCode\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data.\n\nplanning and implementing targeted policies will be easier\nreduce data complexity, enabling easier analysis\nensure equitable distribution of resources to each homogeneous region"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#extract-cluster-variables",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#extract-cluster-variables",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Extract cluster variables",
    "text": "Extract cluster variables\n\n# remember to pick one: COMPUTER_PR or INTERNET_PR \ncluster_vars &lt;- shan_sf %&gt;%\n    st_set_geometry(NULL) %&gt;% \n    select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars)\n\n      TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1  Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2  Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3  Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4 Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5   Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6    Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n\n\n\n# change rows by township name instead of row number\nrow.names(cluster_vars) &lt;- cluster_vars$TS.x\nhead(cluster_vars)\n\n             TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw       Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n\n# delete TS.x field\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict)\n\n         RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit  286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya  417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan  484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein   449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw    280.7624 611.6204   42.06478  408.7951    29.63160\n\n\n\nwrite_rds(shan_ict, 'data/rds/shan_ict.rds')\n\n\nshan_ict &lt;- read_rds('data/rds/shan_ict.rds')"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#data-standardisation",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#data-standardisation",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Data Standardisation",
    "text": "Data Standardisation\nClustering variables with large value ranges will dominate and bias the overall cluster analysis. These are some methods how to avoid it:\n\nMin/Max Standardisation\n\n# normalize() of heatmaply package\n# makes the ranges of the Min-max standardised cluster variables to be 0-1\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\nZ-score Standardisation\n\n# scale() of Base R\n# makes the avg & stdev of Z-score standardised cluster variables be 0 and 1 respectively\n# ASSUME THAT all variables come from some NORMAL distribution\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\nVisualise Standardised cluster variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\n\nHistogramDensity\n\n\n\n\nCode\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nPentration rates now more follows a normal distribution."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#proximity-matrix",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#proximity-matrix",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Proximity Matrix",
    "text": "Proximity Matrix\n\n# calculate distance matrix using dist() of base R\n\n# dist() supports six distance proximity calculations, they are: \n    # euclidean (default), \n    # maximum, \n    # manhattan, \n    # canberra, \n    # binary and \n    # minkowski.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\n# to inspect ...\nproxmat"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#hierarchy-clustering",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#hierarchy-clustering",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Hierarchy Clustering",
    "text": "Hierarchy Clustering\n\n# hclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: \n    # ward.D, \n    # ward.D2, \n    # single, \n    # complete, \n    # average(UPGMA), \n    # mcquitty(WPGMA), \n    # median(WPGMC) and \n    # centroid(UPGMC)\n\n# performs hierarchical cluster analysis using ward.D method\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\n# plot the tree by using plot() of R Graphics\nplot(hclust_ward, cex = 0.6)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#optimal-clustering-algorithm",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#optimal-clustering-algorithm",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Optimal Clustering Algorithm",
    "text": "Optimal Clustering Algorithm\n\n# compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\n# agnes() computes the agglomerative coefficient: measures the amount of clustering structure found \n# (closer to 1 suggest strong clustering structure).\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWard’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used."
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#optimal-clusters",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#optimal-clusters",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Optimal Clusters",
    "text": "Optimal Clusters\nNow we have to determine the optimal clusters to retain.\n\nElbow Method\n\n\nAverage Silhouette Method\n\n\nGap Statistic Method\nCompares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. Optimal clusters yields the largest gap statistic, meaning that the clustering structure is far away from the random uniform distribution of points\n\n# clusGap() of cluster package\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, #  hcut function used is from factoextra package\n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\n# visualise the plot using fviz_gap_stat() of factoextra package\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nOptimal is k = 1.\nHowever, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nAdditional Reference: NbClust package(Charrad et al., 2014)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#dendrograms",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#dendrograms",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Dendrograms",
    "text": "Dendrograms\n\nEach leaf corresponds to one observation. Moving up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nHeight indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are.\nNote that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5) # specify the border colors for the rectangle"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#visually-driven-hierarchy-cluster-analysis-using-heatmaply-package",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#visually-driven-hierarchy-cluster-analysis-using-heatmaply-package",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visually-driven Hierarchy Cluster Analysis using heatmaply package",
    "text": "Visually-driven Hierarchy Cluster Analysis using heatmaply package\n\n# Transforming the data frame into a matrix\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n# Plotting interactive cluster heatmap\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\")"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#map-formed-clusters",
    "href": "resources/Hands-on_Ex/ex7/Hands-On_Ex_7.html#map-formed-clusters",
    "title": "Hands-on Exericse 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Map formed clusters",
    "text": "Map formed clusters\nWith closed examination of the dendragram above, we have decided to retain six clusters.\n\n# cutree() of base R\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\n\nshan_sf_cluster &lt;- cbind(  # append groups onto shan_sf to produce an output sf object\n    shan_sf, \n    as.matrix(groups)) %&gt;% # convert 'list' object group into a matrix\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n# plot the choropleth map, showing formed clusters\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nVery fragmented clusters (major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used)"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex1/Hands-On_Ex_1.html",
    "href": "resources/Hands-on_Ex/ex1/Hands-On_Ex_1.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Overview\nThis will be my first experience with R programming to perform geospatial data science tasks by using sf and tidyverse packages.\n\n\nObjectives\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\n\nGetting Started\n\nSelecting Data (for the purpose of this exercise, these have been chosen)\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\nExtracting Relevant Data\nIn my exercise folder, I will be creating a “data” sub-folder containing a “geospatial” folder, where the Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path data files will be in; and a “aspatial” folder where the listing data file will be in.\n\n\nLoading Packages\nThese R packages will be used:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nRun the following code chunk below.\n\npacman::p_load(sf, tidyverse)\n# p_load() from the pacman package checks if the sf and tidyverse packages are installed; if present, the packages specified will be loaded\n\n\n\n\nImporting Geospatial Data\nI will be importing the following data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\nImporting polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\nNote that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name. Also note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP/\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex1/data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting polyline feature data in shapefile form\nDataset used: CyclingPathGazette File format: shapefile Data frame type: line feature\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024/\", \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex1/data/geospatial/CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\n\n\nImporting GIS data in kml format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system.\n\n\n\nMethods to Check the Content of A Simple Feature Data Frame\n\nst_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. Use st_geometry() to retrieve the geometry list-column as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\nglimpse()\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\nhead()\nhead() to reveal top n entries of a feature object.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument)\n\n\n\n\nPlotting Geospatial Data\nI will be using plot() of R Graphic to visualize geospatial features.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\nNote: plot() is mean for plotting the geospatial object for quick look. For high cartographic quality plot, other R package such as tmap should be used.\n\n\n\nProjection Transformation\nTo perform geoprocessing using two geospatial data, it is important that both geospatial data are projected using similar coordinate systems.\nHence, I will be projecting a simple feature data frame from one coordinate system to another coordinate system.\n\nAssigning EPSG code to a simple feature data frame\nDuring the importing of geospatial data into R, the coordinate system of the source data can be either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nst_set_crs() of sf package to assign the correct EPSG code to mpsz data frame.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nCheck the CSR.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\nTransforming the projection of preschool from wgs84 to svy21.\nI will be transforming the original data from geographic coordinate (GCS) system to projected coordinate system (PCS) because PCS allows for distance or/and area measurements while GCS is more suited when positional accuracy is needed.\nE.g. The preschool simple feature data frame is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nThis is shows that st_set_crs() is not appropriate and st_transform() of sf package should be used because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nThe code chunk below shows the projection transformation.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nDisplay the content of preschool3414 sf data frame as shown below.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nNotice that it is in svy21 projected coordinate system now. In the Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\nImporting and Converting An Aspatial Data\nI will be importing an aspatial data into R environment and save it as a tibble data frame, converting it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\nImporting\nSince listings data set is in csv file format, use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv.gz\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important verify that it has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 GCS.\n\n\nCreating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 GCS and EPSG: 3414 is Singapore SVY21 PCS. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nThis is the newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame.\n\n\n\nGeoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\n\nBuffering\nE.g. The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSolution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\nPoint-in-polygon count\nE.g. A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nSolution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: You should not confuse with st_intersection().\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\n\n\nSolution: &lt;click to reveal&gt;\n\n\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nExploratory Data Analysis (EDA)\nI will be using appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\n\n\nSolution: &lt;click to reveal&gt;:\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n{r warning=FALSE} to remove warning messages\n{r eval=FALSE} can ‘hide’ output text but potentially important result cannot be referenced later on\ncollapsible sections using &lt;details&gt;&lt;/details&gt;"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex10/Hands-on_Ex10_1.html",
    "href": "resources/Hands-on_Ex/ex10/Hands-on_Ex10_1.html",
    "title": "Hands-on Exercise 10: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically weighted regression (GWR)",
    "section": "",
    "text": "In this exercise, I am applying GWR to develop hedonic pricing models, where structural and locational variables are used to model 2015 resale condo prices.\n\nR Packages used\n\nOLS and performing diagnostics tests\n\nolsrr\n\nCalibrating geographical weighted family of models\n\nGWmodel\n\nMultivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\nGW models suit situations when data are not described well by some global model, but where there are spatial regions where a suitably localised calibration provides a better description.\nGWmodel includes functions to calibrate: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms.\nDiscriminant analysis\nused to analyze data when the dependent variable is categorical and the independent variable is interval in nature\n\n\n\nData\n\nURA Master Plan subzone boundary\n\nmpsz &lt;- st_read(dsn = 'data/geospatial/', layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nResale prices of condominium in 2015\n\ncondo_resale &lt;- read_csv('data/aspatial/Condo_resale_2015.csv')\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nWrangling\n\nURA Master Plan subzone boundary\nSince mpsz does not have EPSG information, use st_tranform() to modify the projection of mpsz\n\nmpsz_3414 &lt;- st_transform(mpsz, 3414)\n\n# to verify\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nReveal the extent of mpsz_3414\n\n# Returns bounding of a simple feature or simple feature set\nst_bbox(mpsz_3414)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\n\n\nResale prices of condominium in 2015\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\ncondo_resale_sf &lt;- condo_resale %&gt;% st_as_sf(coords = c('LONGITUDE','LATITUDE'), crs=4326) %&gt;%\n    st_transform(crs=3414) \n\n\ncondo_resale_sf\n\nSimple feature collection with 1436 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 1,436 × 22\n   POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE\n *    &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1   118635       3000000      309    30     7.94          0.166\n 2   288420       3880000      290    32     6.61          0.280\n 3   267833       3325000      248    33     6.90          0.429\n 4   258380       4250000      127     7     4.04          0.395\n 5   467169       1400000      145    28    11.8           0.119\n 6   466472       1320000      139    22    10.3           0.125\n 7   309502       3410000      218    24     4.24          0.326\n 8   468497       1420000      141    24    11.6           0.162\n 9   118450       2025000      165    27     6.46          0.123\n10   268157       2550000      168    31     6.52          0.609\n# ℹ 1,426 more rows\n# ℹ 16 more variables: PROX_ELDERLYCARE &lt;dbl&gt;, PROX_URA_GROWTH_AREA &lt;dbl&gt;,\n#   PROX_HAWKER_MARKET &lt;dbl&gt;, PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;,\n#   PROX_PARK &lt;dbl&gt;, PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\nEDA using ggplot2\n\nUnivariate\nSELLING_PRICE\n\n\nCode\nggplot(data=condo_resale_sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nSince it has a right-skewed distribution, normalise using logarithmic transformation.\nLOG_SELLING_PRICE\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;% \n    mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nSELLING_PRICE vs LOG_SELLING_PRICE\n\nCode\nggplot(data=condo_resale_sf, aes(x=`SELLING_PRICE`)) +\n    geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\nggplot(data=condo_resale_sf, aes(x=`LOG_SELLING_PRICE`)) +\n    geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate (Trellis)\n\n\nCode\nAREA_SQM &lt;- ggplot(data=condo_resale_sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale_sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale_sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale_sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale_sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\nStatistical Point Map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\n\nCode\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz_3414)+\n  tm_polygons() +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\nWarning: The shape mpsz_3414 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n\nHedonic Pricing Models in R using lm()\n\nSimple Linear Regression\nObtain and print a summary analysis\n\n\nCode\ncondo_slr &lt;- lm(\n    SELLING_PRICE ~ AREA_SQM, \n    condo_resale_sf)\nsummary(condo_slr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\n\nSESELLING_PRICE = 14719*AREA_SQM - 258121.1\nR-squared = 0.4518 (model is able to explain ~45% of actual condonresale prices\nModel p-values &lt;&lt;&lt; 0.001 (reject H0 that mean is a good estimator of SELLING_PRICE, hence there is sufficient statistic evidence that simple linear regression model above is a good estimator of SELLING_PRICE.\nBoth coefficient p-values &lt;&lt;&lt; 0.001 (reject H0 … and can infer that both coefficients are good parameter estimates)\n\nVisualise best fit curve on a scatterplot\n\n\nCode\n# using lm() as a method function\nggplot(data=condo_resale_sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are a few statistical outliers with relatively high selling prices.\n\n\n\n\n\nMultiple Linear Regression\nVisualising the relationships of the independent variables (to identify highly correlated variables)\n\n\nCode\n# corrplot\ncorrplot(cor(\n    condo_resale[,5:23]),\n    diag = FALSE,      # correlation coefficients are hidden\n    order = 'AOE',\n    tl.pos = 'td',     # top-diagonal text labels\n    tl.cex = .5,       # size of text labels\n    method = 'number', # visualisation method\n    type = 'upper'     # displays upper half triangle of correlation matrix\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building\n\n\n\nBuilding the model\n\n\nCode\n# using lm()\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale_sf)\nsummary(condo_mlr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nRevising the Model\n\n\n\n\n\n\nWe still have to improve the model by removing statistically insignificant variables\nTests and packages used:\n\nolsrr\n\nols_regress() - model summary\nols_vif_tol() - check multicolinearity\nols_plot_resid_fit() - check linearity\nols_plot_resid_hist() or ols_test_normality() - check normality\ncheck autocorrelation\n\ntbl_regression() from gtsummary\n\n\n\n\n\n[Remove] statistically insignificant variables\n\ncondo_mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                data=condo_resale_sf)\n\n\n\n[VIF] ols_vif_tol() - check multicolinearity\n\n\nCode\nols_vif_tol(condo_mlr1)\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\n\n\n\n\n\nVIF &lt; 10: no sign of multi-colinearity\n\n\n\n\n\n[Residual] ols_plot_resid_fit() - check linearity\n\n\nCode\nols_plot_resid_fit(condo_mlr1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nMost of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\n\n[Residual] ols_plot_resid_hist() or\n{#| output: true} #| code-fold: true{r} ols_plot_resid_hist(condo_mlr1)\n\n\n\n\n\n\nInterpretation\n\n\n\nResiduals appear normally distributed\n\n\n\n\n[Stat. test] ols_test_normality() - check normality\n\n\nCode\nols_test_normality(condo_mlr1)\n\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\np-values &lt;&lt; 0.05(significance level). Hence we will reject the null H0 and infer that there is statistical evidence that the residual are not normally distributed\n\n\n\n\nSpatial autocorrelation test\n\n\nCode\n# save residual of the hedonic pricing model as a data frame\nmlr_output &lt;- as.data.frame(condo_mlr1$residuals)\n\n# join with condo_resale_sf\ncondo_resale_res_sf &lt;- cbind(condo_resale_sf, mlr_output) %&gt;% \n    mutate(MLR_RES = condo_mlr1$residuals)\n# convert condo_resale_res_sf into a SpatialPointsDataFrame\ncondo_resale_sp &lt;- as_Spatial(condo_resale_res_sf)\ncondo_resale_sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 24\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\n\nCode\ntm_shape(mpsz_3414) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_res_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\nWarning: The shape mpsz_3414 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nSigns of spatial autocorrelation. Now need to test for its significance\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\nCode\n# Moran's I\n\n# compute the distance-based weight matrix\nnb &lt;- dnearneigh(\n    coordinates(condo_resale_sp),\n    0,    # lower bound\n    1500, # upper bound\n    longlat = FALSE\n)\n\n# convert nb into spatial weights\nnb_lw &lt;- nb2listw(nb, style = 'W')\n\n# perform Moran's I\nlm.morantest(condo_mlr1, nb_lw)\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale_sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nCode\n# summary(nb)\n# summary(nb_lw)\n\n\n\n\n\nGenerate publication-ready summary tables\n\n\nCode\nols_regress(condo_mlr1)\n\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.592 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.592                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\nOR,\n\n\nCode\ntbl_regression(condo_mlr1, intercept = TRUE) %&gt;% \n    \n    # include model statistics as a table source note\n    add_glance_source_note(\n        label = list(sigma ~ \"\\U03C3\"),\n        include = c(\n            r.squared, \n            adj.r.squared, \n            AIC, \n            statistic,\n            p.value, \n            sigma))\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nCode\n# More info\n# https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html\n\n\n\n\n\nRDS\n\nwrite_rds(mpsz_3414,'../ex11/data/rds/mpsz_3414.rds')\nwrite_rds(condo_resale_sp,'../ex11/data/rds/condo_resale_sp.rds')"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html",
    "href": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html",
    "title": "Hands-on Exercise 3: 1st and 2nd Order Spatial Point Patterns Analysis (SPPA) Methods",
    "section": "",
    "text": "Distribution of Crime Incidents\n\n\n\nPoint pattern analysis (PPA) is the study of the spatial arrangements of points in (usually 2D) space to find out if the pattern is random or the result of something.\n\nSpatial PPA Methods\n\n\n1st order\n\nDensity-based\n\nKernel density estimation: compute intensity of a point distribution (Adaptive v. Fixed Bandwidth)\nQuadrat analysis to obtain variance-mean ratio (VMR: &gt;0,0,&lt;0): measure of dispersion rather than a measure of pattern; single measure for the entire distribution, so variation within the region are not recognised\n\nDistance-based\n\nNearest Neighbour Index\nG-function\nF-function\nK-function\nL-function\n\n\n\n\n\n\n\n\nPoint Pattern Analysis Concepts\nPoint Pattern Analysis: Clustered, Regular and Dispersed Patterns\n\n\n\n\n\n\n\n\n\n\nPattern\nDefinition\nStatistical Implication\nSources\n\n\n\n\nClustered\n\nEvents that are more grouped than expected of CSR\n\n\nsmaller within-cluster distance between points\nbigger btwn-cluster distance\noverdispersion (var. &gt; mean)\n\n\ncontagion (event presence increases probability of events nearby)\nheterogeneity (no correlations; could be parent-offspring clusters; homogenous geography)\n\n\n\nDispersed / Uniform\n\nopposite of clustered\n\n\nopposite of clustered\n\n\ncompetition between entities (their distancing modelled as min. allowed distance between points)\n\n\n\nRandom\n\nneither one from the above\nreferred to as a “hypothetical” pattern\nconstant intensity\n\n\nevery point in space follows a Uniform dist.\nNumber of events in any area follows a Poisson dist.\n\n\n\n\n\n\nPoint Pattern Analysis: Nearest Neighbor Statistics\n\n\n\n\n\n\n\n\nTerminology\nDetail\n\n\n\n\nEvent\nActual observed location of an occurrence\n\n\nPoint\nReference points, which may not coincide with event locations\n\n\nEvent-to-Event Distance\nDistance between two event points.\n\n\nPoint-to-Event Distance\nDistance from a reference point to the nearest event\n\n\nEdge Corrections\nadjustments made to account for boundary effects, where the points near the edges of a study area might have neighboring events outside the study boundary\n\n\nEnvelopes\nsimulations are used to create a reference distribution under CSR\n\n\n\n\nPoint Pattern Analysis: Quadrat Counts\nPoint Pattern Analysis: F and J Functions\nPoint Pattern Analysis: K, L and Kd Functions\n\n\n\n\n\n\n\n\n\nFunctions\nUse\nInterpretation\n\n\n\n\nF\nMeasures point-to-event nearest neighbor distances\n\nAbove the CSR line: Suggests regularity or inhibition (points are more spread out).\nBelow the CSR line: Indicates clustering (points are closer together).\n\n\n\nG\nMeasures (only Nearest Neighbor) distances among events\n\nAbove the Envelope: Indicates clustering, where many events are close together.\nBelow the Envelope: Suggests regularity or inhibition, where events are more evenly spaced.\n\n\n\n(Ripley’s) K\nMeasures the expected number of points within a distance rrr of a randomly chosen point\n\nLimitation of nearest neighbor distance method is that it uses only nearest distance\nConsiders only the shortest scales of variation.\nK function uses more points.\n\nProvides an estimate of spatial dependence over a wider range of scales.\nBased on all the distances between events in the study area.\nAssumes isotropy over the region.\n\n\n\n\n\nL\n\n\n\n\n\n\n\n\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html#fixed-and-adaptive-kde",
    "href": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 3: 1st and 2nd Order Spatial Point Patterns Analysis (SPPA) Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nCompute KDE using fixed BW\n\nkde_childcareSG_600 &lt;- density(\n  childcareSG_ppp_km,\n  sigma=0.6,\n  edge=TRUE,\n  kernel='gaussian'\n)\n\n# sigma = 0.6 instead of 600 because\n# childcareSG_ppp_km object is in KILOMETERS\n\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\nCompute using adaptive BW\nFixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units (for example urban versus rural). One solution is to use adaptive BW instead.\n\ne.g. using kMeans to determine different bandwidth (search radius) to find a fixed number of events across all areas\n\nDerive adaptive KDE using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp_km,\n  method = 'kernel' # voronoi, kernel, nearest being the other methods\n)\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nCompare the fixed and adaptive KDE outputs.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_bw, main = \"Fixed BW\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive BW\")\n\n\n\n\n\n\n\n\n\n\nConverting KDE output into grid object\nConvert it so that it is suitable for mapping purposes.\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG_bw,'SpatialGridDataFrame')\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nConverting gridded output into raster\nConvert the gridded kernal density objects into RasterLayer object by using raster() of raster package\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG_bw)\n\n\nkde_childcareSG_bw_raster # min value differs from reference output(?)\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.005814e-14, 28.51831  (min, max)\n\n\n\n\nAssigning projection systems\nInclude the CRS information on kde_childcareSG_bw_raster RasterLayer\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.005814e-14, 28.51831  (min, max)\n\n\n\nNote the changes in the ‘CRS’ property.\n\n\n\n\nVisualising the output in tmap\nDisplay the raster in cartographic quality map\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\n\nComparing Spatial Point Patterns using KDE\nCompare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nExtract and Plot study areas\n\npg &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"JURONG WEST\")\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nCreate owin object\n\nconvert these sf objects into owin objects that is required by spatstat.\n\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\nCombine childcare points and the study area\n\nextract childcare that is within the specific region for future analysis\n\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nconvert m to km using rescale.ppp()\n\n\nchildcare_pg_ppp_km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp_km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp_km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp_km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\nplot these four study areas and the locations of the childcare centres\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp_km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp_km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp_km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp_km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\ncompute KDE (bw.diggle method is used to derive each of the bandwidth)\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp_km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp_km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp_km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp_km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\nCompute fixed bandwidth KDE (250m for comparison)\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp_km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp_km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp_km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp_km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html#nearest-neighbour-analysis",
    "href": "resources/Hands-on_Ex/ex3/Hands-On_Ex_3.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 3: 1st and 2nd Order Spatial Point Patterns Analysis (SPPA) Methods",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nPerform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThis test measures whether a spatial point pattern is more regular (evenly spaced) or more clustered than a random distribution.\n\nHo = The distribution of childcare services are randomly distributed (CSR).\nH1= The distribution of childcare services are not randomly distributed.\n95% confidence level\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"), # type of alternative for the hypothesis test\n                nsim=99                     # Number of Monte Carlo simulations to perform                                                 independent simulation of events\n  )\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n# clarkevans test is a crude measure of clustering or ordering of a point pattern.\n\n# This very small p-value (and &lt;0.05) indicates strong evidence against Ho, suggesting that the spatial pattern childcareSG_ppps is significantly different from CSR.\n\n\nClark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"), # check for deviations in both directions—whether the pattern is more regular or more clustered.\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.92662, p-value = 0.2729\nalternative hypothesis: two-sided\n\n# p-value &lt; 0.05: no statistical evidence that the spatial pattern in childcare_ck_ppp is different from CSR\n\n\n\nClark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.77312, p-value = 4.226e-05\nalternative hypothesis: two-sided\n\n# same conclusion as above"
  },
  {
    "objectID": "resources/Hands-on_Ex/ex5/Hands-On_Ex_5.html",
    "href": "resources/Hands-on_Ex/ex5/Hands-On_Ex_5.html",
    "title": "Hands-On Exercise 5: Spatial Weights & Applications",
    "section": "",
    "text": "I will be computing spatial weights using R, following these objectives\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep packa\n\n\nData (uploaded to eLearn)\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nPackages Required\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\nData\n\nHunan county boundary layer shapefile\n\nhunan &lt;- st_read(dsn = 'data/geospatial/', layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/Hands-on_Ex/ex5/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nHunan_2012.csv\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCombine using relational join\nleft_join() of dplyr package\n\nhunan &lt;- left_join(hunan,hunan2012)\n\nJoining with `by = join_by(County)`\n\nnames(hunan)\n\n [1] \"NAME_2\"      \"ID_3\"        \"NAME_3\"      \"ENGTYPE_3\"   \"Shape_Leng\" \n [6] \"Shape_Area\"  \"County\"      \"City\"        \"avg_wage\"    \"deposite\"   \n[11] \"FAI\"         \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"      \n[16] \"GIO\"         \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"        \n[21] \"EmpR\"        \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"  \n[26] \"Household_R\" \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"      \n[31] \"Agri\"        \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n[36] \"geometry\"   \n\nhunan &lt;- hunan %&gt;% select(3,7,15,36)\n\n\n\n\nVisualising Regional Development Indicator\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text('NAME_3', size=0.5)\n\n# choropleth map showing the distribution of GDPPC 2012\ngdppc &lt;- qtm(hunan, 'GDPPC')\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nsasp=1 : aspect ratio\nncol=2 : number of columns\n\n\n\nContiguity Spatial Weights Matrices\n\nNote: contiguity = neighbouring but sounds fancier\n\npoly2nb() of spdep package to compute contiguity weight matrices for the study area\n\nbuilds a neighbours list based on regions with contiguous boundaries.\n\nqueen argument that takes TRUE or FALSE\nDefault = TRUE: returns a list of first order neighbours using the Queen criteria.\n\n\n\nComputing (QUEEN) contiguity based neighbours\nCompute Queen contiguity weight matrix that lists all neighboring polygons\n\nwm_q &lt;- poly2nb(\n  hunan,\n  queen = TRUE,\n  # tends to create a larger set of neighbors b/c corner adjacency is allowed\n)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n# exploring wm_q:\n\n# Check neighbors for the first polygon in the object.\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n# Get the county name of Polygon ID=1\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\n# Get the county names of the five neighboring polygons\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n# Get GDPPC of the above 5 countries\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n# Display the complete weight matrix (Loooong output)\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nCreating (ROOK) contiguity based neighbours\nCompute Rook contiguity weight matrix\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\nVisualising contiguity weights\nConnectivity graph\n\nmapping func map_dbl() to apply st_centriod() on input vector (geometry column us.bound)\nget lat-long coordinates using cbind()\ncompute polygon centroids\nconnect centriods\n\nlongitude &lt;- map_dbl(\n  hunan$geometry,\n  ~st_centroid(.x)[[1]]\n)\n\n\nlatitude &lt;- map_dbl(\n  hunan$geometry,\n  ~st_centroid(.x)[[2]]\n)\n\n\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\nPlotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing distance based neighbours\ndnearneigh() of spdep package\n\nIf x is an \"sf\" object and use_s2= is TRUE, spherical distances in km are used\n\n\nDetermine the cut-off distance\nDetermine the upper limit for distance band:\n\nknearneigh()\nknn2nb()\nunlist()\n\n\nk1 &lt;- knn2nb( \n# Convert knn object returned by knearneigh() into a neighbours list of class nb with a list of int vectors containing neighbour region num IDs\n  \n  knearneigh(coords)\n# Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other\n  )\nk1dists &lt;- unlist(\n# Remove the list structure of the returned object\n  \n  nbdists(k1, coords, longlat = TRUE)\n# Return the length of neighbour relationship edges; KM by default\n  )\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nLargest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nCompute fixed distance weight matrix\nUse dnearneigh()\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nNote: ‘Average number of links’: each region has 3.68 neigbours with 62km\n\nDisplay wm_d62 weight matrix\n\nstructure\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\ntable() and card() of spdep\n\ntable(hunan$County, card(wm_d62))\n\n\n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\nPlotting fixed distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\n\nNote:\n\nred: links of 1st nearest neighbours;\nblack: links of neighbours within the cut-off distance of 62km\n\n\n\n\nComputing adaptive distance weight matrix\nIssue of fixed distance weight matrices is that the denser urbanised areas tend to have more neighbours than less dense, rural areas, smoothing the neighbour relationships across neighbours.\nControl the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nNote: each county has strictly 6 neighbours\n\n\nPlotting distance based neighbours\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nWeights based on Inverse Distance (IDW)\n\nDerive spatial weight matrix based on IDW method\n\nnbdists()\n\n# compute the distances between areas\ndist &lt;- nbdists(\n  wm_q,\n  coords,\n  longlat = TRUE # TRUE if point coords are long.-lat. decimal deg.\n  )\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\n\nRow-standardised Weights Matrix\n\nAssign each neighboring polygon with equal weight (style=“W”).\n\nAssign the inverse of #ofneighbors to each neighboring county then\nSum the weighted income values.\n\n\n\nWhile this is the most intuitive way to summaries the neighbors’ values it has one drawback:\n\nPolygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\n\nrswm_q &lt;- nb2listw( # pairs a neighbours list w. spatial weights for the chosen coding scheme\n  wm_q,\n  style=\"W\",\n  zero.policy = TRUE # allows for lists of non-neighbors\n  # Be cautious of missing neighbors in dataset\n  )\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n# when R computes the avg neighboring income values, each neighbor’s income will be multiplied by .125 before being tallied\n\nUsing the same method, derive a row standardised distance weight matrix:\n\nrswm_ids &lt;- nb2listw(\n  wm_q,\n  glist=ids,\n  style=\"B\",\n  zero.policy=TRUE\n  )\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\nApplications of Spatial Weight Matrix\n\nSpatial lag with row-standardized weights\n\n# compute the average neighbor GDPPC value for each polygon\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\n\nGDPPC.lag # returns spatially lagged values\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nPreviously,\n\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n# What is the significance of Spatial Lag with row-standardized weights now?\n# Each region's spatial lag is the weighted avg of the neighboring regions' values, where the weights == proximity of each neighbor.\n\n# Row-standardization ensures comparability across regions, as the influence of neighbors is relative rather than absolute. This is useful when the number of neighbors varies significantly between spatial units.\n\nAppend the spatially lag GDPPC values onto hunan sf data frame\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_3  County GDPPC lag GDPPC                       geometry\n1 Anxiang Anxiang 23667  24847.20 POLYGON ((112.0625 29.75523...\n2 Hanshou Hanshou 20981  22724.80 POLYGON ((112.2288 29.11684...\n3  Jinshi  Jinshi 34592  24143.25 POLYGON ((111.8927 29.6013,...\n4      Li      Li 24473  27737.50 POLYGON ((111.3731 29.94649...\n5   Linli   Linli 25554  27270.25 POLYGON ((111.6324 29.76288...\n6  Shimen  Shimen 27137  21248.80 POLYGON ((110.8825 30.11675...\n\n\nPlot both the GDPPC and spatial lag GDPPC\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nSpatial lag as a sum of neighbouring values\nCalculate spatial lag as a sum of neighboring values by assigning binary weights”\n\naccess neighbors list,\napply a function that will assign binary weights,\nexplicitly assign these weights by using glist = in the nb2listw function\n\nb_weights &lt;- lapply( \n  # applies a function across each value in the neighbors structure\n  # in this case, applies a func that assigns a value of 1 per neighbor\n\n  wm_q, \n  function(x) 0*x + 1\n  )\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nUse lag.listw\n\nlag_sum &lt;- list(\n  hunan$NAME_3, \n\n  # compute a lag variable using weights & gdppc\n  lag.listw(b_weights2, hunan$GDPPC)\n  )\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nSpatial lag : Sum of neigbouring values\n\nAppend the lag_sumGDPPC field into hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nPlot both the GDPPC and Spatial Lag Sum GDPPC\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSpatial window average\nUse include.self() from spdep\n\n# add the diagonal element to the neighbour list\nwm_qs &lt;- include.self(wm_q)\n\n\nNote:\nnum of nonzero links=536,\n%nonzero weights=6.921488,\navg number of links=6.090909 ,\nrespectively as compared to wm_q of 448, 5.785124 and 5.090909\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\nNote: [1] has 6 neighbours instead of 5\n\nObtain weights with nb2listw() , assign weight values with nb2listw() and glist()\n\nwm_qs &lt;- nb2listw(\n  wm_qs,\n  )\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nExpected output:\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\nCreate the lag variable from weight structure and GDPPC variable\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nConvert the lag variable listw object into a data.frame using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nNote:\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\nAppend lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nCompare the values of lag GDPPC and Spatial window average using kable() of Knitr package\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nPlot the lag_gdppc and w_ave_gdppc maps\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nUse core tmap functions for better comparison\n\n\n\nSpatial window sum\nSpatial window sum is the counter part of the window average, but without using row-standardized weights.\nadd the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nassign binary weights to the neighbour structure that includes the diagonal element\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n# note that theres 6 neighbours now\n\nuse nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\ncompute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nconvert the lag variable listw object into a data.frame by using as.data.frame()\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nappend w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\ncompare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nqtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "resources/Take-home_Ex/ex3/Take-home_Ex3.html",
    "href": "resources/Take-home_Ex/ex3/Take-home_Ex3.html",
    "title": "Take-Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "",
    "text": "NOTE: EVAL: FALSE\nOverview\nMotivation\nMethodology\nMy group and I will be investigating crime in Malaysia. This is how we decided to split the workload of the initial analysis:\n\n\neach of us focus on one crime subtype under ‘Assault’ (referred to as ‘violent crimes’ on the source website)\n\nwill: causing injury\nmarcus: murder\nsanthya:\n\n\n\nClustering analysis:\n\nESDA (LISA maps with main input parameters: crime type, contiguity?/bandwidth analysis/k-means method, confidence level)\n\nClustering\n\nsanthya: hclust\nmarcus: clustGEO\nwill: SKATER\n\n\n\n\n\nR packages used\n\nCodepacman::p_load(spdep, tmap, sf, ClustGeo, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse, GGally)\n\n\nDatasets\n\n\nData\nDescription\nSource\n\n\n\nCrimes in Malaysia\nNumber of crimes in Malaysia by district, crime category, and type of crime\ndata.gov.my\n\n\nPopulation figures\nPopulation at state level from 1970 - 2024\ndata.gov.my\n\n\nMalaysia’s Sub-national Administrative Boundaries\n\nMalaysia administrative level 0-2 boundaries, where:\n\nlevel 1: state\nlevel 2: district\n\n\ndata.humdata.org\n\n\n\n\nCodelibrary(readr)\ncrime_district &lt;- read_csv(\"data/crime_district.csv\")\npopulation_state &lt;- read_csv(\"data/population_state.csv\")\nmsia_adm1_sf &lt;- st_read(dsn = 'data/mys_adm_unhcr_20210211_shp/', layer = 'mys_admbnda_adm1_unhcr_20210211')\n\n\ncrime_district :\n\nremove rows containing country-aggregated data, ‘property’-type crimes\n\nremove columns where category='assault' and district='All'\n\nCodecrime_state &lt;- crime_district %&gt;% \n    filter(state != \"Malaysia\") %&gt;% \n    filter(category != \"property\") %&gt;% \n    filter(district == \"All\") %&gt;% \n    select(-c(2:3))\n\n\n\n\npopulation_state :\n\nremove all the dates outside the 2016 to 2022 time period\n\nselect rows aggregated by sex, age and ethnicity (where data under the corresponding columns equals both or overall)\n\nCode{r}\nlibrary(dplyr)\nlibrary(lubridate)\n\n# population_state_filtered &lt;- \npop_data &lt;- population_state %&gt;%\n    filter(year(ymd(date)) &gt;= 2016 & year(ymd(date)) &lt;= 2022) %&gt;% \n    filter(sex == 'both') %&gt;% \n    filter(age == 'overall') %&gt;% \n    filter(ethnicity == 'overall') %&gt;% \n    select(-c(3:5))\n\n\n\n\n\n\n\n\n\n\nPopulation figures are in the ’000s (Thousands of people)\n\n\n\nmsia_adm1_sf :\n\n\nextract ADM1_EN, ADM1_PCODE, Shape_ and geometry data\n\nCodeadm1_sf &lt;- msia_adm1_sf %&gt;% select(-c(3:7))\n\n\n\n\nEnsure that consistent state labels across datasets.\n\nCodeunique(pop_data$state)\nunique(crime_state$state)\nunique(adm1_sf$ADM1_EN)\n\n\nAfter running each dataset through unique() , W.P. Labuan and W.P. Putrajaya are missing from crime data. This is because “data for W.P. Putrajaya and W.P. Labuan are classified under W.P. Kuala Lumpur and Sabah respectively” (source). Hence, I will have to modify pop_data (specifically W.P. Kuala Lumpur data).\n\nCodefixed_pop_data &lt;- pop_data %&gt;%\n  mutate(state = case_when( # case_when allows for multiple if-else statements\n    state == \"W.P. Putrajaya\" ~ \"W.P. Kuala Lumpur\",\n    state == \"W.P. Labuan\" ~ \"Sabah\",\n    TRUE ~ state # assumes no NA, which there arent any\n  )) %&gt;%\n  group_by(state, date) %&gt;%\n  summarise(population = sum(population), .groups = 'drop')\n\n\nDerive crime rate rather than using absolute crime figures. Benefits include:\n\n\n\\[\n\\text{Crime Rate} = \\Bigg( \\frac{\\text{Number of Crimes}}{\\text{Population in Thousands}} \\Bigg) \\times \\ 1\\text{,}000\n\\]\n\nEasier to judge the prevalence of crime relative to the population size of the state\n\nUnderstanding rates can help communicate the actual risk of crime to the community, helping to mitigate unnecessary fear\n\nCodecrime_rates_state &lt;- crime_state %&gt;% \n    left_join(fixed_pop_data, by = c(\"state\", \"date\")) %&gt;% \n    mutate(crime_rate = (crimes / population) * 1000)\n\n\n\nCodewrite_rds(crime_rates_state, 'data/rds/crime_rates_state.rds')\n\n\n\nTabs (Creating, Modifying, Exploring…)\n[Prototype] Shiny Application UI Storyboard\n\nStoryboard Guide\n\nsummary text\nTab 1\nFigure\nFigure caption\nDescription\n&lt;repeat&gt;\nConclusion"
  },
  {
    "objectID": "resources/ICEs/ex9/ice9.html",
    "href": "resources/ICEs/ex9/ice9.html",
    "title": "ICE 9",
    "section": "",
    "text": "Load packages\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nLoad RDS\n\nshan_ict &lt;- read_rds('data/rds/shan_ict.rds')\nshan_sf_cluster &lt;- read_rds('data/rds/shan_sf_cluster.rds')\nshan_sf &lt;- read_rds('data/rds/shan_sf.rds')\n\n\n# H. clustering\nproxmat &lt;- dist(shan_ict, method='euclidean')\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6)) # cutree directly uses hclust object; won't understand k without it\n\n# 'method', 'k' should be the user input parameter\n\n\n# append to geo data\nshan_sf_cluster &lt;- cbind(\n    shan_sf, as.matrix(groups)) %&gt;% # for it to be appendable, must convert to tibble/dt/matrix \n    rename(`CLUSTER` = `as.matrix.groups.`) %&gt;% # for application friendly analysis\n    select(-c(3:4,7:9)) %&gt;% # minus sign to drop\n    rename(TS = TS.x) # application cleanliness\n\n\n# dendrogram\nplot(hclust_ward, cex = .6)\nrect.hclust(hclust_ward, k = 6,border = 2:5)\n\n\n\n\n\n\n\n\n\nqtm(shan_sf_cluster, \"CLUSTER\") # any of the 16 random colors are assigned \n\n\n\n\n\n\n\n\n\n# SKATER\nshan.nb &lt;- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\n# visualise nb\ncoords &lt;- st_coordinates(st_centroid(st_geometry(shan_sf)))\nplot(st_geometry(shan_sf), border=grey(.5))\nplot(shan.nb,\n    coords, \n    col=\"blue\", \n    add=TRUE) # adds to existing plot, otherwise will be plotted separately\n\n\n\n\n\n\n\n\n\n# Compute edge costs\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nshan.w &lt;- nb2listw(\n    shan.nb,\n    lcosts,\n    style = 'B' # ensures cost values arent row-standardised\n)\n\n\n# compute tree\nplot(st_geometry(shan_sf), border = gray(.5))\nshan.mst &lt;- mstree(shan.w)\nplot(\n    shan.mst,\n    coords,\n    cex.labels = .7,\n    cex.circles = .005,\n    add = TRUE\n)\n\n\n\n\n\n\n\n\n# compute spatially constrained clusters using SKATER\nskater_clust6 &lt;- skater(\n    edges = shan.mst[,1:2], # exclude the 3rd col (cost)\n    data = shan_ict,\n    method = 'euclidean',\n    ncuts = 5 # one less than number of clusters\n)\n# plot\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(\n    skater_clust6, \n    coords, \n    cex.labels = .7 ,\n    groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n    cex.circles=0.005,\n    add=TRUE)\n# plot chloropleth map\ngroups_mat &lt;- as.matrix(skater_clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SKATER_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SKATER_CLUSTER\")\n\n\n\n\n\n\n\n\n\n\nClustGeo\n# compute spatial distance matrix\ndist &lt;- st_distance(shan_sf, shan_sf) # in tib format(col.) so need to convert to dist matrix obj\ndistmat &lt;- as.dist(dist)\n\ncr &lt;- choicealpha(\n    proxmat, \n    distmat, \n    range.alpha = seq(0, 1, 0.1), # start, stop, step\n    K = 6, \n    graph = TRUE)\n# expose only the first, so the end-user interpret cut-off\n# can use #| fig-keep: first to only show first figure\n\n\n\n\n\n\n\n\n# save ClustGEO outputs\n\nclustG &lt;- hclustgeo(\n    proxmat,\n    distmat,\n    alpha = 0.2) # user parameter interface: slider; only changes backend when user selects AND clicks a button, not everytime the slider is dragged\n\n# derive cluster object\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\n# join ClusterGeo groups list of formed clusters with shan_sf\nshan_sf_clustGeo &lt;- cbind(\n    shan_sf,\n    as.matrix(groups)) %&gt;% \n    rename(`CLUSTER` = `as.matrix.groups.`)\n\n\n# plot clustGEO chloropleth\nqtm(shan_sf_clustGeo, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n# characterising clusters\nggparcoord(\n    data = shan_sf_clustGeo,\n    columns = c(17:21),\n    scale = 'globalminmax', # no scaling, determined by global data range\n    alphaLines = .2,\n    boxplot = TRUE, # boxplot overlay\n    title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30)\n)\n\n\n\n\nWith #| fig-width: 12 and #| fig-column: page-right\n\n\n\n\n\nggparcoord(\n    data = shan_sf_clustGeo,\n    columns = c(17:21),\n    scale = 'globalminmax', # no scaling, determined by global data range\n    alphaLines = .2,\n    boxplot = TRUE, # boxplot overlay\n    title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30)\n)\n\n\n\n\nWithout #| fig-width: 12 and #| fig-column: page-right\n\n\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")\nqtm(shan_sf_spatialcluster, \"SKATER_CLUSTER\")\nqtm(shan_sf_clustGeo, \"CLUSTER\")\n\n\n\n\n\n\nUsed #| layout-nrow: 1, #| fig-width: 4\n\n\n\n\n\n\n\nUsed #| layout-nrow: 1, #| fig-width: 4\n\n\n\n\n\n\n\nUsed #| layout-nrow: 1, #| fig-width: 4"
  },
  {
    "objectID": "resources/ICEs/ex6/ice6.html",
    "href": "resources/ICEs/ex6/ice6.html",
    "title": "ICE 6",
    "section": "",
    "text": "Notes:\nSpatial Dependency (for interpolation/statistical methods): existence of statistical dependence in a collection of random variables, each with distinct geographical assoc.\n\nNot the focus of this course\n\n\nSpatial Autocorrelation\n\n\nsystematic spatial variable\n\nshow signs of clustering of similar neighbors / random, dissimilar neighbors (checkerboard)\n\n\n\n\nMoran’s I\n\n\nxi: observed value at location i\nxj: neighbor location of i\nwi,j: weight that determines the relationship between i and j\ndenominator standardizes value\ncan use to compared overall differences in study area\n\n\n\nGeary’s C\n\n\ncan compare immediate neighbors\nalways &gt; 0\n\n\n\nRelationship of Moran’s I and Geary’s C (from lesson slides)\n\nC approaches 0 and I approaches 1 when similar values are clustered.\nC approaches 3 and I approaches -1 when dissimilar values tend to cluster.\nHigh values of C measures correspond to low values of I.\nSo the two measures are inversely related.\n\n\n\nGetis-Ord Global G\n\n\nStrictly identifies/detect clusters only (high-high, low-low clusters, …)\n‘d’ means distance metric\nonly positive\n\n\n\nLISA\n\narray of analysis methods for clusters and outliers\n\nHigh–high / Low-low clusters\nLow-high (low outlier surrounded by high)\nHigh-low (high outlier surrounded by low)\n\nhelps determine if resultant clustering patterns are statistically significant\nCategorical geovisualisation to show distinct clusters; neutral/greyed out areas to indicate statistically INSIGNIFICANT areas (does not mean absence of data)\n\n\n\n\nICE\n\nsfdep\nenough for Take-home 2 requirements and additional exploration\n\n\nInstall R Packages\n\npacman::p_load(sf,tmap,sfdep,tidyverse)\n\n\n\nLoad Data\nHunan province administrative boundary layer at county level\n\nhunan &lt;- st_read('data/geospatial', layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex6/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nHunan_2012 development indicators\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRelational Join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;% dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nwm_q &lt;- hunan %&gt;% mutate(\n    nb=st_contiguity(hunan$geometry), # neighbor list object created by st_neighbors()\n    wt=st_weights(nb, style='W'), # default: get row-standardized weights\n    .before=1 # insert to the front (column 1)\n  )\n\n\n# compute global moran I\nmoran1 &lt;- global_moran(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\nglimpse(moran1)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n# K: avg neighbors found\n\n\n# perform global moran I test\nglobal_moran_test(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n# Output:\n# p-value &lt; significance level (0.05): enough statistical evidence to reject null H0 with 95% confidence level\n# low positive Moran statistic: weak clustering\n\n\n# perform global moran I permutation test using MC sims (ALWAYS USE THIS FIRST - 'MORE ROBUST')\n\n# set seed for reproducible computation\nset.seed(69)\n\n# perform MC sims\nglobal_moran_perm(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt,\n  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n# p-value even smaller\n\n\n# perform local moran I\nlisa &lt;-wm_q %&gt;% \n  mutate(\n    local_moran = local_moran(\n      GDPPC,\n      nb,\n      wt,\n      nsim = 99),\n    .before = 1,\n    ) %&gt;% \n  unnest(local_moran) # expands a list-column containing dataframes into rows and columns\n\n# there are 3 p-values\n# p_ii : base method (mean)\n# p_ii_sim : the nsim method (median -- better measure of central tendency; less affected by outliers)\n# p_folded_sim : permutation with replacement (pysal)\n\n\n# visualising p-value and local moran I\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill('ii') +\n  tm_borders(alpha = .5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = 'local moran I',\n    main.title.size = 2)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(col = \"ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = 'p-value moran I',\n    main.title.size = 2)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n# visualising LISA map\nlisa_sig &lt;- lisa %&gt;% filter(p_ii &lt;.05)\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = .5) +\ntm_shape(lisa_sig) +\n  tm_polygons('mean') +\n  tm_borders(alpha = .4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n# Gi statistics - base\nwm_idw &lt;- hunan %&gt;% \n  mutate(\n    nb = st_contiguity(hunan$geometry),\n    wt = st_inverse_distance(\n      nb,\n      hunan$geometry,\n      scale = 1,\n      alpha = 1),\n    .before = 1\n    )\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, hunan$geometry, scale = 1, alpha =\n  1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n# Gi-statistics MC sims perm\nHCSA &lt;- wm_idw %&gt;% \n  mutate(\n    local_Gi = local_gstar_perm(\n      hunan$GDPPC,\n      nb,\n      wt,\n      nsim = 99),\n    .before = 1) %&gt;% \n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0111 0.00000681  0.163  8.70e-1  0.64         0.32    1.34 \n 2 -0.333  Low     0.0111 0.00000692 -0.234  8.15e-1  1            0.5     1.15 \n 3  0.281  High    0.0123 0.00000958 -0.0324 9.74e-1  0.8          0.4     1.14 \n 4  0.411  High    0.0109 0.00000621  0.676  4.99e-1  0.42         0.21    1.07 \n 5  0.387  High    0.0115 0.00000799  0.377  7.06e-1  0.68         0.34    0.715\n 6 -0.368  High    0.0112 0.00000497 -0.370  7.11e-1  0.88         0.44    0.616\n 7  3.56   High    0.0147 0.00000725  2.78   5.40e-3  0.04         0.02    1.51 \n 8  2.52   High    0.0129 0.00000506  1.94   5.29e-2  0.14         0.07    0.946\n 9  4.56   High    0.0141 0.00000654  3.45   5.54e-4  0.02         0.01    0.948\n10  1.16   Low     0.0112 0.00000532  1.19   2.35e-1  0.22         0.11    1.43 \n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wt &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n# Visualising Gi\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill('gi_star') +\n  tm_borders(alpha = .4)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nHCSA_sig &lt;- HCSA %&gt;% filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = .5) +\n\ntm_shape(HCSA_sig) +\n  tm_fill('gi_star') +\n  tm_borders(alpha = .4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "resources/ICEs/ex1/data/MPSZ-2019.html",
    "href": "resources/ICEs/ex1/data/MPSZ-2019.html",
    "title": "William's Simple Geode",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "resources/ICEs/ex4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "resources/ICEs/ex4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "William's Simple Geode",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "resources/ICEs/ex3/ice3.html",
    "href": "resources/ICEs/ex3/ice3.html",
    "title": "ICE 3: SPPA: spatstat methods",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\nIssue 1: Installing maptools\nInstall from Posit Public Package Manager snapshots, because maptools is retired and binary is removed from CRAN\n\ninstall.packages('maptools', repos = 'https://packagemanager.posit.co/cran/2023-10-13')\n\n\nWhen retrieving archived versions, take note of dependencies.\n\n\nAfter installing, ensure eval=FALSE the installing code to avoid maptools from being downloaded and installed repetitively every time the qmd is rendered.\n\n\n\nIssue 2: Create coastal outline\nIn sf package, there are 2 functions that allow the combining of multiple sf into one sf:\n\nst_combine() and\nst_union() - Combines several feature geometries into one, without unioning or resolving internal boundaries\n\n# derive coastal outline of tibble data.frame\nsg_sf &lt;- mpsz_sf %&gt;% st_union()\n\n# sg_sf &lt;- mpsz_sf %&gt;% st_union()\n# plot(sg_sf)\n\n# doesnt work; error message:\n# ! object 'mpsz_sf' not found\n# Backtrace:\n# 1. mpsz_sf %&gt;% st_union()\n# 2. sf::st_union(.)\n\n\nNote: straight convert to sf for consistency\nReference for enrichment\n\n\n\nIntro to spatstat package\n\nfor 2D SPPA, including multi-type or marked points\nsub-packages:\n\n\n# spatstat.data    - datasets\n\n# spatstat.utils   - util functions\n\n# spatstat.univar  - est. & manipulate prob. distr. of 1-d random vars\n\n# spatstat.sparse  - manipulate sparse arrays & perform linear algebra\n\n# spatstat.geom    - define spatial objs & perform geometrical ops \n\n# spatstat.random  - rng of spatial pattern & model sims\n# spatstat.explore - EDA & nonparametric analysis of spatial data.\n\n# spatstat.model   - model-fitting, model diagnostics, and formal inference.\n\n# spatstat.linnet  - defines spatial data on a linear network, and performs geometrical operations and statistical analysis on such data.\n\n\nCreating ppp object from sf data.frame\nInstead of using the 2-step approaches discussed in Hands-on Exercise 3 to create the ppp objects, use as.ppp() from spatstat.geom to dervice a ppp object layer from sf tibble data.frame\n\nchildcare_sf3414 &lt;- st_read('data/child-care-services-geojson.geojson') %&gt;% st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex3/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nchildcare_ppp_ice3 &lt;- as.ppp(childcare_sf3414)\n\nWarning in as.ppp.sf(childcare_sf3414): only first attribute column is used for\nmarks\n\nplot(childcare_ppp_ice3)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nView childcare_ppp_ice3\n\nsummary(childcare_ppp_ice3)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\nCreating owin object from sf data.frame\nCreate an owin object class from polygon sf tibble data.frame\n\nsg_sf &lt;- st_read(dsn = 'data/', layer = 'CostalOutline')\n\nReading layer `CostalOutline' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex3/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nCombining point events object and owin object\n\n# childcare_sg_ppp &lt;- left_join()\n\nchildcare_sg_ppp_ice3 &lt;- ppp(\n  x = childcare_ppp_ice3$x,\n  y = childcare_ppp_ice3$y,\n  window = sg_owin\n  )\n\nWarning: data contain duplicated points\n\n\n\nplot(childcare_sg_ppp_ice3)\n\n\n\n\n\n\n\n\nAlternatively,\n\nchildcare_sg_ppp_ice3_1 &lt;- childcare_ppp_ice3[sg_owin]\n\n\nplot(childcare_sg_ppp_ice3_1)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation of Spatial Point Event\nThe code chunk below re-scale the unit of measurement from metre to kilometre before performing KDE.\n\nchildcare_sg_ppp_km_ice3 &lt;- rescale(childcare_sg_ppp_ice3,1000,'km')\n\n# Computes an adaptive estimate of the intensity function of a point pattern.\nkde_childcare_sg_adaptive &lt;- adaptive.density(\n  childcare_sg_ppp_km_ice3,\n  method = 'kernel'\n)\n\nplot(kde_childcare_sg_adaptive)\n\n\n\n\n\n\n\n\n\n\nKDE - converting output into grid object\n\nmaptools methodspatstat.geom method\n\n\n\ngridded_kde_childcare_sg_adaptive &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcare_sg_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nplot(gridded_kde_childcare_sg_adaptive)\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_childcare_sg_adaptive)\n\n\n\n\n\n\n\n\n\nNote: plot() v. spplot()\n\nplot(): Best for basic, quick visualizations using base graphics.\nspplot(): Ideal for advanced spatial plotting with thematic elements using lattice graphics.\n\n\n\n\n\ngridded_kde_childcare_sg_adaptive_1 &lt;- as(\n  kde_childcare_sg_adaptive,\n  'SpatialGridDataFrame')\n# same output map as maptools method\n# spplot(gridded_kde_childcare_sg_adaptive_1) \n\n\n\n\nPlotting an output raster using tmap\n\nkde_childcareSG_bw &lt;- density(\n  childcare_sg_ppp_km_ice3,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel='gaussian'\n)\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG_bw)\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")\n\nWarning: Currect projection of shape kde_childcareSG_bw_raster unknown. Long\nlat (epsg 4326) coordinates assumed.\n\n\n\n\n\n\n\n\n\n\n\nExtract and create an ppp object showing child care services and within Punggol Planning Area\n\nmpsz_sf &lt;- st_read(dsn = 'data/', layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/williamtjw/is415-gaa-williamtjw/resources/ICEs/ex3/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\npunggol_owin &lt;- mpsz_sf3414 %&gt;% \n  filter(PLN_AREA_N=='PUNGGOL') %&gt;% \n  as.owin()\nplot(punggol_owin)\n\n\n\n\n\n\n\n\n\npunggol_childcare_ppp &lt;- childcare_ppp_ice3[punggol_owin]\nplot(punggol_childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nTake-Home Exercise 1: Geospatial Analysis for Social Good: Myanmar Armmed Conflict Case Study\n\nData(if have access key, for now we use eLearn file of Myanmar)\n\n\nacled_Myanmar_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;% \n  st_as_sf(coords = c('longitude','latitude'),\n    crs = 4326) %&gt;%                           # important to know which PCS to use\n  st_transform(crs = 32647) %&gt;%               # source data\n  mutate(event_date = dmy(event_date))\n\nRows: 55574 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# note that myanmar cuts thru 2 different UTMs(a PCS)\n# dmy: As long as the order of formats is correct, these functions will parse dates correctly even when the input vectors contain differently formatted dates.\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nacled_Myanmar_sf %&gt;% \n  filter(year==2023 | event_type=='Political violence') %&gt;% \n  tm_shape()+\n  tm_dots()\n\n\n\n\n\n\n\n\n\nCould not render the site after many attempts at fixing because of an unknown cause. Next best option was to take a screenshot of the output to see if it was because of processing."
  },
  {
    "objectID": "resources/ICEs/ex2/data/MPSZ-2019/MPSZ-2019.html",
    "href": "resources/ICEs/ex2/data/MPSZ-2019/MPSZ-2019.html",
    "title": "William's Simple Geode",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Applications (GAA)",
    "section": "",
    "text": "This is website contains my notes, ICEs, assignments for GAA. Enjoy."
  }
]